<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Neurotic Networking (Posts about RNN)</title><link>https://necromuralist.github.io/Neurotic-Networking/</link><description></description><atom:link href="https://necromuralist.github.io/Neurotic-Networking/categories/cat_rnn.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2023 &lt;a href="mailto:cloisteredmonkey.jmark@slmail.me"&gt;Cloistered Monkey&lt;/a&gt; 
&lt;div id="license"xmlns:cc="http://creativecommons.org/ns#" &gt;This work is licensed under
&lt;a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"&gt;CC BY 4.0
&lt;img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"&gt;
&lt;img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"&gt;&lt;/a&gt;
&lt;/div&gt;
</copyright><lastBuildDate>Wed, 12 Jul 2023 22:44:11 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Chatbot Tutorial</title><link>https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents" role="doc-toc"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents" role="doc-toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org96dd2fb"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#orgfd8093d"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org963cf4f"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org3ccf55d"&gt;Setup the Timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#orgb9469cd"&gt;Load Dotenv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org4856d11"&gt;Check CUDA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org3be41d6"&gt;Some Type Hints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org64d6872"&gt;Some Constants&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org9734d51"&gt;The Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org7574e41"&gt;Download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org78bffc1"&gt;Movie Lines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#orge609860"&gt;Conversations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org6dfd332"&gt;Store the Processed Lines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org9fdffc7"&gt;Check Our Stored File&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org566bd75"&gt;A Vocabulary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org2ca6d40"&gt;Preparing the Data For Model-Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org655cfbe"&gt;Related Repositories To Check Out&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org96dd2fb" class="outline-2"&gt;
&lt;h2 id="org96dd2fb"&gt;Introduction&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org96dd2fb"&gt;
&lt;p&gt;
This is a walk-through the &lt;a href="https://pytorch.org/tutorials/beginner/chatbot_tutorial.html"&gt;pytorch Chatbot Tutorial&lt;/a&gt; which builds a chatbot using a recurrent Sequence-to-Sequence model trained on the &lt;a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html"&gt;Cornell Movie-Dialogs Corpus&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfd8093d" class="outline-2"&gt;
&lt;h2 id="orgfd8093d"&gt;Set Up&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgfd8093d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org963cf4f" class="outline-3"&gt;
&lt;h3 id="org963cf4f"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org963cf4f"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcdfb643" class="outline-4"&gt;
&lt;h4 id="orgcdfb643"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgcdfb643"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from collections import defaultdict, namedtuple
import codecs
from pathlib import Path
from typing import Dict, List, Union
from zipfile import ZipFile
import csv
import os
import subprocess
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb848980" class="outline-4"&gt;
&lt;h4 id="orgb848980"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgb848980"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from dotenv import load_dotenv
import requests
import torch
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5462749" class="outline-4"&gt;
&lt;h4 id="org5462749"&gt;This Project&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5462749"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from neurotic.tangles.timer import Timer
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3ccf55d" class="outline-3"&gt;
&lt;h3 id="org3ccf55d"&gt;Setup the Timer&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3ccf55d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb9469cd" class="outline-3"&gt;
&lt;h3 id="orgb9469cd"&gt;Load Dotenv&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb9469cd"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;load_dotenv("../../.env")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4856d11" class="outline-3"&gt;
&lt;h3 id="org4856d11"&gt;Check CUDA&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4856d11"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using {}".format(device))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Using cuda
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3be41d6" class="outline-3"&gt;
&lt;h3 id="org3be41d6"&gt;Some Type Hints&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3be41d6"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;OptionalList = Union[list, None]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org64d6872" class="outline-3"&gt;
&lt;h3 id="org64d6872"&gt;Some Constants&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org64d6872"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ENCODING = "iso-8859-1"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9734d51" class="outline-2"&gt;
&lt;h2 id="org9734d51"&gt;The Data&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9734d51"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7574e41" class="outline-3"&gt;
&lt;h3 id="org7574e41"&gt;Download&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7574e41"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class MovieData:
    """Dowload and ready the movie data
    Args:
     download_path: Path to the folder to store the data
     url: download url for the zip file
     chunk_size: bytes to read from stream during download
     clean_up: remove the extra downloaded files
    """
    def __init__(self,
		 download_path: Path,
		 url: str=("http://www.cs.cornell.edu/~cristian/data/"
			   "cornell_movie_dialogs_corpus.zip"),
		 chunk_size=1024,
		 clean_up: bool=True) -&amp;gt; None:
	self.download_path = download_path
	self.url = url
	self.chunk_size = chunk_size
	self.clean_up = clean_up
	self._zip_path = None
	self._data_path = None
	self._zip_file = None
	return

    @property
    def zip_path(self) -&amp;gt; Path:
	"""Path to the downloaded zip file"""
	if self._zip_path is None:
	    self._zip_path = self.download_path.joinpath(Path(self.url).name)
	return self._zip_path

    @property
    def data_path(self) -&amp;gt; Path:
	"""Path to the unzipped file"""
	if self._data_path is None:
	    self._data_path = self.download_path.joinpath(
		Path(self.zip_path).stem)
	return self._data_path

    @property
    def zip_file(self) -&amp;gt; ZipFile:
	"""the Zip file for the zipped data"""
	if self._zip_file is None:
	    self._zip_file = ZipFile(self.zip_path)
	return self._zip_file

    def clean(self) -&amp;gt; None:
	"""remove the extra downloaded files"""
	os.remove(self.zip_path)
	return

    def __call__(self) -&amp;gt; None:
	"""downloads and prepares the file if needed"""
	if not self.data_path.is_dir():
	    if not self.zip_path.is_file():
		response = requests.get(self.url, stream=True)
		with self.zip_path.open("wb") as writer:
		    for chunk in response.iter_content(chunk_size=self.chunk_size):
			if chunk:
			    writer.write(chunk)
	    unpacked = []
	    for name in self.zip_file.namelist():
		name = Path(name)
		# there's extra folders and hidden files in there that I'll avoid
		if name.suffix in (".pdf", ".txt") and not name.name.startswith("."):
		    self.zip_file.extract(str(name), path=self.data_path)
		    unpacked.append(name)
	    assert self.data_path.is_dir()
	    if self.clean_up:
		# there is a sub-folder in the unzipped folder so move the
		# the files up one
		for to_move in unpacked:
		    self.data_path.joinpath(to_move).rename(
			self.data_path.joinpath(to_move.name))

		# now delete the temporary file
		os.remove(self.zip_path)
		if unpacked:
		    # now remove the sub-folder
		    self.data_path.joinpath(unpacked[0].parent).rmdir()
	return
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now let's download and unpack the data.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;datasets = Path(os.environ.get("DATASETS")).expanduser()
assert datasets.is_dir()
movie_data = MovieData(datasets, clean_up=True)
movie_data()
for name in movie_data.data_path.iterdir():
    print(" - {}".format(name.name))
&lt;/pre&gt;&lt;/div&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;chameleons.pdf&lt;/li&gt;
&lt;li&gt;conversation_line_pairs.tsv&lt;/li&gt;
&lt;li&gt;movie_conversations.txt&lt;/li&gt;
&lt;li&gt;movie_characters_metadata.txt&lt;/li&gt;
&lt;li&gt;movie_lines.txt&lt;/li&gt;
&lt;li&gt;movie_titles_metadata.txt&lt;/li&gt;
&lt;li&gt;raw_script_urls.txt&lt;/li&gt;
&lt;li&gt;README.txt&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class MovieFile:
    urls = "raw_script_urls.txt"
    readme = "README.txt"
    lines = "movie_lines.txt"
    characters = "movie_characters_metadata.txt"
    conversations = "movie_conversations.txt"
    titles = "movie_titles_metadata.txt"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org78bffc1" class="outline-3"&gt;
&lt;h3 id="org78bffc1"&gt;Movie Lines&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org78bffc1"&gt;
&lt;p&gt;
Here's an excerpt from the &lt;code&gt;README.txt&lt;/code&gt; file:
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
In all files the field separator is " &lt;del&gt;&lt;del&gt;&lt;del&gt;$&lt;/del&gt;&lt;/del&gt;&lt;/del&gt; "
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;movie_lines.txt
&lt;ul class="org-ul"&gt;
&lt;li&gt;contains the actual text of each utterance&lt;/li&gt;
&lt;li&gt;fields:
&lt;ul class="org-ul"&gt;
&lt;li&gt;lineID&lt;/li&gt;
&lt;li&gt;characterID (who uttered this phrase)&lt;/li&gt;
&lt;li&gt;movieID&lt;/li&gt;
&lt;li&gt;character name&lt;/li&gt;
&lt;li&gt;text of the utterance&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd33661e" class="outline-4"&gt;
&lt;h4 id="orgd33661e"&gt;Movie Line Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd33661e"&gt;
&lt;p&gt;
To load the lines I'm going to make a &lt;a href="https://docs.python.org/3.6/library/collections.html#collections.namedtuple"&gt;namedtuple&lt;/a&gt;.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;MovieLine = namedtuple("MovieLine", ["line_id",
				     "character_id",
				     "movie_id",
				     "character_name",
				     "text"])

LineData = Dict[str, MovieLine]
LineFields = MovieLine(**{field: index
			  for index, field in enumerate(MovieLine._fields)})
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5567457" class="outline-4"&gt;
&lt;h4 id="org5567457"&gt;A Line Loader&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5567457"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class MovieLines:
    """loads the movie dialog lines

    Args:
     path: path to the source file
     separator: column-separator
     encoding: the file encoding type (e.g. UTF-8)
    """
    def __init__(self, path: Path, separator: str=" +++$+++ ",
		 encoding="UTF-8") -&amp;gt; None:
	self.path = path
	self.separator = separator
	self.encoding = encoding
	self._lines = None
	return

    @property
    def lines(self) -&amp;gt; LineData:
	"""Dictionary Of Lines in the Data"""
	if self._lines is None:
	    self._lines = {}
	    with self.path.open(encoding=self.encoding) as reader:
		for line in reader:
		    tokens = line.strip().split(self.separator)

		    text = tokens[LineFields.text] if len(tokens) == len(LineFields) else ""
		    movie_line = MovieLine(line_id=tokens[LineFields.line_id],
					   character_id=tokens[LineFields.character_id],
					   movie_id=tokens[LineFields.movie_id],
					   character_name=tokens[LineFields.character_name],
					   text=text,
		    )
		    self._lines[movie_line.line_id] = movie_line
	return self._lines

    def head(self, lines: int=5, get: bool=False) -&amp;gt; OptionalList:
	"""show the first lines

	Args:
	 lines: number of lines to read
	 get: if true, return the lines
	"""
	output = [] if get else None
	with self.path.open() as reader:
	    for index, line in enumerate(reader):
		line = line.rstrip()
		print(line)
		if get:
		    output.append(line)
		if index + 1 &amp;gt;= lines:
		    break
	return output
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;movie_lines = MovieLines(movie_data.data_path.joinpath(MovieFile.lines), encoding=ENCODING)
output_lines = movie_lines.head(10)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example" id="orgc21bcc2"&gt;
L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!
L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!
L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.
L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?
L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.
L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow
L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.
L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No
L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this "persona"?  And you don't know how to quit?
L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?
&lt;/pre&gt;


&lt;p&gt;
As note in the &lt;code&gt;README.txt&lt;/code&gt; those strange characters are how the columns are separated (I guess so that the commas could be kept in the text). The Line IDs seem to be in reverse oredr, and don't seem to have all the lines - unless they're out of order and just looking at the head is misleading. For reference the movie for the lines I showed (the dialog between Bianca and Cameron) is from &lt;a href="https://www.imdb.com/title/tt0147800/"&gt;12 Things I Hate About You&lt;/a&gt;. For some reason they both encode the chraracters and give their names - &lt;code&gt;u0&lt;/code&gt; is &lt;code&gt;BIANCA&lt;/code&gt;.
&lt;/p&gt;

&lt;p&gt;
If you poke around in the file you'll find that there's something peculiar about the characters in it.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;output = subprocess.run(["file", "-i", str(movie_lines.path)], stdout=subprocess.PIPE)
print(output.stdout)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
b'/home/athena/data/datasets/cornell_movie_dialogs_corpus/movie_lines.txt: text/plain; charset=unknown-8bit\n'
&lt;/pre&gt;


&lt;p&gt;
It doesn't look like standard ASCII, but I wonder if it matters. In the pytorch tutorial they give the encoding as &lt;code&gt;iso-8859-1&lt;/code&gt;, although I can't find any documentation for this, but since they gave it, I guess we can use it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ENCODING&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"iso-8859-1"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
I'm using it in MovieLines too so I defined ENCODING at the top of the notebook, this is just to show where it came from.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orge609860" class="outline-3"&gt;
&lt;h3 id="orge609860"&gt;Conversations&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orge609860"&gt;
&lt;p&gt;
The movie-lines file has all the movie-conversations together, but we want conversations between characters. For that you need to group the lines using the &lt;code&gt;movie_conversations.txt&lt;/code&gt; file.
&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;movie_conversations.txt
&lt;ul class="org-ul"&gt;
&lt;li&gt;the structure of the conversations&lt;/li&gt;
&lt;li&gt;fields
&lt;ul class="org-ul"&gt;
&lt;li&gt;characterID of the first character involved in the conversation&lt;/li&gt;
&lt;li&gt;characterID of the second character involved in the conversation&lt;/li&gt;
&lt;li&gt;movieID of the movie in which the conversation occurred&lt;/li&gt;
&lt;li&gt;list of the utterances that make the conversation, in chronological 
order: ['lineID1','lineID2',É,'lineIDN']
has to be matched with movie_lines.txt to reconstruct the actual content&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;
You can see that the README has some kind of funky character in it (the third item in the &lt;code&gt;order&lt;/code&gt; list). Weird.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0bda173" class="outline-4"&gt;
&lt;h4 id="org0bda173"&gt;A Conversation Holder&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0bda173"&gt;
&lt;p&gt;
A &lt;i&gt;conversation&lt;/i&gt; is a list of lines said by characters to each other. Although the dialog file is presumably in order, we want to be able to partition lines that are part of a single conversation - a verbal interaction between two characters.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ConversationIDs = namedtuple("ConversationIDs", ["character_id_1",
						 "character_id_2",
						 "movie_id",
						 "lines"])
ConversationFields = ConversationIDs(
    **{field: index
       for index, field in enumerate(ConversationIDs._fields)})
ConversationData = List[ConversationIDs]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf8a138b" class="outline-4"&gt;
&lt;h4 id="orgf8a138b"&gt;A Conversations Builder&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf8a138b"&gt;
&lt;p&gt;
This is code to pull the lines out and group them by conversation.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Conversations:
    """Holds the conversations

    Args:
     path: path to the conversations file
     moviez: object with the movie lines
     encoding: the encoding for the file
     separator: the column separator
    """
    def __init__(self,
		 path: Path,
		 movies: MovieLines,
		 separator: str=" +++$+++ ",
		 encoding:str="UTF-8") -&amp;gt; None:
	self.path = path
	self.movies = movies
	self.separator = separator
	self.encoding = encoding
	self._conversations = None
	self._sentence_pairs = None
	return

    @property
    def conversations(self) -&amp;gt; ConversationData:
	"""The list of conversation line data
	"""
	if self._conversations is None:
	    self._conversations = []
	    with self.path.open(encoding=self.encoding) as reader:
		for line in reader:
		    tokens = line.strip().split(self.separator)
		    line_ids = eval(tokens[ConversationFields.lines])
		    lines = [self.movies.lines[line_id] for line_id in line_ids]
		    self._conversations.append(
			ConversationIDs(
			    character_id_1=tokens[ConversationFields.character_id_1],
			    character_id_2=tokens[ConversationFields.character_id_2],
			    movie_id=tokens[ConversationFields.movie_id],
			    lines = lines,
			))
	return self._conversations

    @property
    def sentence_pairs(self) -&amp;gt; list:
	"""paired-sentences from the conversations"""
	if self._sentence_pairs is None:
	    self._sentence_pairs = []
	    for conversation in self.conversations:
		for index in range(len(conversation.lines) - 1):
		    utterance = conversation.lines[index].text
		    response = conversation.lines[index + 1].text
		    # you might not always have pairs
		    if utterance and response:
			self._sentence_pairs.append([utterance, response])
	return self._sentence_pairs

    def head(self, count: int=5) -&amp;gt; None:
	"""Print the first lines

	Args:
	 count: how many lines to print
	"""
	with self.path.open(encoding=self.encoding) as reader:
	    so_far = 0
	    for line in reader:
		print(line.rstrip())
		so_far += 1
		if so_far &amp;gt;= count:
		    break
	return
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now I'll build the conversations from the file.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conversations_path = movie_data.data_path.joinpath(MovieFile.conversations)
conversations = Conversations(conversations_path, movie_lines, encoding=ENCODING)
conversations.head()
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6dfd332" class="outline-3"&gt;
&lt;h3 id="org6dfd332"&gt;Store the Processed Lines&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org6dfd332"&gt;
&lt;p&gt;
Since we've transformed the data we should store it to avoid needing to transform it again later.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with TIMER:
    processed_path = movie_data.data_path.joinpath("conversation_line_pairs.tsv")
    delimiter = str(codecs.decode("\t", "unicode_escape"))
    NEWLINE = "\n"
    with processed_path.open("w", encoding="utf-8") as outputfile:
	writer = csv.writer(outputfile, delimiter=delimiter)
	for pair in conversations.sentence_pairs:
	    writer.writerow(pair)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Started: 2019-02-18 18:44:01.624014
Ended: 2019-02-18 18:44:04.127445
Elapsed: 0:00:02.503431
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org9fdffc7" class="outline-3"&gt;
&lt;h3 id="org9fdffc7"&gt;Check Our Stored File&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9fdffc7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with processed_path.open() as reader:
    count = 0
    for line in reader:
	print(repr(line))
	count += 1
	if count == 5:
	    break
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\tWell, I thought we'd start with pronunciation, if that's okay with you.\n"
"Well, I thought we'd start with pronunciation, if that's okay with you.\tNot the hacking and gagging and spitting part.  Please.\n"
"Not the hacking and gagging and spitting part.  Please.\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n"
"You're asking me out.  That's so cute. What's your name again?\tForget it.\n"
"No, no, it's my fault -- we didn't have a proper introduction ---\tCameron.\n"
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org566bd75" class="outline-2"&gt;
&lt;h2 id="org566bd75"&gt;A Vocabulary&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org566bd75"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;PADDING, START_OF_SENTENCE, END_OF_SENTENCE = 0, 1, 2

class Vocabulary:
    """A class to hold words and sentences

    Args:
     name: name of the vocabulary
     token_delimiter: what to split sentences on
    """
    def __init__(self, name: str, token_delimiter: str=" ") -&amp;gt; None:
	self.name = name
	self.trimmed = False
	self.token_delimiter = token_delimiter
	self.word_to_index = {}
	self._word_to_count = None
	self._index_to_word = None
	return

    @property
    def word_to_count(self) -&amp;gt; defaultdict:
	"""map of word to word count"""
	if self._word_to_count is None:
	    self._word_to_count = defaultdict(lambda: 1)
	return self._word_to_count

    @property
    def index_to_word(self) -&amp;gt; dict:
	"""map of word-index back to the word"""
	if self._index_to_word is None:
	    self._index_to_word = dict(
		PADDING="PAD",
		START_OF_SENTENCE="SOS",
		END_OF_SENTENCE="EOS",
	    )
	return self._index_to_word

    @property
    def word_count(self) -&amp;gt; int:
	"""the number of words in our vocabulary"""
	return len(self.index_to_word)

    def add_sentence(self, sentence: str) -&amp;gt; None:
	"""Adds the words in the sentence to our dictionary

	Args:
	 sentence: string of words
	"""
	for word in sentence.split(self.token_delimiter):
	    self.add_word(word)
	return

    def add_word(self, word: str) -&amp;gt; None:
	"""add the word to our vocabulary

	Args:
	 word: word to add
	"""
	if word not in self.word_to_index:
	    self.word_to_index[word] = self.word_count
	    self.index_to_word[self.word_count] = word
	else:
	    self.word_to_count[word] += 1
	return

    def trim(self, minimum: int) -&amp;gt; None:
	"""Trim words below the minimum

	.. warning:: This will only work once, even if you change the
	  minimum. set self.trimmed to False if you want to do it again

	Args:
	 minimum: lowest acceptible count for a word
	"""
	if self.trimmed:
	    return
	self.trimmed = True
	keepers = []
	for word, count in self.word_to_count.items():
	    if count &amp;gt;= minimum:
		keepers.append(word)
	print("Keep: {}/{} = {:.2f}".format(len(keepers),
					    len(self.word_count),
					    len(keepers)/len(self.word_count)))
	self.reset()
	for word in keepers:
	    self.add_word(word)
	return

    def reset(self) -&amp;gt; None:
	"""Resets the dictionaries"""
	self.word_to_index = {}
	self._word_to_count = None
	self._index_to_word = None
	return
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2ca6d40" class="outline-2"&gt;
&lt;h2 id="org2ca6d40"&gt;Preparing the Data For Model-Training&lt;/h2&gt;
&lt;/div&gt;

&lt;div id="outline-container-org655cfbe" class="outline-2"&gt;
&lt;h2 id="org655cfbe"&gt;Related Repositories To Check Out&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org655cfbe"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a href="https://github.com/ywk991112/pytorch-chatbot"&gt;Formosa Speech Grand Challenge Chatbot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation"&gt;Practical Pytorch seq2seq translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus"&gt;Cornell Movie Corpus Pre-processor&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>rnn</category><category>text</category><category>tutorial</category><guid>https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html</guid><pubDate>Sun, 10 Feb 2019 23:02:29 GMT</pubDate></item></channel></rss>