<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Neurotic Networking (Posts about tutorial)</title><link>https://necromuralist.github.io/Neurotic-Networking/</link><description></description><atom:link href="https://necromuralist.github.io/Neurotic-Networking/categories/tutorial.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2023 &lt;a href="mailto:cloisteredmonkey.jmark@slmail.me"&gt;Cloistered Monkey&lt;/a&gt; 
&lt;div id="license"xmlns:cc="http://creativecommons.org/ns#" &gt;This work is licensed under
&lt;a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"&gt;CC BY 4.0
&lt;img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"&gt;
&lt;img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"&gt;&lt;/a&gt;
&lt;/div&gt;
</copyright><lastBuildDate>Sat, 01 Jul 2023 22:17:17 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Pytorch 60 Minute Blitz</title><link>https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents" role="doc-toc"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents" role="doc-toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#orgfb800dd"&gt;The Departure&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org9b71064"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org5f7b031"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org39bb12c"&gt;The Initiation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#orge97c51b"&gt;What is PyTorch?&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org7cda638"&gt;Tensors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org4fda2a2"&gt;Operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org7cfeea4"&gt;Torch to Numpy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org358cdfd"&gt;Numpy to Torch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org9193f46"&gt;Cuda&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org1b37282"&gt;Autograd: Automatic Differentiation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org46bec82"&gt;Backpropagation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org5d07abc"&gt;Context Manager&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org91be6d1"&gt;Neural Networks&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#orgc11282c"&gt;A Typical Model Training Procedure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org046b00c"&gt;Defining the Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org5362764"&gt;The Loss Function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org41c20be"&gt;Backpropagation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org5033c78"&gt;Update the Weights&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#orgf793aea"&gt;Training a Classifier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#orgcdf3424"&gt;Data Parallelism&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html#org80927e1"&gt;The Return&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfb800dd" class="outline-2"&gt;
&lt;h2 id="orgfb800dd"&gt;The Departure&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgfb800dd"&gt;
&lt;p&gt;
This is a replication of &lt;a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"&gt;Deep Learning With Pytorch: A 60 Minute Blitz&lt;/a&gt; to get me back into using &lt;a href="https://pytorch.org"&gt;PyTorch&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9b71064" class="outline-3"&gt;
&lt;h3 id="org9b71064"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9b71064"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5f7b031" class="outline-4"&gt;
&lt;h4 id="org5f7b031"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5f7b031"&gt;
&lt;p&gt;
Although the project is called PyTorch, the package is named &lt;code&gt;torch&lt;/code&gt;.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import torch
import torch.nn as neural_network
import torch.nn.functional as functional
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
And we're going to use numpy a little.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import numpy
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org39bb12c" class="outline-2"&gt;
&lt;h2 id="org39bb12c"&gt;The Initiation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org39bb12c"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge97c51b" class="outline-3"&gt;
&lt;h3 id="orge97c51b"&gt;What is PyTorch?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orge97c51b"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7cda638" class="outline-4"&gt;
&lt;h4 id="org7cda638"&gt;Tensors&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7cda638"&gt;
&lt;p&gt;
In PyTorch, &lt;a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"&gt;tensors&lt;/a&gt; are similar to numpy's &lt;a href="https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html"&gt;ndarrays&lt;/a&gt; (n-dimensional arrays). You can create an unitialized one using the &lt;code&gt;empty&lt;/code&gt; function.
&lt;/p&gt;
&lt;/div&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="org9920a5e"&gt;&lt;/a&gt;Empty&lt;br&gt;
&lt;div class="outline-text-5" id="text-org9920a5e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;empty_tensor = torch.empty(5, 3)
print(empty_tensor)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([[-2.3492e+02,  4.5902e-41, -2.3492e+02],
        [ 4.5902e-41,  3.1766e+30,  1.7035e+25],
        [ 4.0498e-43,  0.0000e+00, -2.3492e+02],
        [ 4.5902e-41,  2.6417e-37,  0.0000e+00],
        [ 1.4607e-19,  1.8469e+25,  1.0901e+27]])
&lt;/pre&gt;


&lt;p&gt;
Here's the docstring for &lt;code&gt;empty&lt;/code&gt;:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(torch.empty.__doc__)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example" id="org4141a09"&gt;

empty(*sizes, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -&amp;gt; Tensor

Returns a tensor filled with uninitialized data. The shape of the tensor is
defined by the variable argument :attr:`sizes`.

Args:
    sizes (int...): a sequence of integers defining the shape of the output tensor.
        Can be a variable number of arguments or a collection like a list or tuple.
    out (Tensor, optional): the output tensor
    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.
        Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).
    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.
        Default: ``torch.strided``.
    device (:class:`torch.device`, optional): the desired device of returned tensor.
        Default: if ``None``, uses the current device for the default tensor type
        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU
        for CPU tensor types and the current CUDA device for CUDA tensor types.
    requires_grad (bool, optional): If autograd should record operations on the
        returned tensor. Default: ``False``.

Example::

    &amp;gt;&amp;gt;&amp;gt; torch.empty(2, 3)
    tensor(1.00000e-08 *
           [[ 6.3984,  0.0000,  0.0000],
            [ 0.0000,  0.0000,  0.0000]])


&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="orgcd27731"&gt;&lt;/a&gt;Random&lt;br&gt;
&lt;div class="outline-text-5" id="text-orgcd27731"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(torch.rand(5, 3))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([[0.1767, 0.9520, 0.1488],
        [0.5592, 0.4836, 0.2645],
        [0.8066, 0.8864, 0.1083],
        [0.9206, 0.7311, 0.1278],
        [0.0140, 0.5370, 0.3123]])
&lt;/pre&gt;


&lt;p&gt;
The arguments are the same as for empty.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="org905422b"&gt;&lt;/a&gt;Zeros&lt;br&gt;
&lt;div class="outline-text-5" id="text-org905422b"&gt;
&lt;p&gt;
Here we'll create a tensor of zeros as long integers.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(torch.zeros(5, 3, dtype=torch.long))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
&lt;/pre&gt;


&lt;p&gt;
Once again the argument for &lt;code&gt;zeros&lt;/code&gt; is the same as those for &lt;code&gt;empty&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="org8e323d2"&gt;&lt;/a&gt;From Data&lt;br&gt;
&lt;div class="outline-text-5" id="text-org8e323d2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(torch.tensor([5.5, 3]))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([5.5000, 3.0000])
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="org768a07f"&gt;&lt;/a&gt;From A Tensor&lt;br&gt;
&lt;div class="outline-text-5" id="text-org768a07f"&gt;
&lt;p&gt;
You can create a new tensor from a previously constructed one. This preserves any parameters you passed in that you don't subsequently override.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x = torch.tensor([5, 3], dtype=torch.int)
print(x)
y = x.new_ones(5, 3)
print(y)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([5, 3], dtype=torch.int32)
tensor([[1, 1, 1],
        [1, 1, 1],
        [1, 1, 1],
        [1, 1, 1],
        [1, 1, 1]], dtype=torch.int32)
&lt;/pre&gt;


&lt;p&gt;
PyTorch also has another syntax for creating a random tensor from another tensor.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(torch.randn_like(x, dtype=torch.float))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([ 0.6447, -0.9750])
&lt;/pre&gt;


&lt;p&gt;
So in this case it kept the shape but used our dtype. The values seemed odd at first, but that's because the &lt;code&gt;randn&lt;/code&gt; indicates it comes from a standard-normal distribution centered at 0, not some value in the range from zero to one (non-inclusive) like a regular random function would.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="org1263f5b"&gt;&lt;/a&gt;Tensor Size&lt;br&gt;
&lt;div class="outline-text-5" id="text-org1263f5b"&gt;
&lt;p&gt;
Like pandas, the tensor has a shape, but confusingly it's called &lt;code&gt;Size&lt;/code&gt; and can be accessed either from the &lt;code&gt;size&lt;/code&gt; method of the &lt;code&gt;shape&lt;/code&gt; attribute.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(y.size())
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
torch.Size([5, 3])
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(y.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
torch.Size([5, 3])
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(torch.Size.__base__)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
&amp;lt;class 'tuple'&amp;gt;
&lt;/pre&gt;


&lt;p&gt;
The &lt;code&gt;Size&lt;/code&gt; object inherits from tuples and supports all the tuple operations.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4fda2a2" class="outline-4"&gt;
&lt;h4 id="org4fda2a2"&gt;Operations&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4fda2a2"&gt;
&lt;/div&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="org39e7730"&gt;&lt;/a&gt;Addition&lt;br&gt;
&lt;div class="outline-text-5" id="text-org39e7730"&gt;
&lt;p&gt;
For some operations you can use either the operators (like &lt;code&gt;+&lt;/code&gt;) or method calls. Here's two ways to do addition.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SIZE = (5, 3)
x = torch.rand(*SIZE)
y = torch.rand(*SIZE)
output = x + y
print(output)
print()
print(torch.add(x, y))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example" id="orgb68c3c7"&gt;
tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])

tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="org620bbde"&gt;&lt;/a&gt;Pre-Made Tensors&lt;br&gt;
&lt;div class="outline-text-5" id="text-org620bbde"&gt;
&lt;p&gt;
One advantage to using the function is that you can pass in a tensor, rather than having pytorch create the output-tensor for you.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;summation = torch.empty(SIZE)
torch.add(x, y, out=summation)
print(summation)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="org1cf3e47"&gt;&lt;/a&gt;In-Place Operations&lt;br&gt;
&lt;div class="outline-text-5" id="text-org1cf3e47"&gt;
&lt;p&gt;
Tensors also have methods that let you update them instead of creating a new tensor.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x.add_(y)
print(x)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="orgf6c59c8"&gt;&lt;/a&gt;Slicing&lt;br&gt;
&lt;div class="outline-text-5" id="text-orgf6c59c8"&gt;
&lt;p&gt;
The slicing follows what numpy's arrays do. Here's how to get all the rows of the second column.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x[:, 1])
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([1.4905, 0.9883, 0.6291, 1.1548, 0.9954])
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="org2d20b8f"&gt;&lt;/a&gt;Reshaping&lt;br&gt;
&lt;div class="outline-text-5" id="text-org2d20b8f"&gt;
&lt;p&gt;
You can create a new tensor with the same data but a different shape using the &lt;a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view"&gt;view&lt;/a&gt; method.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;y = x.view(15)
z = x.view(-1, 5)
print(x.shape)
print(y.shape)
print(z.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
torch.Size([5, 3])
torch.Size([15])
torch.Size([3, 5])
&lt;/pre&gt;


&lt;p&gt;
Using &lt;code&gt;-1&lt;/code&gt; tells pytorch to infer the dimension based on the original and the dimension that you did pass in.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7cfeea4" class="outline-4"&gt;
&lt;h4 id="org7cfeea4"&gt;Torch to Numpy&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7cfeea4"&gt;
&lt;p&gt;
While there are advantages to using torch for operations (it can use the GPU, for instance), there might be times when you want to convert the tensor to a numpy array.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x = torch.zeros(5)
print(x)
y = x.numpy()
print(y)
x.add_(1)
print(x)
print(y)
print(type(y))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([0., 0., 0., 0., 0.])
[0. 0. 0. 0. 0.]
tensor([1., 1., 1., 1., 1.])
[1. 1. 1. 1. 1.]
&amp;lt;class 'numpy.ndarray'&amp;gt;
&lt;/pre&gt;


&lt;p&gt;
Somehow updating the tensor in place updates the numpy array as well, even though it's an ndarray.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org358cdfd" class="outline-4"&gt;
&lt;h4 id="org358cdfd"&gt;Numpy to Torch&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org358cdfd"&gt;
&lt;p&gt;
You can go the other way as well.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x = numpy.zeros(5)
print(x)
y = torch.from_numpy(x)
print(y)
x += 5
print(y)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[0. 0. 0. 0. 0.]
tensor([0., 0., 0., 0., 0.], dtype=torch.float64)
tensor([5., 5., 5., 5., 5.], dtype=torch.float64)
&lt;/pre&gt;


&lt;p&gt;
So updating the array (in place) updates the tensor.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org9193f46" class="outline-4"&gt;
&lt;h4 id="org9193f46"&gt;Cuda&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org9193f46"&gt;
&lt;p&gt;
As I mentioned before, an advantage of pytorch tensors is that they can be run on the GPU - unfortunately the computer I'm on is old and CUDA doesn't run on it, but we can make a check to see if it will first using =torch.cuda.is_available()
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
print(device)

x = torch.ones(5)

# pass in the device
y = torch.ones_like(x, device=device)

# or move the tensor to the device (not an inplace operation)
x = x.to(device)

z = x + y
print(z)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1b37282" class="outline-3"&gt;
&lt;h3 id="org1b37282"&gt;Autograd: Automatic Differentiation&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1b37282"&gt;
&lt;p&gt;
The &lt;a href="https://pytorch.org/docs/stable/autograd.html"&gt;autograd&lt;/a&gt; module in pytorch performs automatic differentiation for you. It works using &lt;i&gt;define-by-run&lt;/i&gt;, meaning that as you run you forward-pass through the network, it tracks your calls so you don't have to explicitly define anything for backpropagation to work. To enable or disable it you set the &lt;code&gt;requires_grad&lt;/code&gt; attribute of the tensor you want to train.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tense = torch.ones(2, 2, requires_grad=True)
print(tense)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([[1., 1.],
        [1., 1.]], requires_grad=True)
&lt;/pre&gt;


&lt;p&gt;
Now if you do a tensor operation:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tensed = tense + 1
print(tensed)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([[2., 2.],
        [2., 2.]], grad_fn=&amp;lt;AddBackward0&amp;gt;)
&lt;/pre&gt;


&lt;p&gt;
Our new tensor has a gradient function set for it. If you do more operations on &lt;code&gt;tensed&lt;/code&gt;:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tenser = tensed * 5
print(tenser)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([[10., 10.],
        [10., 10.]], grad_fn=&amp;lt;MulBackward0&amp;gt;)
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;a = torch.ones(5, requires_grad=False)
b = a * 5
a.requires_grad_(True)
c = a * 6
print(b)
print(c)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([5., 5., 5., 5., 5.])
tensor([6., 6., 6., 6., 6.], grad_fn=&amp;lt;MulBackward0&amp;gt;)
&lt;/pre&gt;


&lt;p&gt;
Two things to note, one is that the gradient function is only set while the &lt;code&gt;requires_grad&lt;/code&gt; attribute is true, the other is that this only works on the leafs in the graph - you can set it on &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; but not &lt;code&gt;c&lt;/code&gt; - because since I set &lt;code&gt;requires_grad&lt;/code&gt; to True on &lt;code&gt;a&lt;/code&gt;, when I created &lt;code&gt;c&lt;/code&gt; by multiplying &lt;code&gt;a&lt;/code&gt; by 6, &lt;code&gt;c&lt;/code&gt; became part of &lt;code&gt;a&lt;/code&gt;'s graph… I think. Anyway, you can't set it on tensors that are part of the backpropagation path.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org46bec82" class="outline-4"&gt;
&lt;h4 id="org46bec82"&gt;Backpropagation&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org46bec82"&gt;
&lt;p&gt;
You run back-propagation by calling the &lt;a href="https://pytorch.org/docs/stable/autograd.html#torch.Tensor.backward"&gt;&lt;code&gt;backward&lt;/code&gt;&lt;/a&gt; method on the last tensor in the graph. In our case the last tensor we have (&lt;code&gt;tenser&lt;/code&gt;) doesn't output numbers so we need to create a final tensor that does for back-propagation to work.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;output = tenser.mean()
output.backward()
print(tense.grad)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([[1.2500, 1.2500],
        [1.2500, 1.2500]])
&lt;/pre&gt;


&lt;p&gt;
After one pass through the network (and back) our root-node tensor has some gradients.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5d07abc" class="outline-4"&gt;
&lt;h4 id="org5d07abc"&gt;Context Manager&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5d07abc"&gt;
&lt;p&gt;
If you need to temporarily turn the gradient tracking on or off you can use a context manager.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print((tense*2).requires_grad)
with torch.no_grad():
    print((tense* 2).requires_grad)
print((tense * 2).requires_grad)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
True
False
True
&lt;/pre&gt;


&lt;p&gt;
Note that the root-will still have &lt;code&gt;require_grad&lt;/code&gt; as true, it's the output of operations working with it that don't get the gradient set.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(tense.requires_grad)
with torch.no_grad():
    print(tense.requires_grad)
print(tense.requires_grad)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
True
True
True
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org91be6d1" class="outline-3"&gt;
&lt;h3 id="org91be6d1"&gt;Neural Networks&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org91be6d1"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc11282c" class="outline-4"&gt;
&lt;h4 id="orgc11282c"&gt;A Typical Model Training Procedure&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc11282c"&gt;
&lt;ol class="org-ol"&gt;
&lt;li&gt;Define the neural network&lt;/li&gt;
&lt;li&gt;Iterate over a dataset of inputs&lt;/li&gt;
&lt;li&gt;Process each input through the network&lt;/li&gt;
&lt;li&gt;Compute the loss (how much error there is)&lt;/li&gt;
&lt;li&gt;Update the weights of the network&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;
The most common way to update the weights is to use a simple formula.
\[
weight = weight - textit{learning rate} \times gradient
\]
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org046b00c" class="outline-4"&gt;
&lt;h4 id="org046b00c"&gt;Defining the Network&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org046b00c"&gt;
&lt;p&gt;
This will be a network with five layers - two &lt;a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Convolutional_layer"&gt;convolutional layers&lt;/a&gt; followed by three &lt;a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Fully_connected_layer"&gt;fully-connected layers&lt;/a&gt;. For the convolutional layers we're going to use &lt;a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer"&gt;Max-Pooling&lt;/a&gt; and for the fully-connected layers we'll use &lt;a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#ReLU_layer"&gt;ReLU&lt;/a&gt; activation.
&lt;/p&gt;
&lt;/div&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="org7dfc909"&gt;&lt;/a&gt;The Layers&lt;br&gt;
&lt;div class="outline-text-5" id="text-org7dfc909"&gt;
&lt;p&gt;
You can just create the layers in the constructor, but since I'm trying to re-learn what's going on I'm going to peel it apart a little more.
&lt;/p&gt;

&lt;p&gt;
The first layer is the input layer, so the &lt;code&gt;inputs&lt;/code&gt; have to match whatever data you are going to get. In our case we are going to look at a black and white image so it has one input-channel. The three required arguments to the 
&lt;a href="https://pytorch.org/docs/stable/nn.html#convolution-layers"&gt;Conv2d&lt;/a&gt; constructor are:
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;code&gt;in_channels&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;out_channels&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kernel_size&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class LayerOne:
    inputs = 1
    outputs = 6
    convolution_size = 5
    layer = neural_network.Conv2d(inputs, outputs, convolution_size)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class LayerTwo:
    inputs = LayerOne.outputs
    outputs = 16
    convolution_size = 5
    layer = neural_network.Conv2d(inputs, outputs, convolution_size)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
Layer Three is the first &lt;a href="https://pytorch.org/docs/stable/nn.html#linear"&gt;Linear&lt;/a&gt; layer. Linear layers do a linear transformation on the inputs.
&lt;/p&gt;

&lt;p&gt;
\[
y = x W^T + b
\]
&lt;/p&gt;

&lt;p&gt;
Where &lt;i&gt;x&lt;/i&gt; is the input, &lt;i&gt;W&lt;/i&gt; is the weight matrix and &lt;i&gt;b&lt;/i&gt; is a bias constant.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class LayerThree:
    inputs = (LayerTwo.outputs * LayerOne.convolution_size 
	      * LayerTwo.convolution_size)
    outputs = 120
    layer = neural_network.Linear(inputs, outputs)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class LayerFour:
    inputs = LayerThree.outputs
    outputs = 84
    layer = neural_network.Linear(inputs, outputs)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This is the last layer so the outputs are the outputs for the model as a whole.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class LayerFive:
    inputs = LayerFour.outputs
    outputs = 10
    layer = neural_network.Linear(inputs, outputs)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
For the forward-pass our convolutional layers will have their output pooled using &lt;a href="https://pytorch.org/docs/stable/nn.html#torch.nn.functional.max_pool2d"&gt;max_pool2d&lt;/a&gt; and all the layers (except for the output layers) will use &lt;a href="https://pytorch.org/docs/stable/nn.html#torch.nn.functional.relu"&gt;relu&lt;/a&gt; as the activation function to keep the model from being linear.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class NeuralNetwork(neural_network.Module):
    """A five-layer Convolutional Neural Network"""
    def __init__(self):
	super().__init__()
	self.layer_one = LayerOne.layer
	self.layer_two = LayerTwo.layer
	self.layer_three = LayerThree.layer
	self.layer_four = LayerFour.layer
	self.layer_five = LayerFive.layer
	return

    def flattened_features_counts(self, x):
	sizes = x.size()[1:]
	features = 1
	for size in sizes:
	    features *= size
	return features

    def forward(self, x):
	"""One forward pass through the network

	Args:
	 x: a one-channel image

	Returns:
	 a ten-output linear layer
	"""
	x = functional.max_pool2d(functional.relu(self.layer_one(x)), (2, 2))
	x = functional.max_pool2d(functional.relu(self.layer_two(x)), 2)
	x = x.view(-1, self.flattened_features_counts(x))
	x = functional.relu(self.layer_three(x))
	x = functional.relu(self.layer_four(x))
	return self.layer_five(x)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = NeuralNetwork()
print(model)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
NeuralNetwork(
  (layer_one): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
  (layer_two): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (layer_three): Linear(in_features=400, out_features=120, bias=True)
  (layer_four): Linear(in_features=120, out_features=84, bias=True)
  (layer_five): Linear(in_features=84, out_features=10, bias=True)
)
&lt;/pre&gt;


&lt;p&gt;
The output shows the parameters for each layer in our model.
&lt;/p&gt;

&lt;p&gt;
A sample output.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;INPUT_SIZE = 32
mock_image = torch.randn(1, 1, INPUT_SIZE, INPUT_SIZE)
output = model(mock_image)
print(output)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([[ 0.1163,  0.0882,  0.0529,  0.0546, -0.0196, -0.1215, -0.1736,  0.0659,
          0.0762, -0.0093]], grad_fn=&amp;lt;AddmmBackward&amp;gt;)
&lt;/pre&gt;


&lt;p&gt;
This is the output after one forward pass. Unfortunately we didn't want to train it on fake data so we should reset it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model.zero_grad()
output.backward(torch.randn(1, 10))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5362764" class="outline-4"&gt;
&lt;h4 id="org5362764"&gt;The Loss Function&lt;/h4&gt;
&lt;/div&gt;
&lt;div id="outline-container-org41c20be" class="outline-4"&gt;
&lt;h4 id="org41c20be"&gt;Backpropagation&lt;/h4&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5033c78" class="outline-4"&gt;
&lt;h4 id="org5033c78"&gt;Update the Weights&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf793aea" class="outline-3"&gt;
&lt;h3 id="orgf793aea"&gt;Training a Classifier&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcdf3424" class="outline-3"&gt;
&lt;h3 id="orgcdf3424"&gt;Data Parallelism&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org80927e1" class="outline-2"&gt;
&lt;h2 id="org80927e1"&gt;The Return&lt;/h2&gt;
&lt;/div&gt;</description><category>pytorch</category><category>tutorial</category><guid>https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/index.html</guid><pubDate>Wed, 03 Apr 2019 19:36:06 GMT</pubDate></item><item><title>Chatbot Tutorial</title><link>https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents" role="doc-toc"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents" role="doc-toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org96dd2fb"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#orgfd8093d"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org963cf4f"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org3ccf55d"&gt;Setup the Timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#orgb9469cd"&gt;Load Dotenv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org4856d11"&gt;Check CUDA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org3be41d6"&gt;Some Type Hints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org64d6872"&gt;Some Constants&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org9734d51"&gt;The Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org7574e41"&gt;Download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org78bffc1"&gt;Movie Lines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#orge609860"&gt;Conversations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org6dfd332"&gt;Store the Processed Lines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org9fdffc7"&gt;Check Our Stored File&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org566bd75"&gt;A Vocabulary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org2ca6d40"&gt;Preparing the Data For Model-Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html#org655cfbe"&gt;Related Repositories To Check Out&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org96dd2fb" class="outline-2"&gt;
&lt;h2 id="org96dd2fb"&gt;Introduction&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org96dd2fb"&gt;
&lt;p&gt;
This is a walk-through the &lt;a href="https://pytorch.org/tutorials/beginner/chatbot_tutorial.html"&gt;pytorch Chatbot Tutorial&lt;/a&gt; which builds a chatbot using a recurrent Sequence-to-Sequence model trained on the &lt;a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html"&gt;Cornell Movie-Dialogs Corpus&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfd8093d" class="outline-2"&gt;
&lt;h2 id="orgfd8093d"&gt;Set Up&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgfd8093d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org963cf4f" class="outline-3"&gt;
&lt;h3 id="org963cf4f"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org963cf4f"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcdfb643" class="outline-4"&gt;
&lt;h4 id="orgcdfb643"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgcdfb643"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from collections import defaultdict, namedtuple
import codecs
from pathlib import Path
from typing import Dict, List, Union
from zipfile import ZipFile
import csv
import os
import subprocess
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb848980" class="outline-4"&gt;
&lt;h4 id="orgb848980"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgb848980"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from dotenv import load_dotenv
import requests
import torch
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5462749" class="outline-4"&gt;
&lt;h4 id="org5462749"&gt;This Project&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5462749"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from neurotic.tangles.timer import Timer
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3ccf55d" class="outline-3"&gt;
&lt;h3 id="org3ccf55d"&gt;Setup the Timer&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3ccf55d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb9469cd" class="outline-3"&gt;
&lt;h3 id="orgb9469cd"&gt;Load Dotenv&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb9469cd"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;load_dotenv("../../.env")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4856d11" class="outline-3"&gt;
&lt;h3 id="org4856d11"&gt;Check CUDA&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4856d11"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using {}".format(device))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Using cuda
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3be41d6" class="outline-3"&gt;
&lt;h3 id="org3be41d6"&gt;Some Type Hints&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3be41d6"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;OptionalList = Union[list, None]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org64d6872" class="outline-3"&gt;
&lt;h3 id="org64d6872"&gt;Some Constants&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org64d6872"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ENCODING = "iso-8859-1"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9734d51" class="outline-2"&gt;
&lt;h2 id="org9734d51"&gt;The Data&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9734d51"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7574e41" class="outline-3"&gt;
&lt;h3 id="org7574e41"&gt;Download&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7574e41"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class MovieData:
    """Dowload and ready the movie data
    Args:
     download_path: Path to the folder to store the data
     url: download url for the zip file
     chunk_size: bytes to read from stream during download
     clean_up: remove the extra downloaded files
    """
    def __init__(self,
		 download_path: Path,
		 url: str=("http://www.cs.cornell.edu/~cristian/data/"
			   "cornell_movie_dialogs_corpus.zip"),
		 chunk_size=1024,
		 clean_up: bool=True) -&amp;gt; None:
	self.download_path = download_path
	self.url = url
	self.chunk_size = chunk_size
	self.clean_up = clean_up
	self._zip_path = None
	self._data_path = None
	self._zip_file = None
	return

    @property
    def zip_path(self) -&amp;gt; Path:
	"""Path to the downloaded zip file"""
	if self._zip_path is None:
	    self._zip_path = self.download_path.joinpath(Path(self.url).name)
	return self._zip_path

    @property
    def data_path(self) -&amp;gt; Path:
	"""Path to the unzipped file"""
	if self._data_path is None:
	    self._data_path = self.download_path.joinpath(
		Path(self.zip_path).stem)
	return self._data_path

    @property
    def zip_file(self) -&amp;gt; ZipFile:
	"""the Zip file for the zipped data"""
	if self._zip_file is None:
	    self._zip_file = ZipFile(self.zip_path)
	return self._zip_file

    def clean(self) -&amp;gt; None:
	"""remove the extra downloaded files"""
	os.remove(self.zip_path)
	return

    def __call__(self) -&amp;gt; None:
	"""downloads and prepares the file if needed"""
	if not self.data_path.is_dir():
	    if not self.zip_path.is_file():
		response = requests.get(self.url, stream=True)
		with self.zip_path.open("wb") as writer:
		    for chunk in response.iter_content(chunk_size=self.chunk_size):
			if chunk:
			    writer.write(chunk)
	    unpacked = []
	    for name in self.zip_file.namelist():
		name = Path(name)
		# there's extra folders and hidden files in there that I'll avoid
		if name.suffix in (".pdf", ".txt") and not name.name.startswith("."):
		    self.zip_file.extract(str(name), path=self.data_path)
		    unpacked.append(name)
	    assert self.data_path.is_dir()
	    if self.clean_up:
		# there is a sub-folder in the unzipped folder so move the
		# the files up one
		for to_move in unpacked:
		    self.data_path.joinpath(to_move).rename(
			self.data_path.joinpath(to_move.name))

		# now delete the temporary file
		os.remove(self.zip_path)
		if unpacked:
		    # now remove the sub-folder
		    self.data_path.joinpath(unpacked[0].parent).rmdir()
	return
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now let's download and unpack the data.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;datasets = Path(os.environ.get("DATASETS")).expanduser()
assert datasets.is_dir()
movie_data = MovieData(datasets, clean_up=True)
movie_data()
for name in movie_data.data_path.iterdir():
    print(" - {}".format(name.name))
&lt;/pre&gt;&lt;/div&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;chameleons.pdf&lt;/li&gt;
&lt;li&gt;conversation_line_pairs.tsv&lt;/li&gt;
&lt;li&gt;movie_conversations.txt&lt;/li&gt;
&lt;li&gt;movie_characters_metadata.txt&lt;/li&gt;
&lt;li&gt;movie_lines.txt&lt;/li&gt;
&lt;li&gt;movie_titles_metadata.txt&lt;/li&gt;
&lt;li&gt;raw_script_urls.txt&lt;/li&gt;
&lt;li&gt;README.txt&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class MovieFile:
    urls = "raw_script_urls.txt"
    readme = "README.txt"
    lines = "movie_lines.txt"
    characters = "movie_characters_metadata.txt"
    conversations = "movie_conversations.txt"
    titles = "movie_titles_metadata.txt"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org78bffc1" class="outline-3"&gt;
&lt;h3 id="org78bffc1"&gt;Movie Lines&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org78bffc1"&gt;
&lt;p&gt;
Here's an excerpt from the &lt;code&gt;README.txt&lt;/code&gt; file:
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
In all files the field separator is " &lt;del&gt;&lt;del&gt;&lt;del&gt;$&lt;/del&gt;&lt;/del&gt;&lt;/del&gt; "
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;movie_lines.txt
&lt;ul class="org-ul"&gt;
&lt;li&gt;contains the actual text of each utterance&lt;/li&gt;
&lt;li&gt;fields:
&lt;ul class="org-ul"&gt;
&lt;li&gt;lineID&lt;/li&gt;
&lt;li&gt;characterID (who uttered this phrase)&lt;/li&gt;
&lt;li&gt;movieID&lt;/li&gt;
&lt;li&gt;character name&lt;/li&gt;
&lt;li&gt;text of the utterance&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd33661e" class="outline-4"&gt;
&lt;h4 id="orgd33661e"&gt;Movie Line Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd33661e"&gt;
&lt;p&gt;
To load the lines I'm going to make a &lt;a href="https://docs.python.org/3.6/library/collections.html#collections.namedtuple"&gt;namedtuple&lt;/a&gt;.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;MovieLine = namedtuple("MovieLine", ["line_id",
				     "character_id",
				     "movie_id",
				     "character_name",
				     "text"])

LineData = Dict[str, MovieLine]
LineFields = MovieLine(**{field: index
			  for index, field in enumerate(MovieLine._fields)})
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5567457" class="outline-4"&gt;
&lt;h4 id="org5567457"&gt;A Line Loader&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5567457"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class MovieLines:
    """loads the movie dialog lines

    Args:
     path: path to the source file
     separator: column-separator
     encoding: the file encoding type (e.g. UTF-8)
    """
    def __init__(self, path: Path, separator: str=" +++$+++ ",
		 encoding="UTF-8") -&amp;gt; None:
	self.path = path
	self.separator = separator
	self.encoding = encoding
	self._lines = None
	return

    @property
    def lines(self) -&amp;gt; LineData:
	"""Dictionary Of Lines in the Data"""
	if self._lines is None:
	    self._lines = {}
	    with self.path.open(encoding=self.encoding) as reader:
		for line in reader:
		    tokens = line.strip().split(self.separator)

		    text = tokens[LineFields.text] if len(tokens) == len(LineFields) else ""
		    movie_line = MovieLine(line_id=tokens[LineFields.line_id],
					   character_id=tokens[LineFields.character_id],
					   movie_id=tokens[LineFields.movie_id],
					   character_name=tokens[LineFields.character_name],
					   text=text,
		    )
		    self._lines[movie_line.line_id] = movie_line
	return self._lines

    def head(self, lines: int=5, get: bool=False) -&amp;gt; OptionalList:
	"""show the first lines

	Args:
	 lines: number of lines to read
	 get: if true, return the lines
	"""
	output = [] if get else None
	with self.path.open() as reader:
	    for index, line in enumerate(reader):
		line = line.rstrip()
		print(line)
		if get:
		    output.append(line)
		if index + 1 &amp;gt;= lines:
		    break
	return output
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;movie_lines = MovieLines(movie_data.data_path.joinpath(MovieFile.lines), encoding=ENCODING)
output_lines = movie_lines.head(10)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example" id="orgc21bcc2"&gt;
L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!
L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!
L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.
L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?
L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.
L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow
L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.
L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No
L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this "persona"?  And you don't know how to quit?
L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?
&lt;/pre&gt;


&lt;p&gt;
As note in the &lt;code&gt;README.txt&lt;/code&gt; those strange characters are how the columns are separated (I guess so that the commas could be kept in the text). The Line IDs seem to be in reverse oredr, and don't seem to have all the lines - unless they're out of order and just looking at the head is misleading. For reference the movie for the lines I showed (the dialog between Bianca and Cameron) is from &lt;a href="https://www.imdb.com/title/tt0147800/"&gt;12 Things I Hate About You&lt;/a&gt;. For some reason they both encode the chraracters and give their names - &lt;code&gt;u0&lt;/code&gt; is &lt;code&gt;BIANCA&lt;/code&gt;.
&lt;/p&gt;

&lt;p&gt;
If you poke around in the file you'll find that there's something peculiar about the characters in it.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;output = subprocess.run(["file", "-i", str(movie_lines.path)], stdout=subprocess.PIPE)
print(output.stdout)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
b'/home/athena/data/datasets/cornell_movie_dialogs_corpus/movie_lines.txt: text/plain; charset=unknown-8bit\n'
&lt;/pre&gt;


&lt;p&gt;
It doesn't look like standard ASCII, but I wonder if it matters. In the pytorch tutorial they give the encoding as &lt;code&gt;iso-8859-1&lt;/code&gt;, although I can't find any documentation for this, but since they gave it, I guess we can use it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ENCODING&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"iso-8859-1"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
I'm using it in MovieLines too so I defined ENCODING at the top of the notebook, this is just to show where it came from.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orge609860" class="outline-3"&gt;
&lt;h3 id="orge609860"&gt;Conversations&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orge609860"&gt;
&lt;p&gt;
The movie-lines file has all the movie-conversations together, but we want conversations between characters. For that you need to group the lines using the &lt;code&gt;movie_conversations.txt&lt;/code&gt; file.
&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;movie_conversations.txt
&lt;ul class="org-ul"&gt;
&lt;li&gt;the structure of the conversations&lt;/li&gt;
&lt;li&gt;fields
&lt;ul class="org-ul"&gt;
&lt;li&gt;characterID of the first character involved in the conversation&lt;/li&gt;
&lt;li&gt;characterID of the second character involved in the conversation&lt;/li&gt;
&lt;li&gt;movieID of the movie in which the conversation occurred&lt;/li&gt;
&lt;li&gt;list of the utterances that make the conversation, in chronological 
order: ['lineID1','lineID2',É,'lineIDN']
has to be matched with movie_lines.txt to reconstruct the actual content&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;
You can see that the README has some kind of funky character in it (the third item in the &lt;code&gt;order&lt;/code&gt; list). Weird.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0bda173" class="outline-4"&gt;
&lt;h4 id="org0bda173"&gt;A Conversation Holder&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0bda173"&gt;
&lt;p&gt;
A &lt;i&gt;conversation&lt;/i&gt; is a list of lines said by characters to each other. Although the dialog file is presumably in order, we want to be able to partition lines that are part of a single conversation - a verbal interaction between two characters.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ConversationIDs = namedtuple("ConversationIDs", ["character_id_1",
						 "character_id_2",
						 "movie_id",
						 "lines"])
ConversationFields = ConversationIDs(
    **{field: index
       for index, field in enumerate(ConversationIDs._fields)})
ConversationData = List[ConversationIDs]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf8a138b" class="outline-4"&gt;
&lt;h4 id="orgf8a138b"&gt;A Conversations Builder&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf8a138b"&gt;
&lt;p&gt;
This is code to pull the lines out and group them by conversation.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Conversations:
    """Holds the conversations

    Args:
     path: path to the conversations file
     moviez: object with the movie lines
     encoding: the encoding for the file
     separator: the column separator
    """
    def __init__(self,
		 path: Path,
		 movies: MovieLines,
		 separator: str=" +++$+++ ",
		 encoding:str="UTF-8") -&amp;gt; None:
	self.path = path
	self.movies = movies
	self.separator = separator
	self.encoding = encoding
	self._conversations = None
	self._sentence_pairs = None
	return

    @property
    def conversations(self) -&amp;gt; ConversationData:
	"""The list of conversation line data
	"""
	if self._conversations is None:
	    self._conversations = []
	    with self.path.open(encoding=self.encoding) as reader:
		for line in reader:
		    tokens = line.strip().split(self.separator)
		    line_ids = eval(tokens[ConversationFields.lines])
		    lines = [self.movies.lines[line_id] for line_id in line_ids]
		    self._conversations.append(
			ConversationIDs(
			    character_id_1=tokens[ConversationFields.character_id_1],
			    character_id_2=tokens[ConversationFields.character_id_2],
			    movie_id=tokens[ConversationFields.movie_id],
			    lines = lines,
			))
	return self._conversations

    @property
    def sentence_pairs(self) -&amp;gt; list:
	"""paired-sentences from the conversations"""
	if self._sentence_pairs is None:
	    self._sentence_pairs = []
	    for conversation in self.conversations:
		for index in range(len(conversation.lines) - 1):
		    utterance = conversation.lines[index].text
		    response = conversation.lines[index + 1].text
		    # you might not always have pairs
		    if utterance and response:
			self._sentence_pairs.append([utterance, response])
	return self._sentence_pairs

    def head(self, count: int=5) -&amp;gt; None:
	"""Print the first lines

	Args:
	 count: how many lines to print
	"""
	with self.path.open(encoding=self.encoding) as reader:
	    so_far = 0
	    for line in reader:
		print(line.rstrip())
		so_far += 1
		if so_far &amp;gt;= count:
		    break
	return
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now I'll build the conversations from the file.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conversations_path = movie_data.data_path.joinpath(MovieFile.conversations)
conversations = Conversations(conversations_path, movie_lines, encoding=ENCODING)
conversations.head()
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6dfd332" class="outline-3"&gt;
&lt;h3 id="org6dfd332"&gt;Store the Processed Lines&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org6dfd332"&gt;
&lt;p&gt;
Since we've transformed the data we should store it to avoid needing to transform it again later.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with TIMER:
    processed_path = movie_data.data_path.joinpath("conversation_line_pairs.tsv")
    delimiter = str(codecs.decode("\t", "unicode_escape"))
    NEWLINE = "\n"
    with processed_path.open("w", encoding="utf-8") as outputfile:
	writer = csv.writer(outputfile, delimiter=delimiter)
	for pair in conversations.sentence_pairs:
	    writer.writerow(pair)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Started: 2019-02-18 18:44:01.624014
Ended: 2019-02-18 18:44:04.127445
Elapsed: 0:00:02.503431
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org9fdffc7" class="outline-3"&gt;
&lt;h3 id="org9fdffc7"&gt;Check Our Stored File&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9fdffc7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with processed_path.open() as reader:
    count = 0
    for line in reader:
	print(repr(line))
	count += 1
	if count == 5:
	    break
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\tWell, I thought we'd start with pronunciation, if that's okay with you.\n"
"Well, I thought we'd start with pronunciation, if that's okay with you.\tNot the hacking and gagging and spitting part.  Please.\n"
"Not the hacking and gagging and spitting part.  Please.\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n"
"You're asking me out.  That's so cute. What's your name again?\tForget it.\n"
"No, no, it's my fault -- we didn't have a proper introduction ---\tCameron.\n"
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org566bd75" class="outline-2"&gt;
&lt;h2 id="org566bd75"&gt;A Vocabulary&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org566bd75"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;PADDING, START_OF_SENTENCE, END_OF_SENTENCE = 0, 1, 2

class Vocabulary:
    """A class to hold words and sentences

    Args:
     name: name of the vocabulary
     token_delimiter: what to split sentences on
    """
    def __init__(self, name: str, token_delimiter: str=" ") -&amp;gt; None:
	self.name = name
	self.trimmed = False
	self.token_delimiter = token_delimiter
	self.word_to_index = {}
	self._word_to_count = None
	self._index_to_word = None
	return

    @property
    def word_to_count(self) -&amp;gt; defaultdict:
	"""map of word to word count"""
	if self._word_to_count is None:
	    self._word_to_count = defaultdict(lambda: 1)
	return self._word_to_count

    @property
    def index_to_word(self) -&amp;gt; dict:
	"""map of word-index back to the word"""
	if self._index_to_word is None:
	    self._index_to_word = dict(
		PADDING="PAD",
		START_OF_SENTENCE="SOS",
		END_OF_SENTENCE="EOS",
	    )
	return self._index_to_word

    @property
    def word_count(self) -&amp;gt; int:
	"""the number of words in our vocabulary"""
	return len(self.index_to_word)

    def add_sentence(self, sentence: str) -&amp;gt; None:
	"""Adds the words in the sentence to our dictionary

	Args:
	 sentence: string of words
	"""
	for word in sentence.split(self.token_delimiter):
	    self.add_word(word)
	return

    def add_word(self, word: str) -&amp;gt; None:
	"""add the word to our vocabulary

	Args:
	 word: word to add
	"""
	if word not in self.word_to_index:
	    self.word_to_index[word] = self.word_count
	    self.index_to_word[self.word_count] = word
	else:
	    self.word_to_count[word] += 1
	return

    def trim(self, minimum: int) -&amp;gt; None:
	"""Trim words below the minimum

	.. warning:: This will only work once, even if you change the
	  minimum. set self.trimmed to False if you want to do it again

	Args:
	 minimum: lowest acceptible count for a word
	"""
	if self.trimmed:
	    return
	self.trimmed = True
	keepers = []
	for word, count in self.word_to_count.items():
	    if count &amp;gt;= minimum:
		keepers.append(word)
	print("Keep: {}/{} = {:.2f}".format(len(keepers),
					    len(self.word_count),
					    len(keepers)/len(self.word_count)))
	self.reset()
	for word in keepers:
	    self.add_word(word)
	return

    def reset(self) -&amp;gt; None:
	"""Resets the dictionaries"""
	self.word_to_index = {}
	self._word_to_count = None
	self._index_to_word = None
	return
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2ca6d40" class="outline-2"&gt;
&lt;h2 id="org2ca6d40"&gt;Preparing the Data For Model-Training&lt;/h2&gt;
&lt;/div&gt;

&lt;div id="outline-container-org655cfbe" class="outline-2"&gt;
&lt;h2 id="org655cfbe"&gt;Related Repositories To Check Out&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org655cfbe"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a href="https://github.com/ywk991112/pytorch-chatbot"&gt;Formosa Speech Grand Challenge Chatbot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation"&gt;Practical Pytorch seq2seq translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus"&gt;Cornell Movie Corpus Pre-processor&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>rnn</category><category>text</category><category>tutorial</category><guid>https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/text/chatbot-tutorial/index.html</guid><pubDate>Sun, 10 Feb 2019 23:02:29 GMT</pubDate></item></channel></rss>