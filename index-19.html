<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Studies in Deep Learning." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Neurotic Networking (old posts, page 19) | Neurotic Networking</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/index-19.html" rel="canonical">
<link href="index-20.html" rel="prev" type="text/html">
<link href="index-18.html" rel="next" type="text/html"><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
<link href="apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="site.webmanifest" rel="manifest">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="."><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="pages/">Pages</a></li>
<li class="nav-item"><a class="nav-link" href="archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="rss.xml">RSS feed</a></li>
<li class="nav-item dropdown"><a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#">Monkey Pages</a>
<div class="dropdown-menu"><a class="dropdown-item" href="https://necromuralist.github.io/">The Cloistered Monkey</a> <a class="dropdown-item" href="https://necromuralist.github.io/Ape-Iron/">Ape Iron</a> <a class="dropdown-item" href="https://necromuralist.github.io/Bowling-For-Data/">Bowling For Data</a> <a class="dropdown-item" href="https://necromuralist.github.io/Beach-Pig-Thigh/">Beach-Pig Rump & Thigh</a> <a class="dropdown-item" href="https://necromuralist.github.io/Visions-Voices-Data/">Visions, Voices, Data</a></div>
</li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<div class="postindex">
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-the-data/index.html">Siamese Networks: The Data</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-the-data/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:32:40-08:00" itemprop="datePublished" title="2021-01-25 19:32">2021-01-25 19:32</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org55808a2">Transforming the Data</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orgacd1893">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org2d2a01e">Set Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org594378e">The Timer</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org8c8d112">NLTK</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org4807c3d">The Training Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org989ffe3">Middle</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org215766a">Inspecting the Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orgbab6eec">Train Test Split</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org82a3d22">Filtering Out Non-Duplicates</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org0a0c5ce">Encoding the Words</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org43248ab">Build the Vocabulary</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org5d22953">Converting a question to a tensor</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orgbc952c3">Validation Set</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org06065ad">Bundling It Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org2986fd8">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org6684d11">NLTK Setup</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org94d52c9">Constants and Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orga30834f">The Data Tokenizer</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orge006cd1">Question 1</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org844f569">Question 2</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org50630fe">The Data Tensorizer</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org3666c88">Tensorized 1</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orgd1bc28a">Tensorized 2</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org5bd5c64">To Index</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orga718d54">The Data Transformer</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orga31cee0">Data Path</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orgf5a019f">Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org38708da">Training Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org5f6e557">Testing Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org053fcad">Duplicates</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org22cf823">Train Tokenizer</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org04a6172">Test Tokenizer</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orgdff1a7c">The Vocabulary</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org50a9009">Tensorized Train</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orgc203b8b">Tensorized Test</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#orged5c48f">Test Labels</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org57671da">The Final Data</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/index.html#org0e98c1e">Test It Out</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org55808a2">
<h2 id="org55808a2">Transforming the Data</h2>
<div class="outline-text-2" id="text-org55808a2">
<p>We'll will be using the <a href="https://www.kaggle.com/c/quora-question-pairs/">Quora question answer</a> dataset to build a model that could identify similar questions. This is a useful task because you don't want to have several versions of the same question posted. Several times when teaching I end up responding to similar questions on piazza, or on other community forums. This data set has been labeled for you. Run the cell below to import some of the packages you will be using.</p>
</div>
<div class="outline-3" id="outline-container-orgacd1893">
<h3 id="orgacd1893">Imports</h3>
<div class="outline-text-3" id="text-orgacd1893">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="n">expect</span><span class="p">,</span> <span class="n">contain_exactly</span>

<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># my other stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org2d2a01e">
<h3 id="org2d2a01e">Set Up</h3>
<div class="outline-text-3" id="text-org2d2a01e"></div>
<div class="outline-4" id="outline-container-org594378e">
<h4 id="org594378e">The Timer</h4>
<div class="outline-text-4" id="text-org594378e">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8c8d112">
<h4 id="org8c8d112">NLTK</h4>
<div class="outline-text-4" id="text-org8c8d112">
<p>We need to download the <code>punkt</code> data to be able to tokenize our sentences.</p>
<div class="highlight">
<pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">"punkt"</span><span class="p">)</span>
</pre></div>
<pre class="example">
[nltk_data] Downloading package punkt to
[nltk_data]     /home/neurotic/data/datasets/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre></div>
</div>
<div class="outline-4" id="outline-container-org4807c3d">
<h4 id="org4807c3d">The Training Data</h4>
<div class="outline-text-4" id="text-org4807c3d">
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"QUORA_TRAIN"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org989ffe3">
<h2 id="org989ffe3">Middle</h2>
<div class="outline-text-2" id="text-org989ffe3"></div>
<div class="outline-3" id="outline-container-org215766a">
<h3 id="org215766a">Inspecting the Data</h3>
<div class="outline-text-3" id="text-org215766a">
<div class="highlight">
<pre><span></span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Rows: </span><span class="si">{</span><span class="n">rows</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> Columns: </span><span class="si">{</span><span class="n">columns</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Rows: 404,290 Columns: 6
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
id                                                              0
qid1                                                            1
qid2                                                            2
question1       What is the step by step guide to invest in sh...
question2       What is the step by step guide to invest in sh...
is_duplicate                                                    0
Name: 0, dtype: object
</pre>
<p>So, you can see that we have a row ID, followed by IDs for each of the questions, followed by the question-pair, and finally a label of whether the two questions are duplicates (1) or not (0).</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgbab6eec">
<h3 id="orgbab6eec">Train Test Split</h3>
<div class="outline-text-3" id="text-orgbab6eec">
<p>For the moment we're going to use a straight splitting of the dataset, rather than using a shuffled split. We're going for a roughly 75-25 split.</p>
<div class="highlight">
<pre><span></span><span class="n">training_size</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">10</span><span class="o">**</span><span class="mi">5</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">training_size</span><span class="p">]</span>
<span class="n">testing_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">training_size</span><span class="p">:]</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span> <span class="o">==</span> <span class="n">training_size</span>
</pre></div>
<p>Since the data set is large, we'll delete the original pandas DataFrame to save memory.</p>
<div class="highlight">
<pre><span></span><span class="k">del</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org82a3d22">
<h3 id="org82a3d22">Filtering Out Non-Duplicates</h3>
<div class="outline-text-3" id="text-org82a3d22">
<p>We are going to use only the question pairs that are duplicate to train the model.</p>
<p>We build two batches as input for the Siamese network and we assume that question \(q1_i\) (question <i>i</i> in the first batch) is a duplicate of \(q2_i\) (question <i>i</i> in the second batch), but all other questions in the second batch are not duplicates of \(q1_i\).</p>
<p>The test set uses the original pairs of questions and the status describing if the questions are duplicates.</p>
<div class="highlight">
<pre><span></span><span class="n">duplicates</span> <span class="o">=</span> <span class="n">training_data</span><span class="p">[</span><span class="n">training_data</span><span class="o">.</span><span class="n">is_duplicate</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">duplicates</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">question1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">question2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">is_duplicate</span><span class="p">)</span>
</pre></div>
<pre class="example">
Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?
I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?
1
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">duplicates</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> duplicates for the training data."</span><span class="p">)</span>
</pre></div>
<pre class="example">
There are 111,473 duplicates for the training data.
</pre>
<p>We only took the duplicated questions for training our model because the data generator will produce batches \(([q1_1, q1_2, q1_3, ...]\), [q2_1, q2_2,q2_3, â€¦])\) where \(q1_i\) and \(q2_k\) are duplicate if and only if \(i = k\).</p>
</div>
</div>
<div class="outline-3" id="outline-container-org0a0c5ce">
<h3 id="org0a0c5ce">Encoding the Words</h3>
<div class="outline-text-3" id="text-org0a0c5ce">
<p>Now we'll encode each word of the selected duplicate pairs with an index. Given a question, we can then just encode it as a list of numbers.</p>
<p>First we'll tokenize the questions using <code>nltk.word_tokenize</code>.</p>
<p>We'll also need a python default dictionary which later, during inference, assigns the value <i>0</i> to all Out Of Vocabulary (OOV) words.</p>
</div>
<div class="outline-4" id="outline-container-org43248ab">
<h4 id="org43248ab">Build the Vocabulary</h4>
<div class="outline-text-4" id="text-org43248ab">
<p>We'll start by resetting the index. Pandas preserves the original index, but since we dropped the non-duplicates it's missing rows so resetting it will start it at 0 again. By default it normally keeps the original index as a column, but passing in <code>drop=True</code> prevents that.</p>
<div class="highlight">
<pre><span></span><span class="n">reindexed</span> <span class="o">=</span> <span class="n">duplicates</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<p>Now we'll build the vocabulary by mapping the words to the "index" for that word in the dictionary.</p>
<div class="highlight">
<pre><span></span><span class="n">vocabulary</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">vocabulary</span><span class="p">[</span><span class="s1">'&lt;PAD&gt;'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">question_1_train</span> <span class="o">=</span> <span class="n">duplicates</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
    <span class="n">question_2_train</span> <span class="o">=</span> <span class="n">duplicates</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
    <span class="n">combined</span> <span class="o">=</span> <span class="n">question_1_train</span> <span class="o">+</span> <span class="n">question_2_train</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">combined</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">(</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="n">vocabulary</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> words in the vocabulary."</span><span class="p">)</span>            
</pre></div>
<pre class="example">
Started: 2021-01-30 18:36:26.773827
Ended: 2021-01-30 18:36:46.522680
Elapsed: 0:00:19.748853
There are 36,278 words in the vocabulary.
</pre>
<p>Some example vocabulary words.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">[</span><span class="s1">'&lt;PAD&gt;'</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">[</span><span class="s1">'Astrology'</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">[</span><span class="s1">'Astronomy'</span><span class="p">])</span>
</pre></div>
<pre class="example">
1
7
0
</pre>
<p>The last <code>0</code> indicates that, while <i>Astrology</i> is in our vocabulary, <i>Astronomy</i> is not. Peculiar.</p>
<p>Now we'll set up the test arrays. One of the Question 1 entries is empty so we'll have to drop it first.</p>
<div class="highlight">
<pre><span></span><span class="n">testing_data</span> <span class="o">=</span> <span class="n">testing_data</span><span class="p">[</span><span class="o">~</span><span class="n">testing_data</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">Q1_test_words</span> <span class="o">=</span> <span class="n">testing_data</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
    <span class="n">Q2_test_words</span> <span class="o">=</span> <span class="n">testing_data</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2021-01-30 16:43:08.891230
Ended: 2021-01-30 16:43:27.954422
Elapsed: 0:00:19.063192
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org5d22953">
<h3 id="org5d22953">Converting a question to a tensor</h3>
<div class="outline-text-3" id="text-org5d22953">
<p>We'll now convert every question to a tensor, or an array of numbers, using the vocabulary we built above.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">words_to_index</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>

<span class="n">Q1_train</span> <span class="o">=</span> <span class="n">question_1_train</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">words_to_index</span><span class="p">)</span>
<span class="n">Q2_train</span> <span class="o">=</span> <span class="n">question_2_train</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">words_to_index</span><span class="p">)</span>

<span class="n">Q1_test</span> <span class="o">=</span> <span class="n">Q1_test_words</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">words_to_index</span><span class="p">)</span>
<span class="n">Q2_test</span> <span class="o">=</span> <span class="n">Q2_test_words</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">words_to_index</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'first question in the train set:</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">question_1_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="s1">'encoded version:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Q1_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example">
first question in the train set:

['Astrology', ':', 'I', 'am', 'a', 'Capricorn', 'Sun', 'Cap', 'moon', 'and', 'cap', 'rising', '...', 'what', 'does', 'that', 'say', 'about', 'me', '?'] 

encoded version:
[7, 6, 17, 26, 22, 12, 15, 14, 2, 24, 16, 19, 31, 8, 9, 21, 25, 3, 23, 29] 

</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
77,068
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgbc952c3">
<h3 id="orgbc952c3">Validation Set</h3>
<div class="outline-text-3" id="text-orgbc952c3">
<p>You will now split your train set into a training/validation set so that you can use it to train and evaluate your Siamese model.</p>
<div class="highlight">
<pre><span></span><span class="n">TRAINING_FRACTION</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">cut_off</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">question_1_train</span><span class="p">)</span> <span class="o">*</span> <span class="n">TRAINING_FRACTION</span><span class="p">)</span>
<span class="n">train_question_1</span><span class="p">,</span> <span class="n">train_question_2</span> <span class="o">=</span> <span class="n">Q1_train</span><span class="p">[:</span><span class="n">cut_off</span><span class="p">],</span> <span class="n">Q2_train</span><span class="p">[:</span><span class="n">cut_off</span><span class="p">]</span>
<span class="n">validation_question_1</span><span class="p">,</span> <span class="n">validation_question_2</span> <span class="o">=</span> <span class="n">Q1_train</span><span class="p">[</span><span class="n">cut_off</span><span class="p">:</span> <span class="p">],</span> <span class="n">Q2_train</span><span class="p">[</span><span class="n">cut_off</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of duplicate questions: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">Q1_train</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The length of the training set is:  </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_question_1</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The length of the validation set is: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_question_1</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Number of duplicate questions: 111,473
The length of the training set is:  89,178
The length of the validation set is: 22,295
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org06065ad">
<h2 id="org06065ad">Bundling It Up</h2>
<div class="outline-text-2" id="text-org06065ad"></div>
<div class="outline-3" id="outline-container-org2986fd8">
<h3 id="org2986fd8">Imports</h3>
<div class="outline-text-3" id="text-org2986fd8">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org6684d11">
<h3 id="org6684d11">NLTK Setup</h3>
<div class="outline-text-3" id="text-org6684d11">
<div class="highlight">
<pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">"punkt"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org94d52c9">
<h3 id="org94d52c9">Constants and Data</h3>
<div class="outline-text-3" id="text-org94d52c9">
<div class="highlight">
<pre><span></span><span class="n">Tokens</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Tokens"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"unknown"</span><span class="p">,</span> <span class="s2">"padding"</span><span class="p">,</span> <span class="s2">"padding_token"</span><span class="p">])</span>
<span class="n">TOKENS</span> <span class="o">=</span> <span class="n">Tokens</span><span class="p">(</span><span class="n">unknown</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">padding_token</span><span class="o">=</span><span class="s2">"&lt;PAD&gt;"</span><span class="p">)</span>

<span class="n">Question</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Question"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"question_one"</span><span class="p">,</span> <span class="s2">"question_two"</span><span class="p">])</span>
<span class="n">Data</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Data"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"train"</span><span class="p">,</span> <span class="s2">"validate"</span><span class="p">,</span> <span class="s2">"test"</span><span class="p">,</span> <span class="s2">"y_test"</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orga30834f">
<h3 id="orga30834f">The Data Tokenizer</h3>
<div class="outline-text-3" id="text-orga30834f">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DataTokenizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Converts questions to tokens</span>

<span class="sd">    Args:</span>
<span class="sd">     data: the data-frame to tokenize</span>
<span class="sd">    """</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span>
    <span class="n">_question_1</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_question_2</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orge006cd1">
<h4 id="orge006cd1">Question 1</h4>
<div class="outline-text-4" id="text-orge006cd1">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">question_1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""tokenized version of question 1"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_question_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_question_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_question_1</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org844f569">
<h4 id="org844f569">Question 2</h4>
<div class="outline-text-4" id="text-org844f569">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">question_2</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""tokenized version of question 2"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_question_2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_question_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_question_2</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org50630fe">
<h3 id="org50630fe">The Data Tensorizer</h3>
<div class="outline-text-3" id="text-org50630fe">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DataTensorizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Convert tokenized words to numbers</span>

<span class="sd">    Args:</span>
<span class="sd">     vocabulary: word to integer mapping</span>
<span class="sd">     question_1: data to convert</span>
<span class="sd">     question_2: other data to convert</span>
<span class="sd">    """</span>
    <span class="n">vocabulary</span><span class="p">:</span> <span class="nb">dict</span>
    <span class="n">question_1</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span>
    <span class="n">question_2</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span>
    <span class="n">_tensorized_1</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tensorized_2</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org3666c88">
<h4 id="org3666c88">Tensorized 1</h4>
<div class="outline-text-4" id="text-org3666c88">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tensorized_1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""numeric version of question 1"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">question_1</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_index</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_1</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd1bc28a">
<h4 id="orgd1bc28a">Tensorized 2</h4>
<div class="outline-text-4" id="text-orgd1bc28a">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tensorized_2</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Numeric version of question 2"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">question_2</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_index</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_2</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5bd5c64">
<h4 id="org5bd5c64">To Index</h4>
<div class="outline-text-4" id="text-org5bd5c64">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">to_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Convert list of words to list of integers"""</span>
    <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orga718d54">
<h3 id="orga718d54">The Data Transformer</h3>
<div class="outline-text-3" id="text-orga718d54">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DataLoader</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Loads and transforms the data</span>

<span class="sd">    Args:</span>
<span class="sd">     env: The path to the .env file with the raw-data path</span>
<span class="sd">     key: key in the environment with the path to the data</span>
<span class="sd">     train_validation_size: number of entries for the training/validation set</span>
<span class="sd">     training_fraction: what fraction of the training/valdiation set for training</span>
<span class="sd">    """</span>
    <span class="n">env</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"posts/nlp/.env"</span>
    <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"QUORA_TRAIN"</span>
    <span class="n">train_validation_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">300000</span>
    <span class="n">training_fraction</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.8</span>
    <span class="n">_data_path</span><span class="p">:</span> <span class="n">Path</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_raw_data</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_training_data</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_testing_data</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_duplicates</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tokenized_train</span><span class="p">:</span> <span class="n">DataTokenizer</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tokenized_test</span><span class="p">:</span> <span class="n">DataTokenizer</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_vocabulary</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tensorized_train</span><span class="p">:</span> <span class="n">DataTensorizer</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tensorized_test</span><span class="p">:</span> <span class="n">DataTensorizer</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_test_labels</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="o">=</span><span class="kc">None</span>    
    <span class="n">_data</span><span class="p">:</span> <span class="n">namedtuple</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orga31cee0">
<h4 id="orga31cee0">Data Path</h4>
<div class="outline-text-4" id="text-orga31cee0">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">data_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Path</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Where to find the data file"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">load_dotenv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf5a019f">
<h4 id="orgf5a019f">Data</h4>
<div class="outline-text-4" id="text-orgf5a019f">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">raw_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""The raw-data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span>        
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org38708da">
<h4 id="org38708da">Training Data</h4>
<div class="outline-text-4" id="text-org38708da">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">training_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""The training/validation part of the data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_training_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">train_validation_size</span><span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5f6e557">
<h4 id="org5f6e557">Testing Data</h4>
<div class="outline-text-4" id="text-org5f6e557">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">testing_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""The testing portion of the raw data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_testing_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_testing_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train_validation_size</span><span class="p">:]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_testing_data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org053fcad">
<h4 id="org053fcad">Duplicates</h4>
<div class="outline-text-4" id="text-org053fcad">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">duplicates</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""training-validation data that has duplicate questions"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_duplicates</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_duplicates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="o">.</span><span class="n">is_duplicate</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_duplicates</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org22cf823">
<h4 id="org22cf823">Train Tokenizer</h4>
<div class="outline-text-4" id="text-org22cf823">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tokenized_train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataTokenizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""training tokenized    </span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_train</span> <span class="o">=</span> <span class="n">DataTokenizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">duplicates</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_train</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org04a6172">
<h4 id="org04a6172">Test Tokenizer</h4>
<div class="outline-text-4" id="text-org04a6172">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tokenized_test</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataTokenizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Test Tokenizer"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_test</span> <span class="o">=</span> <span class="n">DataTokenizer</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">testing_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_test</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgdff1a7c">
<h4 id="orgdff1a7c">The Vocabulary</h4>
<div class="outline-text-4" id="text-orgdff1a7c">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""The token:index map"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">TOKENS</span><span class="o">.</span><span class="n">unknown</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span><span class="p">[</span><span class="n">TOKENS</span><span class="o">.</span><span class="n">padding_token</span><span class="p">]</span> <span class="o">=</span> <span class="n">TOKENS</span><span class="o">.</span><span class="n">padding</span>
        <span class="n">combined</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenized_train</span><span class="o">.</span><span class="n">question_1</span>
                    <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_train</span><span class="o">.</span><span class="n">question_2</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">combined</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">(</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
                      <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span>            
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org50a9009">
<h4 id="org50a9009">Tensorized Train</h4>
<div class="outline-text-4" id="text-org50a9009">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tensorized_train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataTensorizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Tensorizer for the training data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_train</span> <span class="o">=</span> <span class="n">DataTensorizer</span><span class="p">(</span>
            <span class="n">vocabulary</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">,</span>
            <span class="n">question_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_train</span><span class="o">.</span><span class="n">question_1</span><span class="p">,</span>
            <span class="n">question_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_train</span><span class="o">.</span><span class="n">question_2</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_train</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc203b8b">
<h4 id="orgc203b8b">Tensorized Test</h4>
<div class="outline-text-4" id="text-orgc203b8b">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tensorized_test</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataTensorizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Tensorizer for the testing data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_test</span> <span class="o">=</span> <span class="n">DataTensorizer</span><span class="p">(</span>
            <span class="n">vocabulary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">,</span>
            <span class="n">question_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_test</span><span class="o">.</span><span class="n">question_1</span><span class="p">,</span>
            <span class="n">question_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_test</span><span class="o">.</span><span class="n">question_2</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_test</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orged5c48f">
<h4 id="orged5c48f">Test Labels</h4>
<div class="outline-text-4" id="text-orged5c48f">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">test_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""The labels for the test data</span>

<span class="sd">    0 : not duplicate questions</span>
<span class="sd">    1 : is duplicate</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">testing_data</span><span class="o">.</span><span class="n">is_duplicate</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_labels</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org57671da">
<h4 id="org57671da">The Final Data</h4>
<div class="outline-text-4" id="text-org57671da">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">namedtuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""The final tensorized data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cut_off</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">duplicates</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_fraction</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">Data</span><span class="p">(</span>
            <span class="n">train</span><span class="o">=</span><span class="n">Question</span><span class="p">(</span>
                <span class="n">question_one</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_train</span><span class="o">.</span><span class="n">tensorized_1</span><span class="p">[:</span><span class="n">cut_off</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
                <span class="n">question_two</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_train</span><span class="o">.</span><span class="n">tensorized_2</span><span class="p">[:</span><span class="n">cut_off</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()),</span>
            <span class="n">validate</span><span class="o">=</span><span class="n">Question</span><span class="p">(</span>
                <span class="n">question_one</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_train</span><span class="o">.</span><span class="n">tensorized_1</span><span class="p">[</span><span class="n">cut_off</span><span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
                <span class="n">question_two</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_train</span><span class="o">.</span><span class="n">tensorized_2</span><span class="p">[</span><span class="n">cut_off</span><span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()),</span>
            <span class="n">test</span><span class="o">=</span><span class="n">Question</span><span class="p">(</span>
                <span class="n">question_one</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_test</span><span class="o">.</span><span class="n">tensorized_1</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
                <span class="n">question_two</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_test</span><span class="o">.</span><span class="n">tensorized_2</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()),</span>
            <span class="n">y_test</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test_labels</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org0e98c1e">
<h3 id="org0e98c1e">Test It Out</h3>
<div class="outline-text-3" id="text-org0e98c1e">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of duplicate questions: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">duplicates</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The length of the training set is:  </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The length of the validation set is: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">validate</span><span class="o">.</span><span class="n">question_one</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Number of duplicate questions: 111,474
The length of the training set is:  89,179
The length of the validation set is: 22,295
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'first question in the train set:</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">duplicates</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'encoded version:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">Q1_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
<pre class="example">
first question in the train set:

Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?
encoded version:
[7, 6, 17, 26, 22, 12, 15, 14, 2, 24, 16, 19, 31, 8, 9, 21, 25, 3, 23, 29] 

</pre>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="k">assert</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
77,068
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-duplicate-questions/index.html">Siamese Networks: Duplicate Questions</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-duplicate-questions/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-23T20:20:18-08:00" itemprop="datePublished" title="2021-01-23 20:20">2021-01-23 20:20</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/siamese-networks-duplicate-questions/index.html#org93f2420">Beginning</a>
<ul>
<li><a href="posts/nlp/siamese-networks-duplicate-questions/index.html#orge0c0739">The Posts</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org93f2420">
<h2 id="org93f2420">Beginning</h2>
<div class="outline-text-2" id="text-org93f2420">
<p>In this series of posts we will:</p>
<ul class="org-ul">
<li>Learn about Siamese networks</li>
<li>Understand how the triplet loss works</li>
<li>Understand how to evaluate accuracy</li>
<li>Use cosine similarity between the model's outputted vectors</li>
<li>Use the data generator to get batches of questions</li>
<li>Make predictions using the own model</li>
</ul>
</div>
<div class="outline-3" id="outline-container-orge0c0739">
<h3 id="orge0c0739">The Posts</h3>
<div class="outline-text-3" id="text-orge0c0739">
<ul class="org-ul">
<li><a href="posts/nlp/siamese-networks-the-data/index.html">The Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html">The Data Generator</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html">The Model</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html">Defining the Loss</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html">Training the Model</a></li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/index.html">Evaluating the Model</a></li>
<li><a href="posts/nlp/siamese-networks-new-questions/index.html">Testing Questions Outside the Dataset</a></li>
</ul>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/evaluating-a-siamese-model/index.html">Evaluating a Siamese Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/evaluating-a-siamese-model/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-21T18:34:27-08:00" itemprop="datePublished" title="2021-01-21 18:34">2021-01-21 18:34</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/evaluating-a-siamese-model/index.html#orgf47d406">Beginning</a>
<ul>
<li><a href="posts/nlp/evaluating-a-siamese-model/index.html#org2334445">Imports</a></li>
<li><a href="posts/nlp/evaluating-a-siamese-model/index.html#orged03a37">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/evaluating-a-siamese-model/index.html#org37b1c8c">Middle</a>
<ul>
<li><a href="posts/nlp/evaluating-a-siamese-model/index.html#orgc8022fc">Data</a></li>
<li><a href="posts/nlp/evaluating-a-siamese-model/index.html#org5d5cc4e">Calculating the accuracy</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgf47d406">
<h2 id="orgf47d406">Beginning</h2>
<div class="outline-text-2" id="text-orgf47d406">
<p>We are going to learn how to evaluate a Siamese model using the accuracy metric.</p>
</div>
<div class="outline-3" id="outline-container-org2334445">
<h3 id="org2334445">Imports</h3>
<div class="outline-text-3" id="text-org2334445">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>

<span class="kn">import</span> <span class="nn">trax.fastmath.numpy</span> <span class="k">as</span> <span class="nn">trax_numpy</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orged03a37">
<h3 id="orged03a37">Set Up</h3>
<div class="outline-text-3" id="text-orged03a37">
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>
<span class="n">PREFIX</span> <span class="o">=</span> <span class="s2">"SIAMESE_"</span>
<span class="n">q1</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">PREFIX</span> <span class="o">+</span> <span class="s2">"Q1"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="n">q2</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">PREFIX</span> <span class="o">+</span> <span class="s2">"Q2"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="n">v1</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">PREFIX</span> <span class="o">+</span> <span class="s2">"V1"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">PREFIX</span> <span class="o">+</span> <span class="s2">"V2"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">PREFIX</span> <span class="o">+</span> <span class="s2">"Y_TEST"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org37b1c8c">
<h2 id="org37b1c8c">Middle</h2>
<div class="outline-text-2" id="text-org37b1c8c"></div>
<div class="outline-3" id="outline-container-orgc8022fc">
<h3 id="orgc8022fc">Data</h3>
<div class="outline-text-3" id="text-orgc8022fc">
<p>We're going to use some pre-made data rather than start from scratch to (hopefully) make the actual evaluation clearer.</p>
<p>These are the data structures:</p>
<ul class="org-ul">
<li><code>q1</code>: vector with dimension <code>(batch_size X max_length)</code> containing first questions to compare in the test set.</li>
<li><code>q2</code>: vector with dimension <code>(batch_size X max_length)</code> containing second questions to compare in the test set.</li>
</ul>
<p><b>Notice that for each pair of vectors within a batch \(([q1_1, q1_2, q1_3, \ldots]\), \([q2_1, q2_2,q2_3, ...])\) \(q1_i\) is associated with \(q2_k\).</b></p>
<ul class="org-ul">
<li><code>y_test</code>: 1 if \(q1_i\) and \(q2_k\) are duplicates, 0 otherwise.</li>
<li><code>v1</code>: output vector from the model's prediction associated with the first questions.</li>
<li><code>v2</code>: output vector from the model's prediction associated with the second questions.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'q1 has shape: </span><span class="si">{</span><span class="n">q1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> </span><span class="se">\n\n</span><span class="s1">And it looks like this: </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">q1</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orge3cf3b8">
q1 has shape: (512, 64) 

And it looks like this: 

 [[ 32  38   4 ...   1   1   1]
 [ 30 156  78 ...   1   1   1]
 [ 32  38   4 ...   1   1   1]
 ...
 [ 32  33   4 ...   1   1   1]
 [ 30 156 317 ...   1   1   1]
 [ 30 156   6 ...   1   1   1]]
</pre>
<p>The ones on the right side are padding values.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'q2 has shape: </span><span class="si">{</span><span class="n">q2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> </span><span class="se">\n\n</span><span class="s1">And looks like this: </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">q2</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orga99abc5">
q2 has shape: (512, 64) 

And looks like this: 

 [[   30   156    78 ...     1     1     1]
 [  283   156    78 ...     1     1     1]
 [   32    38     4 ...     1     1     1]
 ...
 [   32    33     4 ...     1     1     1]
 [   30   156    78 ...     1     1     1]
 [   30   156 10596 ...     1     1     1]]
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'y_test has shape: </span><span class="si">{</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> </span><span class="se">\n\n</span><span class="s1">And looks like this: </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">y_test</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org866f01f">
y_test has shape: (512,) 

And looks like this: 

 [0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0
 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0
 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0
 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0
 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1
 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1
 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1
 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0
 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0
 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 0
 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1
 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1
 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'v1 has shape: </span><span class="si">{</span><span class="n">v1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> </span><span class="se">\n\n</span><span class="s1">And looks like this: </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">v1</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orge2754ae">
v1 has shape: (512, 128) 

And looks like this: 

 [[ 0.01273625 -0.1496373  -0.01982759 ...  0.02205012 -0.00169148
  -0.01598107]
 [-0.05592084  0.05792497 -0.02226785 ...  0.08156938 -0.02570007
  -0.00503111]
 [ 0.05686752  0.0294889   0.04522024 ...  0.03141788 -0.08459651
  -0.00968536]
 ...
 [ 0.15115018  0.17791134  0.02200656 ... -0.00851707  0.00571415
  -0.00431194]
 [ 0.06995274  0.13110274  0.0202337  ... -0.00902792 -0.01221745
   0.00505962]
 [-0.16043712 -0.11899089 -0.15950686 ...  0.06544471 -0.01208312
  -0.01183368]]
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'v2 has shape: </span><span class="si">{</span><span class="n">v2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> </span><span class="se">\n\n</span><span class="s1">And looks like this: </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">v2</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org47f09c4">
v2 has shape: (512, 128) 

And looks like this: 

 [[ 0.07437647  0.02804951 -0.02974014 ...  0.02378932 -0.01696189
  -0.01897198]
 [ 0.03270066  0.15122835 -0.02175895 ...  0.00517202 -0.14617395
   0.00204823]
 [ 0.05635608  0.05454165  0.042222   ...  0.03831453 -0.05387777
  -0.01447786]
 ...
 [ 0.04727105 -0.06748016  0.04194937 ...  0.07600753 -0.03072828
   0.00400715]
 [ 0.00269269  0.15222628  0.01714724 ...  0.01482705 -0.0197884
   0.01389528]
 [-0.15475044 -0.15718803 -0.14732707 ...  0.04299919 -0.01070975
  -0.01318042]]
</pre></div>
</div>
<div class="outline-3" id="outline-container-org5d5cc4e">
<h3 id="org5d5cc4e">Calculating the accuracy</h3>
<div class="outline-text-3" id="text-org5d5cc4e">
<p>You will calculate the accuracy by iterating over the test set and checking if the model predicts right or wrong.</p>
<p>You will also need the <code>batch size</code> and the <code>threshold</code> that will determine if two questions are the same or not.</p>
<p><b>Note:</b> A higher threshold means that only very similar questions will be considered as the same question.</p>
<div class="highlight">
<pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">batch</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
<p>The process is pretty straightforward:</p>
<ul class="org-ul">
<li>Iterate over each one of the elements in the batch</li>
<li>Compute the cosine similarity between the predictions
<ul class="org-ul">
<li>For computing the cosine similarity, the two output vectors should have been normalized using L2 normalization meaning their magnitude will be 1. This has been taken care off by the Siamese network. Hence the cosine similarity here is just dot product between two vectors. You can check by implementing the usual cosine similarity formula and check if this holds or not.</li>
</ul>
</li>
<li>Determine if this value is greater than the threshold (If it is, consider the two questions as the same and return 1 else 0)</li>
<li>Compare against the actual target and if the prediction matches, add 1 to the accuracy (increment the correct prediction counter)</li>
<li>Divide the accuracy by the number of processed elements</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">[</span><span class="n">row</span><span class="p">],</span> <span class="n">v2</span><span class="p">[</span><span class="n">row</span><span class="p">])</span>
    <span class="n">similar_enough</span> <span class="o">=</span> <span class="n">similarity</span> <span class="o">&gt;</span> <span class="n">threshold</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">element</span><span class="p">]</span> <span class="o">==</span> <span class="n">similar_enough</span><span class="p">)</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">batch_size</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The accuracy of the model is: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
</pre></div>
<pre class="example">
The accuracy of the model is: 0.6621.
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/modified-triplet-loss/index.html">Modified Triplet Loss</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/modified-triplet-loss/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-21T18:34:00-08:00" itemprop="datePublished" title="2021-01-21 18:34">2021-01-21 18:34</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/modified-triplet-loss/index.html#org0b21340">Beginning</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/index.html#orgbc176d8">Background</a></li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#orga8708bf">Imports</a></li>
</ul>
</li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#orgc8eeb4b">Middle</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/index.html#orgb211397">Similarity Scores</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/index.html#orga071380">Two Vectors</a></li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#org564e191">Similarity score</a></li>
</ul>
</li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#org4117f71">Two Batches of Vectors</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/index.html#org2c82287">Check</a></li>
</ul>
</li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#orge7fa5a0">Hard Negative Mining</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/index.html#orgd33a4eb">Mean Negative</a></li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#org88849d7">Closest Negative</a></li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#org079a6e9">Positives</a></li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#org134cf01">Negatives</a></li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#org0217bf9">Mean negative</a></li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#orgeb505e1">Closest negative</a></li>
</ul>
</li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#orgd3d274c">The Loss Functions</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/index.html#org3df3401">Modified triplet loss</a></li>
<li><a href="posts/nlp/modified-triplet-loss/index.html#orgc30467d">Cost</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org0b21340">
<h2 id="org0b21340">Beginning</h2>
<div class="outline-text-2" id="text-org0b21340">
<p>We'll be looking at how to calculate the full triplet loss as well as a matrix of similarity scores.</p>
</div>
<div class="outline-3" id="outline-container-orgbc176d8">
<h3 id="orgbc176d8">Background</h3>
<div class="outline-text-3" id="text-orgbc176d8">
<p>This is the original triplet loss function:</p>
<p>\[ \mathcal{L_\mathrm{Original}} = \max{(\mathrm{s}(A,N) -\mathrm{s}(A,P) +\alpha, 0)} \]</p>
<p>It can be improved by including the mean negative and the closest negative, to create a new full loss function. The inputs are the Anchor \(\mathrm{A}\), Positive \(\mathrm{P}\) and Negative \(\mathrm{N}\).</p>
\begin{align} \mathcal{L_\mathrm{1}} &amp;= \max{(mean\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{2}} &amp;= \max{(closest\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{Full}} &amp;= \mathcal{L_\mathrm{1}} + \mathcal{L_\mathrm{2}}\\ \end{align}</div>
</div>
<div class="outline-3" id="outline-container-orga8708bf">
<h3 id="orga8708bf">Imports</h3>
<div class="outline-text-3" id="text-orga8708bf">
<div class="highlight">
<pre><span></span><span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgc8eeb4b">
<h2 id="orgc8eeb4b">Middle</h2>
<div class="outline-text-2" id="text-orgc8eeb4b"></div>
<div class="outline-3" id="outline-container-orgb211397">
<h3 id="orgb211397">Similarity Scores</h3>
<div class="outline-text-3" id="text-orgb211397">
<p>The first step is to calculate the matrix of similarity scores using cosine similarity so that you can look up \(\mathrm{s}(A,P)\), \(\mathrm{s}(A,N)\) as needed for the loss formulas.</p>
</div>
<div class="outline-4" id="outline-container-orga071380">
<h4 id="orga071380">Two Vectors</h4>
<div class="outline-text-4" id="text-orga071380">
<p>First, this is how to calculate the similarity score, using cosine similarity, for 2 vectors.</p>
<p>\[ \mathrm{s}(v_1,v_2) = \mathrm{cosine \ similarity}(v_1,v_2) = \frac{v_1 \cdot v_2}{||v_1||~||v_2||} \]</p>
</div>
</div>
<div class="outline-4" id="outline-container-org564e191">
<h4 id="org564e191">Similarity score</h4>
<div class="outline-text-4" id="text-org564e191">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">v2</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Calculates the cosine similarity between two vectors</span>

<span class="sd">    Args:</span>
<span class="sd">     v1: first vector</span>
<span class="sd">     v2: vector to compare to v1</span>

<span class="sd">    Returns:</span>
<span class="sd">     the cosine similarity between v1 and v2</span>
<span class="sd">    """</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v1</span><span class="p">))</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="n">v2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="orgf2e9221"></a>Similar vectors<br>
<div class="outline-text-5" id="text-orgf2e9221">
<div class="highlight">
<pre><span></span><span class="n">v1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : 0.9974
</pre></div>
</li>
<li><a id="orga93dd8e"></a>Identical Vectors<br>
<div class="outline-text-5" id="text-orga93dd8e">
<div class="highlight">
<pre><span></span><span class="n">v2</span> <span class="o">=</span> <span class="n">v1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : 1.0000
</pre></div>
</li>
<li><a id="orgb587616"></a>Opposite Vectors<br>
<div class="outline-text-5" id="text-orgb587616">
<div class="highlight">
<pre><span></span><span class="n">v2</span> <span class="o">=</span> <span class="o">-</span><span class="n">v1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : -1.0000
</pre></div>
</li>
<li><a id="orge2fc3e4"></a>Dissimilar Vectors<br>
<div class="outline-text-5" id="text-orge2fc3e4">
<div class="highlight">
<pre><span></span><span class="n">v2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">42</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : -0.5153
</pre></div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org4117f71">
<h3 id="org4117f71">Two Batches of Vectors</h3>
<div class="outline-text-3" id="text-org4117f71">
<p>Now let's look at how to calculate the similarity scores, using cosine similarity, for 2 batches of vectors. These are rows of individual vectors, just like in the example above, but stacked vertically into a matrix. They would look like the image below for a batch size (row count) of 4 and embedding size (column count) of 5.</p>
<p>The data is setup so that \(v_{1\_1}\) and \(v_{2\_1}\) represent duplicate inputs, but they are not duplicates with any other rows in the batch. This means \(v_{1\_1}\) and \(v_{2\_1}\) (green and green) have more similar vectors than say \(v_{1\_1}\) and \(v_{2\_2}\) (green and magenta).</p>
<p>We'll use two different methods for calculating the matrix of similarities from 2 batches of vectors.</p>
<p>The Input data.</p>
<div class="highlight">
<pre><span></span><span class="n">v1_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">v1_2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="n">v1_3</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="n">v1_4</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">v1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">v1_1</span><span class="p">,</span> <span class="n">v1_2</span><span class="p">,</span> <span class="n">v1_3</span><span class="p">,</span> <span class="n">v1_4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"v1 :"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="n">v2_1</span> <span class="o">=</span> <span class="n">v1_1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># add some noise to create approximate duplicate</span>
<span class="n">v2_2</span> <span class="o">=</span> <span class="n">v1_2</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">v2_3</span> <span class="o">=</span> <span class="n">v1_3</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">v2_4</span> <span class="o">=</span> <span class="n">v1_4</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">v2_1</span><span class="p">,</span> <span class="n">v2_2</span><span class="p">,</span> <span class="n">v2_3</span><span class="p">,</span> <span class="n">v2_4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"v2 :"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgc7e7860">
v1 :
[[ 1  2  3]
 [ 9  8  7]
 [-1 -4 -2]
 [ 1 -7  2]] 

v2 :
[[ 1.34263076  1.18510671  1.04373534]
 [ 8.96692933  6.50763316  7.03243982]
 [-3.4497247  -6.08808183 -4.54327564]
 [-0.77144774 -9.08449817  4.4633513 ]] 
</pre>
<p>For this to work the batch sizes must match.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">v1</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span>
</pre></div>
<p>Now let's look at the similarity scores.</p>
</div>
<ul class="org-ul">
<li><a id="org0b1ad7c"></a>Option 1 : nested loops and the cosine similarity function<br>
<div class="outline-text-5" id="text-org0b1ad7c">
<div class="highlight">
<pre><span></span><span class="n">batch_size</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">v1</span><span class="o">.</span><span class="n">shape</span>
<span class="n">scores_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">])</span>

<span class="n">rows</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">scores_1</span><span class="o">.</span><span class="n">shape</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rows</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">columns</span><span class="p">):</span>
        <span class="n">scores_1</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">[</span><span class="n">row</span><span class="p">],</span> <span class="n">v2</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Option 1 : Loop"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores_1</span><span class="p">)</span>
</pre></div>
<pre class="example">
Option 1 : Loop
[[ 0.88245143  0.87735873 -0.93717609 -0.14613242]
 [ 0.99999485  0.99567656 -0.95998199 -0.34214656]
 [-0.86016573 -0.81584759  0.96484391  0.60584372]
 [-0.31943701 -0.23354642  0.49063636  0.96181686]]
</pre></div>
</li>
<li><a id="org654f479"></a>Option 2 : Vector Normalization and the Dot Product<br>
<div class="outline-text-5" id="text-org654f479">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Normalize x"""</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">scores_2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">v1</span><span class="p">),</span> <span class="n">norm</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Option 2 : Vector Norm & dot product"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores_2</span><span class="p">)</span>
</pre></div>
<pre class="example">
Option 2 : Vector Norm & dot product
[[ 0.88245143  0.87735873 -0.93717609 -0.14613242]
 [ 0.99999485  0.99567656 -0.95998199 -0.34214656]
 [-0.86016573 -0.81584759  0.96484391  0.60584372]
 [-0.31943701 -0.23354642  0.49063636  0.96181686]] 

</pre></div>
</li>
</ul>
<div class="outline-4" id="outline-container-org2c82287">
<h4 id="org2c82287">Check</h4>
<div class="outline-text-4" id="text-org2c82287">
<p>Let's make sure we get the same answer in both cases.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">scores_1</span><span class="p">,</span> <span class="n">scores_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orge7fa5a0">
<h3 id="orge7fa5a0">Hard Negative Mining</h3>
<div class="outline-text-3" id="text-orge7fa5a0">
<p>Now we'll calculate the mean negative \(mean\_neg\) and the closest negative \(close\_neg\) used in calculating \(\mathcal{L_\mathrm{1}}\) and \(\mathcal{L_\mathrm{2}}\).</p>
\begin{align} \mathcal{L_\mathrm{1}} &amp;= \max{(mean\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{2}} &amp;= \max{(closest\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \end{align}
<p>We'll do this using the matrix of similarity scores for a batch size of 4. The diagonal of the matrix contains all the \(\mathrm{s}(A,P)\) values, similarities from duplicate question pairs (aka Positives). This is an important attribute for the calculations to follow.</p>
</div>
<div class="outline-4" id="outline-container-orgd33a4eb">
<h4 id="orgd33a4eb">Mean Negative</h4>
<div class="outline-text-4" id="text-orgd33a4eb">
<p><i>mean_neg</i> is the average of the off diagonals, the \(\mathrm{s}(A,N)\) values, for each row.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org88849d7">
<h4 id="org88849d7">Closest Negative</h4>
<div class="outline-text-4" id="text-org88849d7">
<p><i>closest_neg</i> is the largest off diagonal value, \(\mathrm{s}(A,N)\), that is smaller than the diagonal \(\mathrm{s}(A,P)\) for each row.</p>
<p>We'll start with some hand-made similarity scores.</p>
<div class="highlight">
<pre><span></span><span class="n">similarity_scores</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org079a6e9">
<h4 id="org079a6e9">Positives</h4>
<div class="outline-text-4" id="text-org079a6e9">
<p>All the <i>s(A,P)</i> values are similarities from duplicate question pairs (aka Positives). These are along the diagonal.</p>
<div class="highlight">
<pre><span></span><span class="n">sim_ap</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">similarity_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"s(A, P) :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sim_ap</span><span class="p">))</span>
</pre></div>
<pre class="example">
s(A, P) :

[[ 0.9  0.   0.   0. ]
 [ 0.   0.5  0.   0. ]
 [ 0.   0.  -0.4  0. ]
 [ 0.   0.   0.   0.5]]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org134cf01">
<h4 id="org134cf01">Negatives</h4>
<div class="outline-text-4" id="text-org134cf01">
<p>All the <i>s(A,N)</i> values are similarities of the non duplicate question pairs (aka Negatives). These are in the cells not on the diagonal.</p>
<div class="highlight">
<pre><span></span><span class="n">sim_an</span> <span class="o">=</span> <span class="n">similarity_scores</span> <span class="o">-</span> <span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sim_ap</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"s(A, N) :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sim_an</span><span class="p">)</span>
</pre></div>
<pre class="example">
s(A, N) :

[[ 0.  -0.8  0.3 -0.5]
 [-0.4  0.   0.1 -0.1]
 [ 0.3  0.1  0.  -0.8]
 [-0.5 -0.2 -0.7  0. ]]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org0217bf9">
<h4 id="org0217bf9">Mean negative</h4>
<div class="outline-text-4" id="text-org0217bf9">
<p>This is the average of the <i>s(A,N)</i> values for each row.</p>
<div class="highlight">
<pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">similarity_scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">mean_neg</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sim_an</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"mean_neg :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean_neg</span><span class="p">)</span>
</pre></div>
<pre class="example">
mean_neg :

[[-0.33333333]
 [-0.13333333]
 [-0.13333333]
 [-0.46666667]]
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgeb505e1">
<h4 id="orgeb505e1">Closest negative</h4>
<div class="outline-text-4" id="text-orgeb505e1">
<p>These are the Max <i>s(A,N)</i> that is &lt;= s(A,P) for each row.</p>
<div class="highlight">
<pre><span></span><span class="n">mask_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>            <span class="c1"># mask to exclude the diagonal</span>
<span class="n">mask_2</span> <span class="o">=</span> <span class="n">sim_an</span> <span class="o">&gt;</span> <span class="n">sim_ap</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># mask to exclude sim_an &gt; sim_ap</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">mask_1</span> <span class="o">|</span> <span class="n">mask_2</span>
<span class="n">sim_an_masked</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">sim_an</span><span class="p">)</span>         <span class="c1"># create a copy to preserve sim_an</span>
<span class="n">sim_an_masked</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>

<span class="n">closest_neg</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">sim_an_masked</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Closest Negative :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">closest_neg</span><span class="p">)</span>
</pre></div>
<pre class="example">
Closest Negative :

[[ 0.3]
 [ 0.1]
 [-0.8]
 [-0.2]]
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgd3d274c">
<h3 id="orgd3d274c">The Loss Functions</h3>
<div class="outline-text-3" id="text-orgd3d274c">
<p>The last step is to calculate the loss functions.</p>
\begin{align} \mathcal{L_\mathrm{1}} &amp;= \max{(mean\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{2}} &amp;= \max{(closest\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{Full}} &amp;= \mathcal{L_\mathrm{1}} + \mathcal{L_\mathrm{2}}\\ \end{align}
<p>The Alpha margin.</p>
<div class="highlight">
<pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.25</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org3df3401">
<h4 id="org3df3401">Modified triplet loss</h4>
<div class="outline-text-4" id="text-org3df3401">
<div class="highlight">
<pre><span></span><span class="n">loss_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">mean_neg</span> <span class="o">-</span> <span class="n">sim_ap</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">loss_2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">closest_neg</span> <span class="o">-</span> <span class="n">sim_ap</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">loss_full</span> <span class="o">=</span> <span class="n">loss_1</span> <span class="o">+</span> <span class="n">loss_2</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc30467d">
<h4 id="orgc30467d">Cost</h4>
<div class="outline-text-4" id="text-orgc30467d">
<div class="highlight">
<pre><span></span><span class="n">cost</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">loss_full</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Loss Full :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss_full</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">cost : </span><span class="si">{</span><span class="n">cost</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Loss Full :

[[0.        ]
 [0.        ]
 [0.51666667]
 [0.        ]]

cost : 0.517
</pre></div>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-with-trax/index.html">Siamese Networks With Trax</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-with-trax/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-21T18:33:18-08:00" itemprop="datePublished" title="2021-01-21 18:33">2021-01-21 18:33</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/siamese-networks-with-trax/index.html#org6bc5651">Beginning</a>
<ul>
<li><a href="posts/nlp/siamese-networks-with-trax/index.html#org9e897bf">Imports</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-with-trax/index.html#org3cf3219">Middle</a>
<ul>
<li><a href="posts/nlp/siamese-networks-with-trax/index.html#org56de069">L2 Normalization</a></li>
<li><a href="posts/nlp/siamese-networks-with-trax/index.html#orga631a68">The Siamese Model</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-with-trax/index.html#org1451326">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org6bc5651">
<h2 id="org6bc5651">Beginning</h2>
<div class="outline-text-2" id="text-org6bc5651"></div>
<div class="outline-3" id="outline-container-org9e897bf">
<h3 id="org9e897bf">Imports</h3>
<div class="outline-text-3" id="text-org9e897bf">
<div class="highlight">
<pre><span></span><span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">jax.interpreters.xla</span> <span class="kn">import</span> <span class="n">_DeviceArray</span> <span class="k">as</span> <span class="n">DeviceArray</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>
<span class="kn">import</span> <span class="nn">trax.fastmath.numpy</span> <span class="k">as</span> <span class="nn">fast_numpy</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org3cf3219">
<h2 id="org3cf3219">Middle</h2>
<div class="outline-text-2" id="text-org3cf3219"></div>
<div class="outline-3" id="outline-container-org56de069">
<h3 id="org56de069">L2 Normalization</h3>
<div class="outline-text-3" id="text-org56de069">
<p>Before building the model you will need to define a function that applies L2 normalization to a tensor. Luckily this is pretty straightforward.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DeviceArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""L2 Normalization</span>

<span class="sd">    Args:</span>
<span class="sd">     x: the data to normalize</span>

<span class="sd">    Returns:</span>
<span class="sd">     normalized version of x</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">fast_numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fast_numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
<p>The denominator can be replaced by <code>np.linalg.norm(x, axis</code>-1, keepdims=True)= to achieve the same result.</p>
<div class="highlight">
<pre><span></span><span class="n">tensor</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'The tensor is of type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">And looks like this:</span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">tensor</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example">
The tensor is of type: &lt;class 'numpy.ndarray'&gt;

And looks like this:

 [[0.68535982 0.95339335 0.00394827 0.51219226 0.81262096]
 [0.61252607 0.72175532 0.29187607 0.91777412 0.71457578]]
</pre>
<div class="highlight">
<pre><span></span><span class="n">norm_tensor</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'The normalized tensor is of type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">norm_tensor</span><span class="p">)</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">And looks like this:</span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">norm_tensor</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example">
The normalized tensor is of type: &lt;class 'jax.interpreters.xla._DeviceArray'&gt;

And looks like this:

 [[0.45177674 0.6284596  0.00260263 0.33762783 0.535665  ]
 [0.40091467 0.47240815 0.1910407  0.6007077  0.46770892]]
</pre>
<p>Notice that the initial tensor was converted from a numpy array to a jax array in the process.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orga631a68">
<h3 id="orga631a68">The Siamese Model</h3>
<div class="outline-text-3" id="text-orga631a68">
<p>To create a <code>Siamese</code> model you will first need to create a LSTM model using the <code>Serial</code> combinator layer and then use another combinator layer called <code>Parallel</code> to create the Siamese model. You should be familiar with the following layers:</p>
<ul class="org-ul">
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial"><code>Serial</code></a> : A combinator layer that allows to stack layers serially using functioncomposition.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding"><code>Embedding</code></a> : Maps discrete tokens to vectors. It will have shape <code>(vocabulary length X dimension of output vectors)</code>. The dimension of output vectors (also called <code>d_feature</code>) is the number of elements in the word embedding.</li>
</ul>
<p>-<a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTM"><code>LSTM</code></a> : The LSTM layer. It leverages another Trax layer called <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTMCell"><code>LSTMCell</code></a>. The number of units should be specified and should match the number of elements in the word embedding.</p>
<ul class="org-ul">
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Mean"><code>Mean</code></a> Computes the mean across a desired axis. Mean uses one tensor axis to form groups of values and replaces each group with the mean value of that group.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn"><code>Fn</code></a> Layer with no weights that applies the function f, which should be specified using a lambda syntax.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Parallel"><code>Parallel</code></a> It is a combinator layer (like <code>Serial</code>) that applies a list of layers in parallel to its inputs.</li>
</ul>
<p>Putting everything together the Siamese model looks like this:</p>
<div class="highlight">
<pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">model_dimension</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># Define the LSTM model</span>
<span class="n">LSTM</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_feature</span><span class="o">=</span><span class="n">model_dimension</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">model_dimension</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s1">'Normalize'</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="p">)</span>

<span class="c1"># Use the Parallel combinator to create a Siamese model out of the LSTM </span>
<span class="n">Siamese</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="p">(</span><span class="n">LSTM</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">)</span>
</pre></div>
<p>Next is a helper function that prints information for every layer (sublayer within <code>Serial</code>):</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">show_layers</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">layer_prefix</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total layers: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">sublayers</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">sublayers</span><span class="p">)):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'========'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">layer_prefix</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">sublayers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Siamese model:</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">show_layers</span><span class="p">(</span><span class="n">Siamese</span><span class="p">,</span> <span class="s1">'Parallel.sublayers'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org55edc94">
Siamese model:

Total layers: 2

========
Parallel.sublayers_0: Serial[
  Embedding_500_128
  LSTM_128
  Mean
  Normalize
]

========
Parallel.sublayers_1: Serial[
  Embedding_500_128
  LSTM_128
  Mean
  Normalize
]
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Detail of LSTM models:</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">show_layers</span><span class="p">(</span><span class="n">LSTM</span><span class="p">,</span> <span class="s1">'Serial.sublayers'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org659bbc0">
Detail of LSTM models:

Total layers: 4

========
Serial.sublayers_0: Embedding_500_128

========
Serial.sublayers_1: LSTM_128

========
Serial.sublayers_2: Mean

========
Serial.sublayers_3: Normalize
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org1451326">
<h2 id="org1451326">End</h2>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/ner-testing-the-model/index.html">NER: Testing the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/ner-testing-the-model/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-13T15:03:18-08:00" itemprop="datePublished" title="2021-01-13 15:03">2021-01-13 15:03</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/ner-testing-the-model/index.html#org803d2d7">Testing New Sentences</a>
<ul>
<li><a href="posts/nlp/ner-testing-the-model/index.html#org607828b">Set Up the Model and Maps</a></li>
</ul>
</li>
<li><a href="posts/nlp/ner-testing-the-model/index.html#orge662298">Middle</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org803d2d7">
<h2 id="org803d2d7">Testing New Sentences</h2>
<div class="outline-text-2" id="text-org803d2d7">
<ul class="org-ul">
<li><a href="posts/nlp/named-entity-recognition/index.html">The First Post</a></li>
<li><a href="posts/nlp/ner-evaluating-the-model/index.html">The Previous Post</a></li>
</ul>
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.named_entity_recognition</span> <span class="kn">import</span> <span class="p">(</span><span class="n">NER</span><span class="p">,</span>
                                                   <span class="n">NERData</span><span class="p">,</span>
                                                   <span class="n">TOKEN</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-org607828b">
<h3 id="org607828b">Set Up the Model and Maps</h3>
<div class="outline-text-3" id="text-org607828b">
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">NERData</span><span class="p">()</span><span class="o">.</span><span class="n">data</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NER</span><span class="p">(</span><span class="n">vocabulary_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">),</span>
            <span class="n">tag_count</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">tags</span><span class="p">))</span><span class="o">.</span><span class="n">model</span>
<span class="n">model</span><span class="o">.</span><span class="n">init_from_file</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/ner/model.pkl.gz"</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example">
Serial[
  Embedding_35180_50
  LSTM_50
  Dense_18
  LogSoftmax
]
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orge662298">
<h2 id="orge662298">Middle</h2>
<div class="outline-text-2" id="text-orge662298">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">sentence</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">model</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">vocabulary</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">,</span>
            <span class="n">tags</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">tags</span><span class="p">,</span>
            <span class="n">unknown</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">TOKEN</span><span class="o">.</span><span class="n">unknown</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Predicts the named entities in a sentence</span>

<span class="sd">    Args:</span>
<span class="sd">     sentence: the sentence to analyze</span>
<span class="sd">     model: the NER model</span>
<span class="sd">     vocabulary: token to id map</span>
<span class="sd">     tags: tag to id map</span>
<span class="sd">     unknown: key in the vocabulary for unknown tokens</span>
<span class="sd">    """</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocabulary</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="n">unknown</span><span class="p">)</span>
              <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)))</span>
    <span class="n">batch_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][:]</span> <span class="o">=</span> <span class="n">tokens</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tags</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="n">indices</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">predictions</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">sentence</span> <span class="o">=</span> <span class="s2">"Bilbo Baggins, the Shire's director of trade and manufacturing policy for the Lord Sauron, said in an interview on Sunday morning that Rumblefish was working to prepare for the possibility of a second wave of the Coronavirus in the Fall, although he said it wouldnâ€™t necessarily come before the fall of the Empire and the rise of the corpse brigade in July"</span>

<span class="k">def</span> <span class="nf">print_predictions</span><span class="p">(</span><span class="n">sentence</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">entity</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="n">predictions</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">entity</span> <span class="o">!=</span> <span class="s1">'O'</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">entity</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span>

<span class="n">print_predictions</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
</pre></div>
<pre class="example">
Lord - B-org
Sauron, - I-org
Sunday - B-tim
morning - I-tim
July - B-tim
</pre>
<div class="highlight">
<pre><span></span><span class="n">print_predictions</span><span class="p">(</span><span class="s2">"anyone lived in a pretty how town "</span>
                  <span class="s2">"(with up so floating many bells down) "</span>
                  <span class="s2">"spring summer autumn winter "</span>
                  <span class="s2">"he sang his didn't he danced his did."</span><span class="p">)</span>
</pre></div>
<pre class="example">
summer - I-tim
autumn - I-tim
</pre>
<p>Hmm, that's interesting.</p>
<div class="highlight">
<pre><span></span><span class="n">print_predictions</span><span class="p">(</span><span class="s2">"Spring Summer Autumn Winter"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Summer - B-eve
</pre>
<p>Some kind of anti-spring bias.</p>
<div class="highlight">
<pre><span></span><span class="n">print_predictions</span><span class="p">(</span><span class="s2">"Boogie booty bunny butt"</span><span class="p">)</span>
</pre></div>
<pre class="example">
booty - B-per
</pre>
<p>Well, I suppose I'd have to match the dataset to put more weird things in there.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/ner-evaluating-the-model/index.html">NER: Evaluating the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/ner-evaluating-the-model/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-13T15:02:42-08:00" itemprop="datePublished" title="2021-01-13 15:02">2021-01-13 15:02</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/ner-evaluating-the-model/index.html#org50f1f89">Beginning</a>
<ul>
<li><a href="posts/nlp/ner-evaluating-the-model/index.html#org61bfc3c">Imports</a></li>
<li><a href="posts/nlp/ner-evaluating-the-model/index.html#orgeb9a7f9">Set Up</a>
<ul>
<li><a href="posts/nlp/ner-evaluating-the-model/index.html#orge9674b7">Plotting</a></li>
<li><a href="posts/nlp/ner-evaluating-the-model/index.html#orgbb5009e">The Previous Code</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/ner-evaluating-the-model/index.html#org6fc47c5">Middle</a>
<ul>
<li><a href="posts/nlp/ner-evaluating-the-model/index.html#orgf2c6aac">A Test Input</a></li>
<li><a href="posts/nlp/ner-evaluating-the-model/index.html#org7066a31">Plotting</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org50f1f89">
<h2 id="org50f1f89">Beginning</h2>
<div class="outline-text-2" id="text-org50f1f89">
<ul class="org-ul">
<li><a href="posts/nlp/named-entity-recognition/index.html">The First Post</a></li>
<li><a href="posts/nlp/ner-training-the-model/index.html">The Previous Post</a></li>
<li><a href="posts/nlp/ner-testing-the-model/index.html">The Next Post</a></li>
</ul>
<p>Now we'll evaluate our model using the test set. To do this we'll need to create a mask to avoid counting the padding tokens when computing the accuracy.</p>
<ul class="org-ul">
<li><b>Step 1</b>: Calling <code>model(sentences)</code> will give us the predicted output.</li>
<li><b>Step 2</b>: The output will be the prediction with an added dimension. For each word in each sentence there will be a vector of probabilities for each tag type. For each word in each sentence we'll need to pick the maximum valued tag. This will require <a href="https://numpy.org/doc/stable/reference/generated/numpy.argmax.html"><code>np.argmax</code></a> and careful use of the <code>axis</code> argument.</li>
<li><b>Step 3</b>: Create a mask to prevent counting pad characters. It will have the same dimensions as the output.</li>
<li><b>Step 4</b>: Compute the accuracy metric by comparing the outputs against the test labels. Take the sum of that and divide by the total number of <b>unpadded</b> tokens. Use the mask value to mask the padded tokens.</li>
</ul>
</div>
<div class="outline-3" id="outline-container-org61bfc3c">
<h3 id="org61bfc3c">Imports</h3>
<div class="outline-text-3" id="text-org61bfc3c">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">trax</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.named_entity_recognition</span> <span class="kn">import</span> <span class="p">(</span><span class="n">DataGenerator</span><span class="p">,</span>
                                                   <span class="n">NER</span><span class="p">,</span>
                                                   <span class="n">NERData</span><span class="p">,</span>
                                                   <span class="n">TOKEN</span><span class="p">)</span>
<span class="c1"># another project</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgeb9a7f9">
<h3 id="orgeb9a7f9">Set Up</h3>
<div class="outline-text-3" id="text-orgeb9a7f9"></div>
<div class="outline-4" id="outline-container-orge9674b7">
<h4 id="orge9674b7">Plotting</h4>
<div class="outline-text-4" id="text-orge9674b7">
<div class="highlight">
<pre><span></span><span class="n">slug</span> <span class="o">=</span> <span class="s2">"ner-evaluating-the-model"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">slug</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span> <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">])</span>
<span class="n">PLOT</span> <span class="o">=</span> <span class="n">Plot</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgbb5009e">
<h4 id="orgbb5009e">The Previous Code</h4>
<div class="outline-text-4" id="text-orgbb5009e">
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">NERData</span><span class="p">()</span><span class="o">.</span><span class="n">data</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NER</span><span class="p">(</span><span class="n">vocabulary_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">),</span>
            <span class="n">tag_count</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">tags</span><span class="p">))</span><span class="o">.</span><span class="n">model</span>

<span class="n">Settings</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Settings"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"batch_size"</span><span class="p">,</span> <span class="s2">"padding_id"</span><span class="p">,</span> <span class="s2">"seed"</span><span class="p">])</span>
<span class="n">SETTINGS</span> <span class="o">=</span> <span class="n">Settings</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                    <span class="n">padding_id</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">TOKEN</span><span class="o">.</span><span class="n">pad</span><span class="p">],</span>
                    <span class="n">seed</span><span class="o">=</span><span class="mi">33</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">init_from_file</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/ner/model.pkl.gz"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SETTINGS</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

<span class="n">test_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">x_test</span><span class="p">,</span>
                                   <span class="n">y</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">y_test</span><span class="p">,</span>
                                   <span class="n">batch_size</span><span class="o">=</span><span class="n">SETTINGS</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                   <span class="n">padding</span><span class="o">=</span><span class="n">SETTINGS</span><span class="o">.</span><span class="n">padding_id</span><span class="p">)</span>
</pre></div>
<pre class="example">
Serial[
  Embedding_35180_50
  LSTM_50
  Dense_18
  LogSoftmax
]
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org6fc47c5">
<h2 id="org6fc47c5">Middle</h2>
<div class="outline-text-2" id="text-org6fc47c5">
<p>As a reminder, here's what happens when you apply a boolean comparison to a numpy array.</p>
<div class="highlight">
<pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
<pre class="example">
[False  True False False]
</pre></div>
<div class="outline-3" id="outline-container-orgf2c6aac">
<h3 id="orgf2c6aac">A Test Input</h3>
<div class="outline-text-3" id="text-orgf2c6aac">
<div class="highlight">
<pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">test_generator</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"x's shape: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> y's shape: </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">predictions</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"predictions has shape: </span><span class="si">{</span><span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
x's shape: (64, 44) y's shape: (64, 44)
&lt;class 'jax.interpreters.xla._DeviceArray'&gt;
predictions has shape: (64, 44, 18)
</pre>
<p><b>Note:</b> the model's prediction has 3 axes:</p>
<ul class="org-ul">
<li>the number of examples</li>
<li>the number of words in each example (padded to be as long as the longest sentence in the batch)</li>
<li>the number of possible targets (the 17 named entity tags).</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">evaluate_prediction</span><span class="p">(</span><span class="n">pred</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">interpreters</span><span class="o">.</span><span class="n">xla</span><span class="o">.</span><span class="n">_DeviceArray</span><span class="p">,</span>
                        <span class="n">labels</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                        <span class="n">pad</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">SETTINGS</span><span class="o">.</span><span class="n">padding_id</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Calculates the accuracy of a prediction</span>

<span class="sd">    Args:</span>
<span class="sd">      pred: prediction array with shape </span>
<span class="sd">           (num examples, max sentence length in batch, num of classes)</span>
<span class="sd">      labels: array of size (batch_size, seq_len)</span>
<span class="sd">      pad: integer representing pad character</span>

<span class="sd">    Returns:</span>
<span class="sd">      accuracy: fraction of correct predictions</span>
<span class="sd">    """</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="n">pad</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">outputs</span><span class="o">==</span><span class="n">labels</span><span class="p">)[</span><span class="n">mask</span><span class="p">])</span><span class="o">/</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"accuracy: "</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
<pre class="example">
accuracy:  0.9636752
</pre>
<p>Hmm, does pretty good.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org7066a31">
<h3 id="org7066a31">Plotting</h3>
<div class="outline-text-3" id="text-org7066a31">
<p>Let's look at running more batches. It occurred to me that you could also just do the whole set at once, I don't know what's special about using the batches.</p>
<div class="highlight">
<pre><span></span><span class="n">repetitions</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span>
    <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">x_test</span><span class="p">)</span><span class="o">/</span><span class="n">SETTINGS</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>
<span class="n">nexts</span> <span class="o">=</span> <span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">test_generator</span><span class="p">)</span> <span class="k">for</span> <span class="n">repetition</span> <span class="ow">in</span> <span class="n">repetitions</span><span class="p">)</span>
<span class="n">accuracies</span> <span class="o">=</span> <span class="p">[</span><span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">nexts</span><span class="p">]</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Accuracy</span><span class="o">=</span><span class="n">accuracies</span><span class="p">))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Accuracy</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">tan</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Accuracy Distribution"</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">fontscale</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"accuracy_distribution"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/ner-evaluating-the-model/accuracy_distribution.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/ner-training-the-model/index.html">NER: Training the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/ner-training-the-model/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-13T15:01:58-08:00" itemprop="datePublished" title="2021-01-13 15:01">2021-01-13 15:01</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/ner-training-the-model/index.html#orgf903cf8">Training the Model</a>
<ul>
<li><a href="posts/nlp/ner-training-the-model/index.html#orgef62622">Imports</a></li>
<li><a href="posts/nlp/ner-training-the-model/index.html#org38919b2">Set Up</a>
<ul>
<li><a href="posts/nlp/ner-training-the-model/index.html#org0842213">Plotting</a></li>
<li><a href="posts/nlp/ner-training-the-model/index.html#orgdc61517">Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/ner-training-the-model/index.html#org1f6bcbf">Middle</a>
<ul>
<li><a href="posts/nlp/ner-training-the-model/index.html#orgc5cfbc2">The Data Generators</a></li>
<li><a href="posts/nlp/ner-training-the-model/index.html#orge82b8d5">Training The Model</a></li>
<li><a href="posts/nlp/ner-training-the-model/index.html#org48c4d71">Plotting the Metrics</a>
<ul>
<li><a href="posts/nlp/ner-training-the-model/index.html#org7dfdf89">Accuracy</a></li>
<li><a href="posts/nlp/ner-training-the-model/index.html#org9e50560">Plotting Loss</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgf903cf8">
<h2 id="orgf903cf8">Training the Model</h2>
<div class="outline-text-2" id="text-orgf903cf8">
<ul class="org-ul">
<li><a href="posts/nlp/named-entity-recognition/index.html">The First Post</a></li>
<li><a href="posts/nlp/ner-building-the-model/index.html">The Previous Post</a></li>
<li><a href="posts/nlp/ner-evaluating-the-model/index.html">The Next Post</a></li>
</ul>
</div>
<div class="outline-3" id="outline-container-orgef62622">
<h3 id="orgef62622">Imports</h3>
<div class="outline-text-3" id="text-orgef62622">
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">tempfile</span> <span class="kn">import</span> <span class="n">TemporaryFile</span>

<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">holoviews</span> <span class="kn">import</span> <span class="n">opts</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">trax.supervised</span> <span class="kn">import</span> <span class="n">training</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">trax</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.named_entity_recognition</span> <span class="kn">import</span> <span class="p">(</span><span class="n">DataGenerator</span><span class="p">,</span>
                                                   <span class="n">NER</span><span class="p">,</span>
                                                   <span class="n">NERData</span><span class="p">,</span>
                                                   <span class="n">TOKEN</span><span class="p">)</span>
<span class="c1"># another project</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org38919b2">
<h3 id="org38919b2">Set Up</h3>
<div class="outline-text-3" id="text-org38919b2"></div>
<div class="outline-4" id="outline-container-org0842213">
<h4 id="org0842213">Plotting</h4>
<div class="outline-text-4" id="text-org0842213">
<div class="highlight">
<pre><span></span><span class="n">slug</span> <span class="o">=</span> <span class="s2">"ner-training-the-model"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">slug</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span> <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">])</span>
<span class="n">PLOT</span> <span class="o">=</span> <span class="n">Plot</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgdc61517">
<h4 id="orgdc61517">Data</h4>
<div class="outline-text-4" id="text-orgdc61517">
<div class="highlight">
<pre><span></span><span class="n">ner</span> <span class="o">=</span> <span class="n">NERData</span><span class="p">()</span>

<span class="n">Settings</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Settings"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"seed"</span><span class="p">,</span> <span class="s2">"batch_size"</span><span class="p">,</span> <span class="s2">"embedding_size"</span><span class="p">,</span> <span class="s2">"learning_rate"</span><span class="p">])</span>
<span class="n">SETTINGS</span> <span class="o">=</span> <span class="n">Settings</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">embedding_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">trainee</span> <span class="o">=</span> <span class="n">NER</span><span class="p">(</span><span class="n">vocabulary_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">),</span>
              <span class="n">tag_count</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tags</span><span class="p">))</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SETTINGS</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

<span class="n">training_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">x_train</span><span class="p">,</span>
                                   <span class="n">y</span><span class="o">=</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span>
                                   <span class="n">batch_size</span><span class="o">=</span><span class="n">SETTINGS</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                   <span class="n">padding</span><span class="o">=</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">TOKEN</span><span class="o">.</span><span class="n">pad</span><span class="p">])</span>

<span class="n">validation_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">x_validate</span><span class="p">,</span>
                                     <span class="n">y</span><span class="o">=</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">y_validate</span><span class="p">,</span>
                                     <span class="n">batch_size</span><span class="o">=</span><span class="n">SETTINGS</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">TOKEN</span><span class="o">.</span><span class="n">pad</span><span class="p">])</span>

<span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">(</span><span class="n">speak</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org1f6bcbf">
<h2 id="org1f6bcbf">Middle</h2>
<div class="outline-text-2" id="text-org1f6bcbf"></div>
<div class="outline-3" id="outline-container-orgc5cfbc2">
<h3 id="orgc5cfbc2">The Data Generators</h3>
<div class="outline-text-3" id="text-orgc5cfbc2">
<p>Before we start, we need to create the data generators for training and validation data. It is important that you mask padding in the loss weights of your data, which can be done using the <code>id_to_mask</code> argument of <code>trax.supervised.inputs.add_loss_weights</code>.</p>
<div class="highlight">
<pre><span></span><span class="n">train_generator</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">add_loss_weights</span><span class="p">(</span>
    <span class="n">training_generator</span><span class="p">,</span>
    <span class="n">id_to_mask</span><span class="o">=</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">TOKEN</span><span class="o">.</span><span class="n">pad</span><span class="p">])</span>

<span class="n">evaluate_generator</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">add_loss_weights</span><span class="p">(</span>
    <span class="n">validation_generator</span><span class="p">,</span>
    <span class="n">id_to_mask</span><span class="o">=</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">TOKEN</span><span class="o">.</span><span class="n">pad</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orge82b8d5">
<h3 id="orge82b8d5">Training The Model</h3>
<div class="outline-text-3" id="text-orge82b8d5">
<p>You will now write a function that takes in your model and trains it.</p>
<p>As you've seen in the previous assignments, you will first create the <a href="https://trax-ml.readthedocs.io/en/stable/trax.supervised.html#trax.supervised.training.TrainTask">TrainTask</a> and <a href="https://trax-ml.readthedocs.io/en/stable/trax.supervised.html#trax.supervised.training.EvalTask">EvalTask</a> using your data generator. Then you will use the <code>training.Loop</code> to train your model.</p>
<p><b>Instructions:</b> Implement the <code>train_model</code> program below to train the neural network above. Here is a list of things you should do:</p>
<ul class="org-ul">
<li>Create the trainer object by calling <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop"><code>trax.supervised.training.Loop</code></a> and pass in the following:
<ul class="org-ul">
<li>model = NER</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask">training task</a> that uses the train data generator defined in the cell above</li>
<li>loss_layer = <a href="https://github.com/google/trax/blob/22765bb18608d376d8cd660f9865760e4ff489cd/trax/layers/metrics.py#L71">tl.CrossEntropyLoss()</a></li>
<li>optimizer = <a href="https://github.com/google/trax/blob/03cb32995e83fc1455b0c8d1c81a14e894d0b7e3/trax/optimizers/adam.py#L23">trax.optimizers.Adam(0.01)</a></li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask">evaluation task</a> that uses the validation data generator defined in the cell above
<ul class="org-ul">
<li>metrics for <code>EvalTask</code>: <code>tl.CrossEntropyLoss()</code> and <code>tl.Accuracy()</code></li>
<li>in <code>EvalTask</code> set <code>n_eval_batches=10</code> for better evaluation accuracy</li>
</ul>
</li>
<li>output_dir = output_dir</li>
</ul>
</li>
</ul>
<p>You'll be using a <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.CrossEntropyLoss">cross entropy loss</a>, with an <a href="https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html#trax.optimizers.adam.Adam">Adam optimizer</a>. Please read the <a href="https://trax-ml.readthedocs.io/en/latest/trax.html">trax</a> documentation to get a full understanding. The <a href="https://github.com/google/trax">trax GitHub</a> also contains some useful information and a link to a colab notebook.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">NER</span><span class="p">:</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">,</span>
                <span class="n">train_generator</span><span class="p">:</span> <span class="nb">type</span><span class="p">,</span>
                <span class="n">eval_generator</span><span class="p">:</span> <span class="nb">type</span><span class="p">,</span>
                <span class="n">train_steps</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">steps_per_checkpoint</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="n">SETTINGS</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">output_dir</span><span class="o">=</span><span class="s2">"~/models/ner/"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">training</span><span class="o">.</span><span class="n">Loop</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Train the Named Entity Recognition Model</span>
<span class="sd">    Args: </span>
<span class="sd">      NER: the model you are building</span>
<span class="sd">      train_generator: The data generator for training examples</span>
<span class="sd">      eval_generator: The data generator for validation examples,</span>
<span class="sd">      train_steps: number of training steps</span>
<span class="sd">      output_dir: folder to save your model</span>

<span class="sd">    Returns:</span>
<span class="sd">      training_loop: a trax supervised training Loop</span>
<span class="sd">    """</span>
    <span class="n">train_task</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">TrainTask</span><span class="p">(</span>
        <span class="n">labeled_data</span><span class="o">=</span><span class="n">train_generator</span><span class="p">,</span>
        <span class="n">loss_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">WeightedCategoryCrossEntropy</span><span class="p">(),</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">),</span>
        <span class="n">n_steps_per_checkpoint</span><span class="o">=</span><span class="n">steps_per_checkpoint</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">eval_task</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">EvalTask</span><span class="p">(</span>
      <span class="n">labeled_data</span> <span class="o">=</span> <span class="n">eval_generator</span><span class="p">,</span>
      <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="n">layers</span><span class="o">.</span><span class="n">WeightedCategoryCrossEntropy</span><span class="p">(),</span>
                 <span class="n">layers</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">()],</span>
      <span class="n">n_eval_batches</span> <span class="o">=</span> <span class="n">SETTINGS</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="p">)</span>

    <span class="n">training_loop</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">Loop</span><span class="p">(</span>
        <span class="n">NER</span><span class="p">,</span>
        <span class="n">train_task</span><span class="p">,</span>
        <span class="n">eval_tasks</span><span class="o">=</span><span class="p">[</span><span class="n">eval_task</span><span class="p">],</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Running </span><span class="si">{</span><span class="n">train_steps</span><span class="si">}</span><span class="s2"> steps"</span><span class="p">)</span>
    <span class="n">training_loop</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">n_steps</span> <span class="o">=</span> <span class="n">train_steps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">training_loop</span>
</pre></div>
<p>For some reason they don't give you the option to turn off the print statements so I'm going to suppress all stdout.</p>
<div class="highlight">
<pre><span></span><span class="n">training_steps</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">real_stdout</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span>

<span class="n">TIMER</span><span class="o">.</span><span class="n">emit</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">TIMER</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TemporaryFile</span><span class="p">(</span><span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">temp_file</span><span class="p">:</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">temp_file</span>
    <span class="n">training_loop</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">trainee</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">train_generator</span><span class="p">,</span>
                                <span class="n">evaluate_generator</span><span class="p">,</span>
                                <span class="n">steps_per_checkpoint</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                <span class="n">train_steps</span><span class="o">=</span><span class="n">training_steps</span><span class="p">,</span>
                                <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">TIMER</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">real_stdout</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">TIMER</span><span class="o">.</span><span class="n">ended</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">TIMER</span><span class="o">.</span><span class="n">started</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0:03:51.538599
</pre></div>
</div>
<div class="outline-3" id="outline-container-org48c4d71">
<h3 id="org48c4d71">Plotting the Metrics</h3>
<div class="outline-text-3" id="text-org48c4d71"></div>
<div class="outline-4" id="outline-container-org7dfdf89">
<h4 id="org7dfdf89">Accuracy</h4>
<div class="outline-text-4" id="text-org7dfdf89">
<div class="highlight">
<pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">training_loop</span><span class="o">.</span><span class="n">history</span>
<span class="n">frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eval"</span><span class="p">,</span> <span class="s2">"metrics/Accuracy"</span><span class="p">),</span>
                         <span class="n">columns</span><span class="o">=</span><span class="s2">"Batch Accuracy"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">maximum</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">Accuracy</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()]</span>
<span class="n">vline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">maximum</span><span class="o">.</span><span class="n">Batch</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">hline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">maximum</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Batch"</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="s2">"Accuracy"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
                        <span class="n">opts</span><span class="o">.</span><span class="n">Curve</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">))</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">hline</span> <span class="o">*</span> <span class="n">vline</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Evaluation Batch Accuracy"</span><span class="p">,</span>
                                   <span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"evaluation_accuracy"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/ner-training-the-model/evaluation_accuracy.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object></div>
</div>
<div class="outline-4" id="outline-container-org9e50560">
<h4 id="org9e50560">Plotting Loss</h4>
<div class="outline-text-4" id="text-org9e50560">
<div class="highlight">
<pre><span></span><span class="n">frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eval"</span><span class="p">,</span>
                                     <span class="s2">"metrics/WeightedCategoryCrossEntropy"</span><span class="p">),</span>
                         <span class="n">columns</span><span class="o">=</span><span class="s2">"Batch Loss"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">minimum</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">Loss</span><span class="o">.</span><span class="n">idxmin</span><span class="p">()]</span>
<span class="n">vline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">Batch</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">hline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">Loss</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Batch"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Loss"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">Curve</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">))</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">hline</span> <span class="o">*</span> <span class="n">vline</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Evaluation Batch Cross Entropy"</span><span class="p">,</span>
                                   <span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"evaluation_cross_entropy"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/ner-training-the-model/evaluation_cross_entropy.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So it looks like I passed the best point again and am probably overfitting. I wonder if they have a callback to grab the best model like pytorch does? I'm surprised at how fast these models train.</p>
</div>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/ner-building-the-model/index.html">NER: Building the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/ner-building-the-model/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-13T15:01:26-08:00" itemprop="datePublished" title="2021-01-13 15:01">2021-01-13 15:01</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/ner-building-the-model/index.html#orgc85e8d7">Beginning</a>
<ul>
<li><a href="posts/nlp/ner-building-the-model/index.html#org0479bd6">Imports</a></li>
<li><a href="posts/nlp/ner-building-the-model/index.html#orga2029b4">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/ner-building-the-model/index.html#org30efa7b">Middle</a>
<ul>
<li><a href="posts/nlp/ner-building-the-model/index.html#orgb21c54e">Inspecting the Model</a></li>
<li><a href="posts/nlp/ner-building-the-model/index.html#orge7e7ed0">Pack It Up for Later</a>
<ul>
<li><a href="posts/nlp/ner-building-the-model/index.html#org6c63c47">Imports</a></li>
<li><a href="posts/nlp/ner-building-the-model/index.html#org4aa1dfa">Constants</a></li>
<li><a href="posts/nlp/ner-building-the-model/index.html#orge4c45e4">The Model</a></li>
</ul>
</li>
<li><a href="posts/nlp/ner-building-the-model/index.html#orgd076117">Sanity Check</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgc85e8d7">
<h2 id="orgc85e8d7">Beginning</h2>
<div class="outline-text-2" id="text-orgc85e8d7">
<ul class="org-ul">
<li><a href="posts/nlp/named-entity-recognition/index.html">The First Post</a></li>
<li><a href="posts/nlp/ner-data/index.html">The Previous Post</a></li>
<li><a href="posts/nlp/ner-training-the-model/index.html">The Next Post</a></li>
</ul>
<p>Here we'll actually build the model.</p>
<ul class="org-ul">
<li>Feed the data into an Embedding layer, to produce more semantic entries</li>
<li>Feed it into an LSTM layer</li>
<li>Run the output through a linear layer</li>
<li>Run the result through a log softmax layer to get the predicted class for each word.</li>
</ul>
</div>
<div class="outline-3" id="outline-container-org0479bd6">
<h3 id="org0479bd6">Imports</h3>
<div class="outline-text-3" id="text-org0479bd6">
<div class="highlight">
<pre><span></span><span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.named_entity_recognition</span> <span class="kn">import</span> <span class="n">DataGenerator</span><span class="p">,</span> <span class="n">NERData</span><span class="p">,</span> <span class="n">TOKEN</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orga2029b4">
<h3 id="orga2029b4">Set Up</h3>
<div class="outline-text-3" id="text-orga2029b4">
<div class="highlight">
<pre><span></span><span class="n">ner</span> <span class="o">=</span> <span class="n">NERData</span><span class="p">()</span>

<span class="n">vocab</span> <span class="o">=</span> <span class="n">vocabulary</span> <span class="o">=</span> <span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span>
<span class="n">tag_map</span> <span class="o">=</span> <span class="n">tags</span> <span class="o">=</span> <span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tags</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org30efa7b">
<h2 id="org30efa7b">Middle</h2>
<div class="outline-text-2" id="text-org30efa7b">
<p>These are the Trax components we'll use (the links are to the implementations on Github).</p>
<ul class="org-ul">
<li><a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/combinators.py#L26">tl.Serial</a>: Combinator that applies layers serially (by function composition).</li>
<li><a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L113">tl.Embedding</a>: Initializes the embedding. In this case it is the dimension of the model by the size of the vocabulary.
<ul class="org-ul">
<li><code>tl.Embedding(vocab_size, d_feature)</code>.</li>
<li><code>vocab_size</code> is the number of unique words in the given vocabulary.</li>
<li><code>d_feature</code> is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example).</li>
</ul>
</li>
<li><a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/rnn.py#L87">tl.LSTM</a>:=Trax= LSTM layer of size d_model.
<ul class="org-ul">
<li><code>LSTM(n_units)</code> Builds an LSTM layer of n_cells.</li>
</ul>
</li>
<li><a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L28)(https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py%23L28">tl.Dense</a>: A dense layer.
<ul class="org-ul">
<li><code>tl.Dense(n_units)</code>: The parameter <code>n_units</code> is the number of units chosen for this dense layer.</li>
</ul>
</li>
<li><a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L242">tl.LogSoftmax</a>: Log of the output probabilities.
<ul class="org-ul">
<li>Here, you don't need to set any parameters for <code>LogSoftMax()</code>.</li>
</ul>
</li>
</ul>
<p><b>Online documentation</b></p>
<ul class="org-ul">
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#module-trax.layers.combinators">tl.Serial</a></li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding">tl.Embedding</a></li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTM">tl.LSTM</a></li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense">tl.Dense</a></li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax">tl.LogSoftmax</a></li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">NER</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">35181</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">tags</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="n">tag_map</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Args: </span>
<span class="sd">      vocab_size: number of words in the vocabulary</span>
<span class="sd">      d_model: the embedding size</span>

<span class="sd">    Returns:</span>
<span class="sd">       model: a trax serial model</span>
<span class="sd">    """</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_feature</span><span class="o">=</span><span class="n">d_model</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">d_model</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_units</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">tag_map</span><span class="p">)),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">()</span>
      <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgb21c54e">
<h3 id="orgb21c54e">Inspecting the Model</h3>
<div class="outline-text-3" id="text-orgb21c54e">
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">NER</span><span class="p">()</span>
<span class="c1"># display your model</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example">
Serial[
  Embedding_35181_50
  LSTM_50
  Dense_18
  LogSoftmax
]
</pre></div>
</div>
<div class="outline-3" id="outline-container-orge7e7ed0">
<h3 id="orge7e7ed0">Pack It Up for Later</h3>
<div class="outline-text-3" id="text-orge7e7ed0"></div>
<div class="outline-4" id="outline-container-org6c63c47">
<h4 id="org6c63c47">Imports</h4>
<div class="outline-text-4" id="text-org6c63c47">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="kn">import</span> <span class="nn">attr</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4aa1dfa">
<h4 id="org4aa1dfa">Constants</h4>
<div class="outline-text-4" id="text-org4aa1dfa">
<div class="highlight">
<pre><span></span><span class="n">Settings</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Settings"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"embeddings_size"</span><span class="p">])</span>
<span class="n">SETTINGS</span> <span class="o">=</span> <span class="n">Settings</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge4c45e4">
<h4 id="orge4c45e4">The Model</h4>
<div class="outline-text-4" id="text-orge4c45e4">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">NER</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""The named entity recognition model</span>

<span class="sd">    Args:</span>
<span class="sd">     vocabulary_size: number of tokens in the vocabulary</span>
<span class="sd">     tag_count: number of tags</span>
<span class="sd">     embeddings_size: the number of features in the embeddings layer</span>
<span class="sd">    """</span>
    <span class="n">vocabulary_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">tag_count</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">embeddings_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">SETTINGS</span><span class="o">.</span><span class="n">embeddings_size</span>
    <span class="n">_model</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org600177f"></a>The Actual Model<br>
<div class="outline-text-5" id="text-org600177f">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""The NER model instance"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_size</span><span class="p">,</span>
                             <span class="n">d_feature</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings_size</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings_size</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_count</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">()</span>
      <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-orgd076117">
<h3 id="orgd076117">Sanity Check</h3>
<div class="outline-text-3" id="text-orgd076117">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.named_entity_recognition</span> <span class="kn">import</span> <span class="n">NER</span>

<span class="n">builder</span> <span class="o">=</span> <span class="n">NER</span><span class="p">(</span><span class="mi">122</span><span class="p">,</span> <span class="mi">666</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">builder</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example">
Serial[
  Embedding_122_50
  LSTM_50
  Dense_666
  LogSoftmax
]
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/ner-data/index.html">NER: Data</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/ner-data/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-13T15:00:14-08:00" itemprop="datePublished" title="2021-01-13 15:00">2021-01-13 15:00</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/ner-data/index.html#org9679649">The Data</a>
<ul>
<li><a href="posts/nlp/ner-data/index.html#org8937f89">Imports</a></li>
<li><a href="posts/nlp/ner-data/index.html#orge3e4a5b">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/ner-data/index.html#orga194042">Middle</a>
<ul>
<li><a href="posts/nlp/ner-data/index.html#orgba60b83">Reviewing The Dataset</a></li>
<li><a href="posts/nlp/ner-data/index.html#org9531ca8">A Data Generator</a></li>
</ul>
</li>
<li><a href="posts/nlp/ner-data/index.html#org85b2469">Bundle It Up</a>
<ul>
<li><a href="posts/nlp/ner-data/index.html#org34507d7">Imports</a></li>
<li><a href="posts/nlp/ner-data/index.html#org49ec067">Some Types</a></li>
<li><a href="posts/nlp/ner-data/index.html#org2635538">The Data Generator</a>
<ul>
<li><a href="posts/nlp/ner-data/index.html#org756294c">The Batch Generator</a></li>
<li><a href="posts/nlp/ner-data/index.html#org2460b59">The Generator Method</a></li>
<li><a href="posts/nlp/ner-data/index.html#orgc7414ba">The Iterator Method</a></li>
<li><a href="posts/nlp/ner-data/index.html#orgda8ec9c">The Next Method</a></li>
</ul>
</li>
<li><a href="posts/nlp/ner-data/index.html#org03f505e">Test It</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org9679649">
<h2 id="org9679649">The Data</h2>
<div class="outline-text-2" id="text-org9679649">
<ul class="org-ul">
<li><a href="posts/nlp/named-entity-recognition/index.html">The First Post</a></li>
<li><a href="posts/nlp/ner-pre-processing-the-data/index.html">The Previous Post</a></li>
<li><a href="posts/nlp/ner-building-the-model/index.html">The Next Post</a></li>
</ul>
</div>
<div class="outline-3" id="outline-container-org8937f89">
<h3 id="org8937f89">Imports</h3>
<div class="outline-text-3" id="text-org8937f89">
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.named_entity_recognition</span> <span class="kn">import</span> <span class="n">NERData</span><span class="p">,</span> <span class="n">TOKEN</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orge3e4a5b">
<h3 id="orge3e4a5b">Set Up</h3>
<div class="outline-text-3" id="text-orge3e4a5b">
<div class="highlight">
<pre><span></span><span class="n">ner</span> <span class="o">=</span> <span class="n">NERData</span><span class="p">()</span>

<span class="c1"># to make the functions pass we need to use their names (initially)</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">vocabulary</span> <span class="o">=</span> <span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">vocabulary</span>
<span class="n">tag_map</span> <span class="o">=</span> <span class="n">tags</span> <span class="o">=</span> <span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tags</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orga194042">
<h2 id="orga194042">Middle</h2>
<div class="outline-text-2" id="text-orga194042"></div>
<div class="outline-3" id="outline-container-orgba60b83">
<h3 id="orgba60b83">Reviewing The Dataset</h3>
<div class="outline-text-3" id="text-orgba60b83">
<p>As a review we can look at what's in the vocabulary.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">[</span><span class="s2">"the"</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">TOKEN</span><span class="o">.</span><span class="n">pad</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">[</span><span class="s2">"The"</span><span class="p">])</span>
</pre></div>
<pre class="example">
9
35178
61
</pre>
<p>The vocabulary maps words in our vocabulary to unique integers. As you can see, we made it case-sensitive.</p>
<p>We also made a map for tags.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">tag</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">tags</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" - </span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orge4f043b">
- O: 0
- B-geo: 1
- B-gpe: 2
- B-per: 3
- I-geo: 4
- B-org: 5
- I-org: 6
- B-tim: 7
- B-art: 8
- I-art: 9
- I-per: 10
- I-gpe: 11
- I-tim: 12
- B-nat: 13
- B-eve: 14
- I-eve: 15
- I-nat: 16
- UNK: 17
</pre>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Prefix</th>
<th class="org-left" scope="col">Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">B</td>
<td class="org-left">Token Begins an entity</td>
</tr>
<tr>
<td class="org-left">I</td>
<td class="org-left">Token is Inside an entity</td>
</tr>
</tbody>
</table>
<p>This is to help when you have multi-token entities. So if you had the name "Burt Reynolds", "Burt" would be tagged <code>B-per</code> and "Reynolds" would be tagged "I-per".</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The number of tags is </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tag_map</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The vocabulary size is </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The training size is </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">x_train</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The validation size is </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">x_validate</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"The first training sentence is "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"'</span><span class="si">{</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">raw_data_sets</span><span class="o">.</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">'"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Its corresponding label is"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" '</span><span class="si">{</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">raw_data_sets</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">'"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"The first training encoded sentence is "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Its corresponding encoded label is"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org87d1a3b">
The number of tags is 18
The vocabulary size is 35,180
The training size is 33,570
The validation size is 7,194
The first training sentence is 
'Opposition leader Michael Howard said he hopes the government in coming weeks will try to uncover possible security flaws exploited in the attacks .'
Its corresponding label is
 'O O B-per I-per O O O O O O O O O O O O O O O O O O O O'
The first training encoded sentence is 
[7848, 538, 5951, 6187, 172, 502, 2453, 9, 293, 11, 5306, 822, 141, 1962, 7, 26689, 1176, 686, 11905, 14806, 11, 9, 292, 21]
Its corresponding encoded label is
[0, 0, 3, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
</pre></div>
</div>
<div class="outline-3" id="outline-container-org9531ca8">
<h3 id="org9531ca8">A Data Generator</h3>
<div class="outline-text-3" id="text-org9531ca8">
<p>The generator will have a main outer loop:</p>
<pre class="example" id="org361d5b2">
while True:  
    yield((X,Y))  
</pre>
<p>runs continuously in the fashion of generators, pausing when yielding the next values. We will generate a batch_size output on each pass of this loop.</p>
<p>It has two inner loops.</p>
<ol class="org-ol">
<li>The first stores in temporal lists the data samples to be included in the next batch, and finds the maximum length of the sentences contained in it. By adjusting the length to include only the size of the longest sentence in each batch, overall computation is reduced.</li>
<li>The second loop moves those inputs from the temporal list into NumPy arrays pre-filled with pad values.</li>
</ol>
<p>There are three slightly out of the ordinary features.</p>
<ol class="org-ol">
<li>The first is the use of the NumPy <code>full</code> function to fill the NumPy arrays with a pad value. See <a href="https://numpy.org/doc/1.18/reference/generated/numpy.full.html"><code>full</code> function documentation</a>.</li>
<li>The second is tracking the current location in the incoming lists of sentences. Generators variables hold their values between invocations, so we create an <code>index</code> variable, initialize to zero, and increment by one for each sample included in a batch. However, we do not use the <code>index</code> to access the positions of the list of sentences directly. Instead, we use it to select one index from a list of indexes. In this way, we can change the order in which we traverse our original list, keeping untouched our original list.</li>
<li>The third also relates to wrapping. Because <code>batch_size</code> and the length of the input lists are not aligned, gathering a batch_size group of inputs may involve wrapping back to the beginning of the input loop. In our approach, it is just enough to reset the <code>index</code> to 0. We can re-shuffle the list of indexes to produce different batches each time.</li>
</ol>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">data_generator</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">pad</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                   <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Generate batches of data for training</span>

<span class="sd">    Args: </span>
<span class="sd">      batch_size - size of each batch generated</span>
<span class="sd">      x - sentences where words are represented as integers</span>
<span class="sd">      y - tags associated with the sentences</span>
<span class="sd">      pad - number to use as the padding character</span>
<span class="sd">      shuffle - Whether to shuffle the data</span>
<span class="sd">      verbose - Whether to print information to stdout</span>

<span class="sd">    Yields:</span>
<span class="sd">     a tuple containing 2 elements:</span>
<span class="sd">       X - np.ndarray of dim (batch_size, max_len) of padded sentences</span>
<span class="sd">       Y - np.ndarray of dim (batch_size, max_len) of tags associated with the sentences in X</span>
<span class="sd">    """</span>    
    <span class="c1"># count the number of lines in data_lines</span>
    <span class="n">num_lines</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># create an array with the indexes of data_lines that can be shuffled</span>
    <span class="n">lines_index</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_lines</span><span class="p">))</span>

    <span class="c1"># shuffle the indexes if shuffle is set to True</span>
    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">lines_index</span><span class="p">)</span>

    <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># tracks current location in x, y</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">buffer_x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="n">buffer_y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="n">max_len</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
             <span class="c1"># if the index is greater than or equal to the number of lines in x</span>
            <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;=</span> <span class="n">num_lines</span><span class="p">:</span>
                <span class="c1"># then reset the index to 0</span>
                <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="c1"># re-shuffle the indexes if shuffle is set to True</span>
                <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
                    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">lines_index</span><span class="p">)</span>

            <span class="c1"># The current position is obtained using `lines_index[index]`</span>
            <span class="c1"># Store the x value at the current position into the buffer_x</span>
            <span class="n">buffer_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">lines_index</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span>

            <span class="c1"># Store the y value at the current position into the buffer_y</span>
            <span class="n">buffer_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">lines_index</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span>

            <span class="n">lenx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">buffer_x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>    <span class="c1">#length of current x[]</span>
            <span class="k">if</span> <span class="n">lenx</span> <span class="o">&gt;</span> <span class="n">max_len</span><span class="p">:</span>
                <span class="n">max_len</span> <span class="o">=</span> <span class="n">lenx</span>                   <span class="c1">#max_len tracks longest x[]</span>

            <span class="c1"># increment index by one</span>
            <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>


        <span class="c1"># create X,Y, NumPy arrays of size (batch_size, max_len) 'full' of pad value</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_len</span><span class="p">),</span> <span class="n">pad</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_len</span><span class="p">),</span> <span class="n">pad</span><span class="p">)</span>

        <span class="c1"># copy values from lists to NumPy arrays. Use the buffered values</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="c1"># get the example (sentence as a tensor)</span>
            <span class="c1"># in `buffer_x` at the `i` index</span>
            <span class="n">x_i</span> <span class="o">=</span> <span class="n">buffer_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># similarly, get the example's labels</span>
            <span class="c1"># in `buffer_y` at the `i` index</span>
            <span class="n">y_i</span> <span class="o">=</span> <span class="n">buffer_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="c1"># Walk through each word in x_i</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_i</span><span class="p">)):</span>
                <span class="c1"># store the word in x_i at position j into X</span>
                <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

                <span class="c1"># store the label in y_i at position j into Y</span>
                <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">"index="</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
        <span class="k">yield</span><span class="p">((</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">mini_sentences</span> <span class="o">=</span> <span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span> <span class="mi">8</span><span class="p">]</span>
<span class="n">mini_labels</span> <span class="o">=</span> <span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span> <span class="mi">8</span><span class="p">]</span>
<span class="n">dg</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">mini_sentences</span><span class="p">,</span> <span class="n">mini_labels</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="s2">"&lt;PAD&gt;"</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">Y1</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dg</span><span class="p">)</span>
<span class="n">X2</span><span class="p">,</span> <span class="n">Y2</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Y1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X1</span><span class="p">[</span><span class="mi">0</span><span class="p">][:],</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">Y1</span><span class="p">[</span><span class="mi">0</span><span class="p">][:])</span>
</pre></div>
<pre class="example">
index= 5
index= 2
(5, 27) (5, 27) (5, 24) (5, 24)
[ 7848   538  5951  6187   172   502  2453     9   293    11  5306   822
   141  1962     7 26689  1176   686 11905 14806    11     9   292    21
 35178 35178 35178] 
 [    0     0     3    10     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
 35178 35178 35178]
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org85b2469">
<h2 id="org85b2469">Bundle It Up</h2>
<div class="outline-text-2" id="text-org85b2469"></div>
<div class="outline-3" id="outline-container-org34507d7">
<h3 id="org34507d7">Imports</h3>
<div class="outline-text-3" id="text-org34507d7">
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org49ec067">
<h3 id="org49ec067">Some Types</h3>
<div class="outline-text-3" id="text-org49ec067">
<div class="highlight">
<pre><span></span><span class="n">Vectors</span> <span class="o">=</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span>
<span class="n">Batch</span> <span class="o">=</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org2635538">
<h3 id="org2635538">The Data Generator</h3>
<div class="outline-text-3" id="text-org2635538">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DataGenerator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""A generator of data to train the NER Model</span>

<span class="sd">    Args:</span>
<span class="sd">     batch_size: how many lines to generate at once</span>
<span class="sd">     x: the encoded sentences</span>
<span class="sd">     y: the encoded labels </span>
<span class="sd">     padding: encoding to use for padding lines</span>
<span class="sd">     shuffle: whether to shuffle the data</span>
<span class="sd">     verbose: whether to print messages to stdout</span>
<span class="sd">    """</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">Vectors</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">Vectors</span>
    <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span>
    <span class="n">_batch</span><span class="p">:</span> <span class="nb">iter</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org756294c">
<h4 id="org756294c">The Batch Generator</h4>
<div class="outline-text-4" id="text-org756294c">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">batch_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Generates batches"""</span>
    <span class="n">line_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
    <span class="n">line_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">line_count</span><span class="p">))</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">line_indices</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="n">longest</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">batch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;=</span> <span class="n">line_count</span><span class="p">:</span>
                <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
                    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">line_indices</span><span class="p">)</span>

            <span class="n">x_batch</span><span class="p">[</span><span class="n">batch_index</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">line_indices</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span>
            <span class="n">y_batch</span><span class="p">[</span><span class="n">batch_index</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">line_indices</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span>

            <span class="n">longest</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">longest</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_batch</span><span class="p">[</span><span class="n">batch_index</span><span class="p">]))</span>
            <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">longest</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">longest</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">batch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span> 
            <span class="n">line</span> <span class="o">=</span> <span class="n">x_batch</span><span class="p">[</span><span class="n">batch_index</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">y_batch</span><span class="p">[</span><span class="n">batch_index</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)):</span>
                <span class="n">X</span><span class="p">[</span><span class="n">batch_index</span><span class="p">,</span> <span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
                <span class="n">Y</span><span class="p">[</span><span class="n">batch_index</span><span class="p">,</span> <span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">label</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"index="</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
        <span class="k">yield</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
    <span class="k">return</span>    
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2460b59">
<h4 id="org2460b59">The Generator Method</h4>
<div class="outline-text-4" id="text-org2460b59">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""The instance of the generator"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_generator</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc7414ba">
<h4 id="orgc7414ba">The Iterator Method</h4>
<div class="outline-text-4" id="text-orgc7414ba">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgda8ec9c">
<h4 id="orgda8ec9c">The Next Method</h4>
<div class="outline-text-4" id="text-orgda8ec9c">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Batch</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org03f505e">
<h3 id="org03f505e">Test It</h3>
<div class="outline-text-3" id="text-org03f505e">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.named_entity_recognition</span> <span class="kn">import</span> <span class="n">DataGenerator</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">],</span>
                          <span class="n">y</span><span class="o">=</span><span class="n">ner</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_sets</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span> <span class="mi">8</span><span class="p">],</span>
                          <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                          <span class="n">padding</span><span class="o">=</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">TOKEN</span><span class="o">.</span><span class="n">pad</span><span class="p">])</span>

<span class="n">X1</span><span class="p">,</span> <span class="n">Y1</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
<span class="n">X2</span><span class="p">,</span> <span class="n">Y2</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Y1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X1</span><span class="p">[</span><span class="mi">0</span><span class="p">][:],</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">Y1</span><span class="p">[</span><span class="mi">0</span><span class="p">][:])</span>
</pre></div>
<pre class="example">
(5, 27) (5, 27) (5, 24) (5, 24)
[ 7848   538  5951  6187   172   502  2453     9   293    11  5306   822
   141  1962     7 26689  1176   686 11905 14806    11     9   292    21
 35178 35178 35178] 
 [    0     0     3    10     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
 35178 35178 35178]
</pre></div>
</div>
</div>
</div>
</article>
</div>
<ul class="pager postindexpager clearfix">
<li class="previous"><a href="index-20.html" rel="prev">Newer posts</a></li>
<li class="next"><a href="index-18.html" rel="next">Older posts</a></li>
</ul>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script><!--End of body content-->
<footer id="footer">Scribbles by <a href="mailto:cloisteredmonkey.jmark@slmail.me">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>
<div id="license" xmlns:cc="http://creativecommons.org/ns#">This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" rel="license noopener noreferrer" style="display:inline-block;" target="_blank">CC BY 4.0 <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></div>
</footer>
</div>
</div>
<script src="assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
