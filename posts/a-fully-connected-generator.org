#+BEGIN_COMMENT
.. title: A Fully Connected Generator
.. slug: a-fully-connected-generator
.. date: 2023-07-01 15:51:10 UTC-07:00
.. tags: gans
.. category: GANs
.. link: 
.. description: A fully connected Generator for GANs.
.. type: text

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 3
#+PROPERTY: header-args :session ~/.local/share/jupyter/runtime/kernel-0a799e7d-36f7-47a5-9e30-c69570bfcaf5.json

* The Fully Connected Generator Factory

The ~GeneratorFactory~ builds the fully-connected Generator.

#+begin_src plantuml :file ../files/posts/a-fully-connected-generator/fully-connected-factory.png :exports none
!theme mars

class GeneratorFactory {
  input_size: Integer
  output_size: Integer
  hidden_layer_size: Integer
  block_count: Integer
  size_multiplier: Integer
  generator : nn.Sequential

  block(input_size: Integer, output_size: Integer) : nn.Sequential
}
#+end_src

#+RESULTS:
[[file:../files/posts/a-fully-connected-generator/fully-connected-factory.png]]

** The Factory
 #+begin_src plantuml :file ../files/posts/a-fully-connected-generator/fully-connected.png :exports none
!theme mars

class GeneratorFactory {
    input_size: Integer
    hidden_size: Integer
    output_size: Integer
    block_count: Integer
    size_multiplier: Integer
    generator: FullyConnectedGenerator
    block(input_size: Integer, output_size: Integer): Sequential

}
#+end_src

#+begin_src python :tangle ../neurotic/gans/fully_connected.py :exports none
# python
<<factory-python-imports>>

# pypi
<<factory-pypi-imports>>

<<generator-defaults>>


<<generator-factory>>

    <<factory-block-method>>


    <<factory-blocks-property>>
#+end_src

*** Python Imports

#+begin_src python :noweb-ref factory-python-imports
from dataclasses import dataclass
#+end_src

| Item        | Documentation |
|-------------+---------------|
| ~dataclass~ | [[https://docs.python.org/3/library/dataclasses.html][dataclasses]]   |

*** PyPi Imports

#+begin_src python :noweb-ref factory-pypi-imports
from torch import nn
#+end_src

*** Generator Defaults
The GeneratorDefault class is a [[https://docs.python.org/3/library/dataclasses.html][python dataclass]] to hold the default values for the generator.

#+begin_src python :noweb-ref generator-defaults
@dataclass
class GeneratorDefault:
    """Default values for the generator"""
    input_size: int=10
    hidden_layer_size: int=128
    output_size: int=784
    block_count: int=4
    size_multiplier: int=2
#+end_src

| Attribute         | Description                                                   |
|-------------------+---------------------------------------------------------------|
| input_size        | length of input to the network (presumed 10 is for 10 digits) |
| hidden_layer_size | length of output for first layer                              |
| output_size       | length of the output image                                    |
| block_count       | Number of Linear blocks for the generator                     |
| size_multiplier   | Amount hidden layer output multiplies by for each block       |

#+begin_notecard
The ~output_size~ is based on the MNIST images which are 28 pixels x 28 pixels which when flattened out to a one-dimensional vector ends up as 784 pixels.
#+end_notecard

*** The Generator Factory Definition

#+begin_src python :noweb-ref generator-factory
class GeneratorFactory:
    """Builder of fully-connected generators

    Args:

     input_size: length for the input noise-vector
     hidden_layer_size: length of output for first layer
     output_size: the length of the output image vector
     block_count: how many linear-norm-relu blocks to give the generator
     size_multiplier: how much to multiply hidden layer by for each block
    """
    def __init__(self, input_size: int=GeneratorDefault.input_size,
                 hidden_layer_size: int=GeneratorDefault.hidden_layer_size,
                 output_size: int=GeneratorDefault.output_size,
                 block_count: int=GeneratorDefault.block_count,
                 size_multiplier: int=GeneratorDefault.size_multiplier):
        self.input_size = input_size
        self.hidden_layer_size = hidden_layer_size
        self.output_size = output_size
        self.block_count = block_count
        self.size_multiplier = size_multiplier
        self._blocks = None
        return
#+end_src

**** The Block Creation Method

#+begin_src python :noweb-ref factory-block-method
def block(self, input_size: int, output_size: int) -> nn.Sequential:
    """Create a linear block for the generator

    Args:
     - `input_size`: vector size for the input to the linear layer
     - `output_size`: vector size for the output

    Returns:
     - Sequential generator block
    """
    return nn.Sequential(
        nn.Linear(input_size, output_size),
        nn.BatchNorm1d(output_size),
        nn.ReLU(inplace=True),
    )
#+end_src

#+begin_notecard
**Note:** The default for ~ReLU~ is ~inplace=True~, but according to this [[https://discuss.pytorch.org/t/guidelines-for-when-and-why-one-should-set-inplace-true/50923][post on pytorch's forum]] you can use ~inplace=True~ to save memory if it doesn't produce an error and you don't need the values that you had before applying the ReLU. Confusingly, though, the [[https://pytorch.org/docs/master/notes/autograd.html#in-place-operations-with-autograd][Autograd  Documentation]] suggests you never use ~inplace=True~ since it doesn't save much memory and can cause problems for Autograd. Hmm...
#+end_notecard

**** The Blocks Property

#+begin_src python :noweb-ref factory-blocks-property
@property
def blocks(self) -> nn.Sequential: 
   """Creates the network for the generator


    Returns:
     sequence of generator blocks with Linear and Sigmoid tail
    """
   if self._blocks is None:
      self._blocks = nn.Sequential(
         self.block(2, 2),
         self.block(2, 2),
         self.block(2, 2),
         self.block(2, 2),
         nn.Linear(self.hidden_layer_size * 8,
                   self.output_size),
         nn.Sigmoid()
      )
   return self._blocks
#+end_src

* The Fully Connected Generator
 #+begin_src plantuml :file ../files/posts/a-fully-connected-generator/fully-connected.png :exports none
!theme mars

class FullyConnectedGenerator {
 generator: Sequential
 forward(noise: torch.Tensor) : torch.Tensor
}

nn.Sequential o- FullyConnected
nn.Module <|-- FullyConnected
 #+end_src

 #+RESULTS:
 [[file:../files/posts/a-fully-connected-generator/fully-connected.png]]

 [[img-url: fully-connected.png]]

* Testing the Factory
#+begin_src gherkin :tangle ../tests/features/fully_connected/generator_factory.feature
Feature: A Fully Connected Generator factory
  A builder of fully-connected multi-layer perceptrons to generate images.

Scenario: The default fully-connected generator factory
  Given a default fully-connected-generator-factory
  When the input_size is checked
  And the hidden_size is checked
  And the output_size is checked
  And the block_count is checked
  And the size_multiplier is checked

  Then the input_size is the default
  And the hidden_size is the default
  And the image_size is the default
  And the block_count is the default
  And the size_multiplier is the default

Scenario: The Default Factory Builds a Block
  Given a default fully-connected-generator-factory
  When the block method is called
  Then the block output is a Sequential
  And the block output has three layers
  And the block output has the expected Linear layer
  And the block output has the expected Normalization Layer
  And the block output has the expected activation layer

Scenario: The Default Factory Builds the Blocks
  Given a default fully-connected-generator-factory
  When the blocks property is checked
  Then the blocks are a Sequential
  And the blocks have the right number of layers
  And all but the last two blocks layers match the block call
  And the second to the last blocks layer is a linear layer
  And the blocks linear layer has the right input and output dimensions
  And the last blocks layer is a sigmoid

Scenario: The Factory Builds With No Generator Blocks
  Given a fully-connected-generator-factory with no block_count
  When the blocks property is checked
#  Then the blocks have the right number of layers
#  And the blocks linear layer has the right input and output dimensions
#  And the second to the last blocks layer is a linear layer
#  And the last blocks layer is a sigmoid
#+end_src

#+begin_src python :tangle ../tests/functional/fully_connected/test_generator_factory.py :exports none
"""Fully Connected Generator factory feature tests."""
# python

<<python-testing-imports>>
# from pypi

<<pypi-testing-imports>>

# the software under test
<<factory-import>>


<<fake-sequential>>


<<scenarios>>

#* Scenario: The default fully-connected generator factory *#

<<given-default-factory>>


<<check-input-size>>


<<check-hidden-size>>


<<check-output-size>>


<<check-block-count>>


<<check-size-multiplier>>


<<default-input-size>>


<<default-hidden-size>>


<<default-output-size>>


<<default-block-count>>


<<default-size-multiplier>>

#* Scenario: The Default Factory Builds a Block *#

#**  Given a default fully-connected-generator-factory

<<call-block-method>>


<<check-block>>


<<check-block-length>>


<<check-linear>>


<<check-normalization-layer>>


<<check-activation-layer>>


#** Scenario: The Default Factory Builds the Blocks **#

#  Given a default fully-connected-generator-factory


<<get-blocks-property>>


<<check-blocks-are-sequential>>


<<check-blocks-layer-count>>


<<check-blocks-block-layers>>


<<check-second-to-the-last-layer>>


<<check-second-to-last-input-and-output>>


<<check-last-layer-is-sigmoid>>


#** Scenario: The Factory Builds With No Generator Blocks **#

<<create-factory-with-zero-block-count>>

#  When the blocks property is checked
#  Then the blocks have the right number of layers
#  And the blocks linear layer has the right input and output dimensions
#  And the second to the last blocks layer is a linear layer
#  And the last blocks layer is a sigmoid
#+end_src
** The imports
*** From Python

#+begin_src python :noweb-ref python-testing-imports
import random
#+end_src

*** From PyPi
#+begin_src python :noweb-ref pypi-testing-imports
from expects import (
    be_a,
    be_true,
    equal,
    expect,
    have_length,
)

from pytest_bdd import (
    given,
    scenarios,
    then,
    when,
)

from torch import nn

# this project (testing only)
from ..fixtures import katamari


and_when = when
And = then
#+end_src

** The Factory Import

#+begin_src python :noweb-ref factory-import
from neurotic.gans.fully_connected import (GeneratorDefault,
                                           GeneratorFactory)
#+end_src
** Set the Feature File
#+begin_src python :noweb-ref scenarios
scenarios("fully_connected/generator_factory.feature")
#+end_src

** The Fake Sequential

This is a fake-Sequential object to test the blocks property.

#+begin_src python :noweb-ref fake-sequential
class FakeSequential(nn.Module):
    """A fake module to check blocks"""
#+end_src
** The Default Factory Scenario

*** The Default Fully Connected Generator Factory

#+begin_src python :noweb-ref given-default-factory
@given("a default fully-connected-generator-factory",
       target_fixture="factory")
def _():
    return GeneratorFactory()
#+end_src

*** Check the Input Size
#+begin_src python :noweb-ref check-input-size
@when("the input_size is checked", target_fixture="input_size")
def _(factory):
    return factory.input_size
#+end_src

*** Default Input Size

#+begin_src python :noweb-ref default-input-size
@then('the input_size is the default')
def _(input_size):
    expect(input_size).to(equal(GeneratorDefault.input_size))
    return
#+end_src

*** Check Hidden Layer Size

#+begin_src python :noweb-ref check-hidden-size
@and_when("the hidden_size is checked", target_fixture="hidden_size")
def _(factory):
    return factory.hidden_layer_size
#+end_src
*** Default Hidden Layer Size

#+begin_src python :noweb-ref default-hidden-size
@then("the hidden_size is the default")
def _(hidden_size):
    expect(hidden_size).to(equal(GeneratorDefault.hidden_layer_size))
#+end_src
*** Check the Output Image Size

#+begin_src python :noweb-ref check-output-size
@and_when("the output_size is checked", target_fixture="output_size")
def _(factory):
    return factory.output_size
#+end_src
*** Default Output Image Size

#+begin_src python :noweb-ref default-output-size
@then("the image_size is the default")
def _(output_size):
    expect(output_size).to(equal(GeneratorDefault.output_size))
#+end_src
*** Check the Block Count

#+begin_src python :noweb-ref check-block-count
@and_when("the block_count is checked", target_fixture="block_count")
def _(factory):
    return factory.block_count
#+end_src
*** Default Block Count

#+begin_src python :noweb-ref default-block-count
@then("the block_count is the default")
def _(block_count):
    expect(block_count).to(equal(GeneratorDefault.block_count))
#+end_src
*** Check the Size Multiplier

#+begin_src python :noweb-ref check-size-multiplier
@and_when("the size_multiplier is checked", target_fixture="size_multiplier")
def _(factory):
    return factory.size_multiplier
#+end_src

*** Default Size Multiplier

#+begin_src python :noweb-ref default-size-multiplier
@then("the size_multiplier is the default")
def _(size_multiplier):
    expect(size_multiplier).to(equal(GeneratorDefault.size_multiplier))
    return
#+end_src
** The Block Method Call Scenario
*** Call the Block

#+begin_src python :noweb-ref call-block-method
@when("the block method is called" , target_fixture="block_output")
def _(factory, katamari):
    katamari.input_size = random.randrange(10, 100)
    katamari.output_size = random.randrange(10, 100)
    katamari.output = factory.block(input_size=katamari.input_size,
                                    output_size=katamari.output_size)
    return katamari
#+end_src

*** Check the Block

#+begin_src python :noweb-ref check-block
@then("the block output is a Sequential")
def _(block_output):
    expect(block_output.output).to(be_a(nn.Sequential))
    return
#+end_src

*** Check The Number Of Layers

#+begin_src python :noweb-ref check-block-length
@And("the block output has three layers")
def _(block_output):
    expect(block_output.output).to(have_length(3))
    return
#+end_src

*** Check The linear Layer

#+begin_src python :noweb-ref check-linear
@And("the block output has the expected Linear layer")
def _(block_output):
    first_layer = block_output.output[0]
    expect(first_layer).to(be_a(nn.Linear))
    expect(first_layer.in_features).to(equal(block_output.input_size))
    expect(first_layer.out_features).to(equal(block_output.output_size))
    return
#+end_src

*** Check the Normalization Layer

#+begin_src python :noweb-ref check-normalization-layer
@And("the block output has the expected Normalization Layer")
def _(block_output):
    second_layer = block_output.output[1]
    expect(second_layer).to(be_a(nn.BatchNorm1d))
    expect(second_layer.num_features).to(equal(block_output.output_size))
    return
#+end_src

*** Check the Activation Layer

#+begin_src python :noweb-ref check-activation-layer
@And("the block output has the expected activation layer")
def _(block_output):
    third_layer = block_output.output[2]
    expect(third_layer).to(be_a(nn.ReLU))
    expect(third_layer.inplace).to(be_true)
    return
#+end_src

** The Blocks Property Scenario

*** Get the Blocks

#+begin_src python :noweb-ref get-blocks-property
@when("the blocks property is checked", target_fixture="blocks")
def _(factory, monkeypatch):
    def mock_blocks(input_size, output_size):
        return FakeSequential()
    monkeypatch.setattr(factory, "block", mock_blocks)
    return factory.blocks
#+end_src

*** Check the Blocks are Sequential

#+begin_src python :noweb-ref check-blocks-are-sequential
@then("the blocks are a Sequential")
def _(blocks):
    expect(blocks).to(be_a(nn.Sequential))
    return
#+end_src

*** Check the Blocks Layer Count

#+begin_src python :noweb-ref check-blocks-layer-count
@And("the blocks have the right number of layers")
def _(blocks):
    expect(blocks).to(have_length(GeneratorDefault.block_count + 2))
    return
#+end_src

*** Check the Blocks Blocks

#+begin_src python :noweb-ref check-blocks-block-layers
@And("all but the last two blocks layers match the block call")
def _(blocks):
    for layer in blocks[:-2]:
        expect(layer).to(be_a(FakeSequential))
    return
#+end_src

*** Check the Second to the Last Layer

#+begin_src python :noweb-ref check-second-to-the-last-layer
@And("the second to the last blocks layer is a linear layer")
def _(blocks):
    expect(blocks[-2]).to(be_a(nn.Linear))
    return
#+end_src

*** Check Second to Last Layer Input and Output

#+begin_src python :noweb-ref check-second-to-last-input-and-output
@And("the blocks linear layer has the right input and output dimensions")
def _(blocks):
    almost_last = blocks[-2]
    expect(almost_last.in_features).to(equal(GeneratorDefault.hidden_layer_size * 8))
    expect(almost_last.out_features).to(equal(GeneratorDefault.output_size))
    return
#+end_src

*** Check the Last Blocks Layer

#+begin_src python :noweb-ref check-last-layer-is-sigmoid
@And("the last blocks layer is a sigmoid")
def _(blocks):
    expect(blocks[-1]).to(be_a(nn.Sigmoid))
    return
#+end_src

** Scenario: No Block Count

#+begin_src python :noweb-ref create-factory-with-zero-block-count
@given("a fully-connected-generator-factory with no block_count",
       target_fixture="blocks")
def _(katamari):
    return
#+end_src
* Testing The Generator
#+begin_src gherkin  :tangle ../tests/features/fully_connected/generator.feature

#+end_src
* Links

- Expects — Expects 0.9.0 documentation [Internet]. [cited 2023 Jul 5]. Available from: https://expects.readthedocs.io/en/stable/
- PyTorch Forums [Internet]. 2019 [cited 2023 Jul 5]. Guidelines for when and why one should set inplace = True? Available from: https://discuss.pytorch.org/t/guidelines-for-when-and-why-one-should-set-inplace-true/50923
- Autograd mechanics — PyTorch master documentation [Internet]. [cited 2023 Jul 5]. Available from: https://pytorch.org/docs/master/notes/autograd.html#in-place-operations-with-autograd
