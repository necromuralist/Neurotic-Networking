<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="The Modified Triplet Loss Metric." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Modified Triplet Loss | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/modified-triplet-loss/index.html" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../siamese-networks-with-trax/index.html" rel="prev" title="Siamese Networks With Trax" type="text/html">
<link href="../evaluating-a-siamese-model/index.html" rel="next" title="Evaluating a Siamese Model" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Modified Triplet Loss" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/modified-triplet-loss/index.html" property="og:url">
<meta content="The Modified Triplet Loss Metric." property="og:description">
<meta content="article" property="og:type">
<meta content="2021-01-21T18:34:00-08:00" property="article:published_time">
<meta content="nlp" property="article:tag">
<meta content="nn" property="article:tag">
<meta content="siamese networks" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item dropdown"><a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#">Monkey Pages</a>
<div class="dropdown-menu"><a class="dropdown-item" href="https://necromuralist.github.io/">The Cloistered Monkey</a> <a class="dropdown-item" href="https://necromuralist.github.io/Ape-Iron/">Ape Iron</a> <a class="dropdown-item" href="https://necromuralist.github.io/Bowling-For-Data/">Bowling For Data</a> <a class="dropdown-item" href="https://necromuralist.github.io/Beach-Pig-Thigh/">Beach-Pig Rump & Thigh</a> <a class="dropdown-item" href="https://necromuralist.github.io/Visions-Voices-Data/">Visions, Voices, Data</a></div>
</li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="#">Modified Triplet Loss</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="#" rel="bookmark"><time class="published dt-published" datetime="2021-01-21T18:34:00-08:00" itemprop="datePublished" title="2021-01-21 18:34">2021-01-21 18:34</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="index.html#orge8ae832">Beginning</a>
<ul>
<li><a href="index.html#orgfd3a2cd">Background</a></li>
<li><a href="index.html#org7e792ad">Imports</a></li>
</ul>
</li>
<li><a href="index.html#orgf0b4b8d">Middle</a>
<ul>
<li><a href="index.html#orgd37800f">Similarity Scores</a>
<ul>
<li><a href="index.html#org522294a">Two Vectors</a></li>
<li><a href="index.html#orga1958dc">Similarity score</a></li>
</ul>
</li>
<li><a href="index.html#orgd473b2b">Two Batches of Vectors</a>
<ul>
<li><a href="index.html#orgf0c9f27">Check</a></li>
</ul>
</li>
<li><a href="index.html#org2c0843f">Hard Negative Mining</a>
<ul>
<li><a href="index.html#org144ae1b">Mean Negative</a></li>
<li><a href="index.html#orgeafd2f9">Closest Negative</a></li>
<li><a href="index.html#org5aafa77">Positives</a></li>
<li><a href="index.html#org4c45288">Negatives</a></li>
<li><a href="index.html#orge6f4742">Mean negative</a></li>
<li><a href="index.html#org798041f">Closest negative</a></li>
</ul>
</li>
<li><a href="index.html#org1985a78">The Loss Functions</a>
<ul>
<li><a href="index.html#org183fdcf">Modified triplet loss</a></li>
<li><a href="index.html#orgee665e2">Cost</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orge8ae832">
<h2 id="orge8ae832">Beginning</h2>
<div class="outline-text-2" id="text-orge8ae832">
<p>We'll be looking at how to calculate the full triplet loss as well as a matrix of similarity scores.</p>
</div>
<div class="outline-3" id="outline-container-orgfd3a2cd">
<h3 id="orgfd3a2cd">Background</h3>
<div class="outline-text-3" id="text-orgfd3a2cd">
<p>This is the original triplet loss function:</p>
<p>\[ \mathcal{L_\mathrm{Original}} = \max{(\mathrm{s}(A,N) -\mathrm{s}(A,P) +\alpha, 0)} \]</p>
<p>It can be improved by including the mean negative and the closest negative, to create a new full loss function. The inputs are the Anchor \(\mathrm{A}\), Positive \(\mathrm{P}\) and Negative \(\mathrm{N}\).</p>
\begin{align} \mathcal{L_\mathrm{1}} &amp;= \max{(mean\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{2}} &amp;= \max{(closest\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{Full}} &amp;= \mathcal{L_\mathrm{1}} + \mathcal{L_\mathrm{2}}\\ \end{align}</div>
</div>
<div class="outline-3" id="outline-container-org7e792ad">
<h3 id="org7e792ad">Imports</h3>
<div class="outline-text-3" id="text-org7e792ad">
<div class="highlight">
<pre><span></span><span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgf0b4b8d">
<h2 id="orgf0b4b8d">Middle</h2>
<div class="outline-text-2" id="text-orgf0b4b8d"></div>
<div class="outline-3" id="outline-container-orgd37800f">
<h3 id="orgd37800f">Similarity Scores</h3>
<div class="outline-text-3" id="text-orgd37800f">
<p>The first step is to calculate the matrix of similarity scores using cosine similarity so that you can look up \(\mathrm{s}(A,P)\), \(\mathrm{s}(A,N)\) as needed for the loss formulas.</p>
</div>
<div class="outline-4" id="outline-container-org522294a">
<h4 id="org522294a">Two Vectors</h4>
<div class="outline-text-4" id="text-org522294a">
<p>First, this is how to calculate the similarity score, using cosine similarity, for 2 vectors.</p>
<p>\[ \mathrm{s}(v_1,v_2) = \mathrm{cosine \ similarity}(v_1,v_2) = \frac{v_1 \cdot v_2}{||v_1||~||v_2||} \]</p>
</div>
</div>
<div class="outline-4" id="outline-container-orga1958dc">
<h4 id="orga1958dc">Similarity score</h4>
<div class="outline-text-4" id="text-orga1958dc">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">v2</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Calculates the cosine similarity between two vectors</span>

<span class="sd">    Args:</span>
<span class="sd">     v1: first vector</span>
<span class="sd">     v2: vector to compare to v1</span>

<span class="sd">    Returns:</span>
<span class="sd">     the cosine similarity between v1 and v2</span>
<span class="sd">    """</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v1</span><span class="p">))</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="n">v2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org6167f02"></a>Similar vectors<br>
<div class="outline-text-5" id="text-org6167f02">
<div class="highlight">
<pre><span></span><span class="n">v1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : 0.9974
</pre></div>
</li>
<li><a id="orge5a7aa4"></a>Identical Vectors<br>
<div class="outline-text-5" id="text-orge5a7aa4">
<div class="highlight">
<pre><span></span><span class="n">v2</span> <span class="o">=</span> <span class="n">v1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : 1.0000
</pre></div>
</li>
<li><a id="orgfadc514"></a>Opposite Vectors<br>
<div class="outline-text-5" id="text-orgfadc514">
<div class="highlight">
<pre><span></span><span class="n">v2</span> <span class="o">=</span> <span class="o">-</span><span class="n">v1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : -1.0000
</pre></div>
</li>
<li><a id="org448b94d"></a>Dissimilar Vectors<br>
<div class="outline-text-5" id="text-org448b94d">
<div class="highlight">
<pre><span></span><span class="n">v2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">42</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : -0.5153
</pre></div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-orgd473b2b">
<h3 id="orgd473b2b">Two Batches of Vectors</h3>
<div class="outline-text-3" id="text-orgd473b2b">
<p>Now let's look at how to calculate the similarity scores, using cosine similarity, for 2 batches of vectors. These are rows of individual vectors, just like in the example above, but stacked vertically into a matrix. They would look like the image below for a batch size (row count) of 4 and embedding size (column count) of 5.</p>
<p>The data is setup so that \(v_{1\_1}\) and \(v_{2\_1}\) represent duplicate inputs, but they are not duplicates with any other rows in the batch. This means \(v_{1\_1}\) and \(v_{2\_1}\) (green and green) have more similar vectors than say \(v_{1\_1}\) and \(v_{2\_2}\) (green and magenta).</p>
<p>We'll use two different methods for calculating the matrix of similarities from 2 batches of vectors.</p>
<p>The Input data.</p>
<div class="highlight">
<pre><span></span><span class="n">v1_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">v1_2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="n">v1_3</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="n">v1_4</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">v1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">v1_1</span><span class="p">,</span> <span class="n">v1_2</span><span class="p">,</span> <span class="n">v1_3</span><span class="p">,</span> <span class="n">v1_4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"v1 :"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="n">v2_1</span> <span class="o">=</span> <span class="n">v1_1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># add some noise to create approximate duplicate</span>
<span class="n">v2_2</span> <span class="o">=</span> <span class="n">v1_2</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">v2_3</span> <span class="o">=</span> <span class="n">v1_3</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">v2_4</span> <span class="o">=</span> <span class="n">v1_4</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">v2_1</span><span class="p">,</span> <span class="n">v2_2</span><span class="p">,</span> <span class="n">v2_3</span><span class="p">,</span> <span class="n">v2_4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"v2 :"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org2d6ddfa">
v1 :
[[ 1  2  3]
 [ 9  8  7]
 [-1 -4 -2]
 [ 1 -7  2]] 

v2 :
[[ 1.34263076  1.18510671  1.04373534]
 [ 8.96692933  6.50763316  7.03243982]
 [-3.4497247  -6.08808183 -4.54327564]
 [-0.77144774 -9.08449817  4.4633513 ]] 
</pre>
<p>For this to work the batch sizes must match.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">v1</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span>
</pre></div>
<p>Now let's look at the similarity scores.</p>
</div>
<ul class="org-ul">
<li><a id="org0e96f3a"></a>Option 1 : nested loops and the cosine similarity function<br>
<div class="outline-text-5" id="text-org0e96f3a">
<div class="highlight">
<pre><span></span><span class="n">batch_size</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">v1</span><span class="o">.</span><span class="n">shape</span>
<span class="n">scores_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">])</span>

<span class="n">rows</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">scores_1</span><span class="o">.</span><span class="n">shape</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rows</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">columns</span><span class="p">):</span>
        <span class="n">scores_1</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">[</span><span class="n">row</span><span class="p">],</span> <span class="n">v2</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Option 1 : Loop"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores_1</span><span class="p">)</span>
</pre></div>
<pre class="example">
Option 1 : Loop
[[ 0.88245143  0.87735873 -0.93717609 -0.14613242]
 [ 0.99999485  0.99567656 -0.95998199 -0.34214656]
 [-0.86016573 -0.81584759  0.96484391  0.60584372]
 [-0.31943701 -0.23354642  0.49063636  0.96181686]]
</pre></div>
</li>
<li><a id="org4f4e81f"></a>Option 2 : Vector Normalization and the Dot Product<br>
<div class="outline-text-5" id="text-org4f4e81f">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Normalize x"""</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">scores_2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">v1</span><span class="p">),</span> <span class="n">norm</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Option 2 : Vector Norm & dot product"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores_2</span><span class="p">)</span>
</pre></div>
<pre class="example">
Option 2 : Vector Norm & dot product
[[ 0.88245143  0.87735873 -0.93717609 -0.14613242]
 [ 0.99999485  0.99567656 -0.95998199 -0.34214656]
 [-0.86016573 -0.81584759  0.96484391  0.60584372]
 [-0.31943701 -0.23354642  0.49063636  0.96181686]] 

</pre></div>
</li>
</ul>
<div class="outline-4" id="outline-container-orgf0c9f27">
<h4 id="orgf0c9f27">Check</h4>
<div class="outline-text-4" id="text-orgf0c9f27">
<p>Let's make sure we get the same answer in both cases.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">scores_1</span><span class="p">,</span> <span class="n">scores_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org2c0843f">
<h3 id="org2c0843f">Hard Negative Mining</h3>
<div class="outline-text-3" id="text-org2c0843f">
<p>Now we'll calculate the mean negative \(mean\_neg\) and the closest negative \(close\_neg\) used in calculating \(\mathcal{L_\mathrm{1}}\) and \(\mathcal{L_\mathrm{2}}\).</p>
\begin{align} \mathcal{L_\mathrm{1}} &amp;= \max{(mean\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{2}} &amp;= \max{(closest\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \end{align}
<p>We'll do this using the matrix of similarity scores for a batch size of 4. The diagonal of the matrix contains all the \(\mathrm{s}(A,P)\) values, similarities from duplicate question pairs (aka Positives). This is an important attribute for the calculations to follow.</p>
</div>
<div class="outline-4" id="outline-container-org144ae1b">
<h4 id="org144ae1b">Mean Negative</h4>
<div class="outline-text-4" id="text-org144ae1b">
<p><i>mean_neg</i> is the average of the off diagonals, the \(\mathrm{s}(A,N)\) values, for each row.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgeafd2f9">
<h4 id="orgeafd2f9">Closest Negative</h4>
<div class="outline-text-4" id="text-orgeafd2f9">
<p><i>closest_neg</i> is the largest off diagonal value, \(\mathrm{s}(A,N)\), that is smaller than the diagonal \(\mathrm{s}(A,P)\) for each row.</p>
<p>We'll start with some hand-made similarity scores.</p>
<div class="highlight">
<pre><span></span><span class="n">similarity_scores</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5aafa77">
<h4 id="org5aafa77">Positives</h4>
<div class="outline-text-4" id="text-org5aafa77">
<p>All the <i>s(A,P)</i> values are similarities from duplicate question pairs (aka Positives). These are along the diagonal.</p>
<div class="highlight">
<pre><span></span><span class="n">sim_ap</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">similarity_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"s(A, P) :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sim_ap</span><span class="p">))</span>
</pre></div>
<pre class="example">
s(A, P) :

[[ 0.9  0.   0.   0. ]
 [ 0.   0.5  0.   0. ]
 [ 0.   0.  -0.4  0. ]
 [ 0.   0.   0.   0.5]]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org4c45288">
<h4 id="org4c45288">Negatives</h4>
<div class="outline-text-4" id="text-org4c45288">
<p>All the <i>s(A,N)</i> values are similarities of the non duplicate question pairs (aka Negatives). These are in the cells not on the diagonal.</p>
<div class="highlight">
<pre><span></span><span class="n">sim_an</span> <span class="o">=</span> <span class="n">similarity_scores</span> <span class="o">-</span> <span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sim_ap</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"s(A, N) :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sim_an</span><span class="p">)</span>
</pre></div>
<pre class="example">
s(A, N) :

[[ 0.  -0.8  0.3 -0.5]
 [-0.4  0.   0.1 -0.1]
 [ 0.3  0.1  0.  -0.8]
 [-0.5 -0.2 -0.7  0. ]]
</pre></div>
</div>
<div class="outline-4" id="outline-container-orge6f4742">
<h4 id="orge6f4742">Mean negative</h4>
<div class="outline-text-4" id="text-orge6f4742">
<p>This is the average of the <i>s(A,N)</i> values for each row.</p>
<div class="highlight">
<pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">similarity_scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">mean_neg</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sim_an</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"mean_neg :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean_neg</span><span class="p">)</span>
</pre></div>
<pre class="example">
mean_neg :

[[-0.33333333]
 [-0.13333333]
 [-0.13333333]
 [-0.46666667]]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org798041f">
<h4 id="org798041f">Closest negative</h4>
<div class="outline-text-4" id="text-org798041f">
<p>These are the Max <i>s(A,N)</i> that is &lt;= s(A,P) for each row.</p>
<div class="highlight">
<pre><span></span><span class="n">mask_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>            <span class="c1"># mask to exclude the diagonal</span>
<span class="n">mask_2</span> <span class="o">=</span> <span class="n">sim_an</span> <span class="o">&gt;</span> <span class="n">sim_ap</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># mask to exclude sim_an &gt; sim_ap</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">mask_1</span> <span class="o">|</span> <span class="n">mask_2</span>
<span class="n">sim_an_masked</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">sim_an</span><span class="p">)</span>         <span class="c1"># create a copy to preserve sim_an</span>
<span class="n">sim_an_masked</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>

<span class="n">closest_neg</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">sim_an_masked</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Closest Negative :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">closest_neg</span><span class="p">)</span>
</pre></div>
<pre class="example">
Closest Negative :

[[ 0.3]
 [ 0.1]
 [-0.8]
 [-0.2]]
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1985a78">
<h3 id="org1985a78">The Loss Functions</h3>
<div class="outline-text-3" id="text-org1985a78">
<p>The last step is to calculate the loss functions.</p>
\begin{align} \mathcal{L_\mathrm{1}} &amp;= \max{(mean\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{2}} &amp;= \max{(closest\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{Full}} &amp;= \mathcal{L_\mathrm{1}} + \mathcal{L_\mathrm{2}}\\ \end{align}
<p>The Alpha margin.</p>
<div class="highlight">
<pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.25</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org183fdcf">
<h4 id="org183fdcf">Modified triplet loss</h4>
<div class="outline-text-4" id="text-org183fdcf">
<div class="highlight">
<pre><span></span><span class="n">loss_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">mean_neg</span> <span class="o">-</span> <span class="n">sim_ap</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">loss_2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">closest_neg</span> <span class="o">-</span> <span class="n">sim_ap</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">loss_full</span> <span class="o">=</span> <span class="n">loss_1</span> <span class="o">+</span> <span class="n">loss_2</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgee665e2">
<h4 id="orgee665e2">Cost</h4>
<div class="outline-text-4" id="text-orgee665e2">
<div class="highlight">
<pre><span></span><span class="n">cost</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">loss_full</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Loss Full :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss_full</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">cost : </span><span class="si">{</span><span class="n">cost</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Loss Full :

[[0.        ]
 [0.        ]
 [0.51666667]
 [0.        ]]

cost : 0.517
</pre></div>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/nlp/index.html" rel="tag">nlp</a></li>
<li><a class="tag p-category" href="../../../categories/nn/index.html" rel="tag">nn</a></li>
<li><a class="tag p-category" href="../../../categories/siamese-networks/index.html" rel="tag">siamese networks</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../siamese-networks-with-trax/index.html" rel="prev" title="Siamese Networks With Trax">Previous post</a></li>
<li class="next"><a href="../evaluating-a-siamese-model/index.html" rel="next" title="Evaluating a Siamese Model">Next post</a></li>
</ul>
</nav>
</aside>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script></article>
<!--End of body content-->
<footer id="footer">Scribbles by <a href="mailto:cloisteredmonkey.jmark@slmail.me">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>
<div id="license" xmlns:cc="http://creativecommons.org/ns#">This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" rel="license noopener noreferrer" style="display:inline-block;" target="_blank">CC BY 4.0 <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></div>
</footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
