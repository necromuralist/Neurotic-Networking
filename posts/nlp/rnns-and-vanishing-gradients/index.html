<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="A look at the problem of vanishing gradients with RNNs." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>RNNS and Vanishing Gradients | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/rnns-and-vanishing-gradients/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../deep-n-grams-batch-generation/" rel="prev" title="Deep N-Grams: Batch Generation" type="text/html">
<link href="../ner-pre-processing-the-data/" rel="next" title="NER: Pre-Processing the Data" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="RNNS and Vanishing Gradients" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/rnns-and-vanishing-gradients/" property="og:url">
<meta content="A look at the problem of vanishing gradients with RNNs." property="og:description">
<meta content="article" property="og:type">
<meta content="2021-01-10T18:52:32-08:00" property="article:published_time">
<meta content="nlp" property="article:tag">
<meta content="rnn" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">RNNS and Vanishing Gradients</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2021-01-10T18:52:32-08:00" itemprop="datePublished" title="2021-01-10 18:52">2021-01-10 18:52</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org727cc2a">Vanishing Gradients</a>
<ul>
<li><a href="#org0faaab0">Background</a></li>
<li><a href="#org61035f6">Imports</a></li>
<li><a href="#org72d6dd1">Set Up</a></li>
</ul>
</li>
<li><a href="#orgee4b3df">Middle</a>
<ul>
<li><a href="#org34179ca">The Data</a></li>
<li><a href="#org3615f20">The Sigmoid</a></li>
<li><a href="#org29a9eb3">The Gradient</a></li>
<li><a href="#orged89cd9">Plotting the Sigmoid</a></li>
<li><a href="#org22a7677">The Numerical Impact</a>
<ul>
<li><a href="#orgafdec8a">Multiplication & Decay</a></li>
</ul>
</li>
<li><a href="#orgef90723">A Decay Simulation</a>
<ul>
<li><a href="#orgb10496b">Input data</a></li>
<li><a href="#org69b5557">Plot The Decay</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge1065bc">So, How Do You Fix This?</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org727cc2a">
<h2 id="org727cc2a">Vanishing Gradients</h2>
<div class="outline-text-2" id="text-org727cc2a">
<p>This will be a look at the problem of vanishing gradients from an intuitive standpoint.</p>
</div>
<div class="outline-3" id="outline-container-org0faaab0">
<h3 id="org0faaab0">Background</h3>
<div class="outline-text-3" id="text-org0faaab0">
<p>Adding layers to a neural network introduces multiplicative effects in both forward and backward propagation. The back-prop in particular presents a problem as the gradient of activation functions can be very small. Multiplied together across many layers, their product can be vanishingly small. This results in weights not being updated in the front layers and training not progressing.</p>
<p>Gradients of the sigmoid function, for example, are in the range 0 to 0.25. To calculate gradients for the front layers of a neural network the chain rule is used. This means that these tiny values are multiplied starting at the last layer, working backwards to the first layer, with the gradients shrinking exponentially at each step.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org61035f6">
<h3 id="org61035f6">Imports</h3>
<div class="outline-text-3" id="text-org61035f6">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># another project</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org72d6dd1">
<h3 id="org72d6dd1">Set Up</h3>
<div class="outline-text-3" id="text-org72d6dd1">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"rnns-and-vanishing-gradients"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span>
                <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span> <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">])</span>
<span class="n">PLOT</span> <span class="o">=</span> <span class="n">Plot</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgee4b3df">
<h2 id="orgee4b3df">Middle</h2>
<div class="outline-text-2" id="text-orgee4b3df"></div>
<div class="outline-3" id="outline-container-org34179ca">
<h3 id="org34179ca">The Data</h3>
<div class="outline-text-3" id="text-org34179ca">
<p>This will be an evenly spaced set of points over an interval (see <a href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html">numpy.linspace</a>).</p>
<div class="highlight">
<pre><span></span><span class="n">STOP</span><span class="p">,</span> <span class="n">STEPS</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">STOP</span><span class="p">,</span> <span class="n">STOP</span><span class="p">,</span> <span class="n">STEPS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org3615f20">
<h3 id="org3615f20">The Sigmoid</h3>
<div class="outline-text-3" id="text-org3615f20">
<p>Our activation function will be the <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid (wikipedia link)</a> (well, the logistic function).</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>
<p>Now we'll calculate the activations for our input data.</p>
<div class="highlight">
<pre><span></span><span class="n">activations</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org29a9eb3">
<h3 id="org29a9eb3">The Gradient</h3>
<div class="outline-text-3" id="text-org29a9eb3">
<p>Our gradient is the derivative of the sigmoid.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
<p>Now we can get the gradients for our activations.</p>
<div class="highlight">
<pre><span></span><span class="n">gradients</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">activations</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orged89cd9">
<h3 id="orged89cd9">Plotting the Sigmoid</h3>
<div class="outline-text-3" id="text-orged89cd9">
<div class="highlight">
<pre><span></span><span class="n">tangent_x</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">tangent_y</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">tangent_x</span><span class="p">)</span>
<span class="n">span</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">gradient_tangent</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tangent_x</span><span class="p">))</span>

<span class="n">tangent_plot_x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">tangent_x</span> <span class="o">-</span> <span class="n">span</span><span class="p">,</span> <span class="n">tangent_x</span> <span class="o">+</span> <span class="n">span</span><span class="p">,</span> <span class="n">STEPS</span><span class="p">)</span>
<span class="n">tangent_plot_y</span> <span class="o">=</span> <span class="n">tangent_y</span> <span class="o">+</span> <span class="n">gradient_tangent</span> <span class="o">*</span> <span class="p">(</span><span class="n">tangent_plot_x</span> <span class="o">-</span> <span class="n">tangent_x</span><span class="p">)</span>

<span class="n">frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span>
    <span class="p">{</span><span class="s2">"X"</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
     <span class="s2">"Sigmoid"</span><span class="p">:</span> <span class="n">activations</span><span class="p">,</span>
     <span class="s2">"X-Tangent"</span><span class="p">:</span> <span class="n">tangent_plot_x</span><span class="p">,</span>
     <span class="s2">"Y-Tangent"</span><span class="p">:</span> <span class="n">tangent_plot_y</span><span class="p">,</span>
     <span class="s2">"Gradient"</span><span class="p">:</span> <span class="n">gradients</span><span class="p">})</span>
<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"X"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Sigmoid"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span>
        <span class="o">*</span> <span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"X"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Gradient"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">)</span>
        <span class="o">*</span> <span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"X-Tangent"</span><span class="p">,</span>
                       <span class="n">y</span><span class="o">=</span><span class="s2">"Y-Tangent"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">tan</span><span class="p">))</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
            <span class="n">title</span><span class="o">=</span><span class="s2">"Sigmoid and Tangent"</span><span class="p">,</span>
            <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
            <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
            <span class="n">fontscale</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">fontscale</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"sigmoid_tangent"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="sigmoid_tangent.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>The thing to notice is that as the input data moves away from the center (at 0) the gradients get smaller in either direction, rapidly approaching zero.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org22a7677">
<h3 id="org22a7677">The Numerical Impact</h3>
<div class="outline-text-3" id="text-org22a7677"></div>
<div class="outline-4" id="outline-container-orgafdec8a">
<h4 id="orgafdec8a">Multiplication & Decay</h4>
<div class="outline-text-4" id="text-orgafdec8a">
<p>Multiplying numbers smaller than 1 results in smaller and smaller numbers. Below is an example that finds the gradient for an input <i>x = 0</i> and multiplies it over n steps. Look how quickly it 'Vanishes' to almost zero. Yet \(\sigma(x=0) \implies 0.5\) which has a sigmoid gradient of 0.25 and that happens to be the largest sigmoid gradient possible.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgef90723">
<h3 id="orgef90723">A Decay Simulation</h3>
<div class="outline-text-3" id="text-orgef90723"></div>
<div class="outline-4" id="outline-container-orgb10496b">
<h4 id="orgb10496b">Input data</h4>
<div class="outline-text-4" id="text-orgb10496b">
<div class="highlight">
<pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">x</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">gradients</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">steps</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-- Inputs --"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"steps :"</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"x value :"</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"sigmoid :"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{:.5f}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"gradient :"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{:.5f}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gradients</span><span class="p">),</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
-- Inputs --
steps : 6
x value : 0
sigmoid : 0.50000
gradient : 0.25000 

</pre></div>
</div>
<div class="outline-4" id="outline-container-org69b5557">
<h4 id="org69b5557">Plot The Decay</h4>
<div class="outline-text-4" id="text-org69b5557">
<div class="highlight">
<pre><span></span><span class="n">decaying_values</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span> <span class="o">*</span> <span class="n">gradients</span><span class="p">)</span><span class="o">.</span><span class="n">cumprod</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Step</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span> <span class="n">Gradient</span><span class="o">=</span><span class="n">decaying_values</span><span class="p">))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Step"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Gradient"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Cumulative Gradient"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">fontscale</span>
<span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"cumulative_gradient"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="cumulative_gradient.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>The point being that the gradients very quickly approach zero.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orge1065bc">
<h2 id="orge1065bc">So, How Do You Fix This?</h2>
<div class="outline-text-2" id="text-orge1065bc">
<p>One solution is to use activation functions that don't have tiny gradients. Other solutions involve more sophisticated model design. But they're both discussions for another time.</p>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/nlp/" rel="tag">nlp</a></li>
<li><a class="tag p-category" href="../../../categories/rnn/" rel="tag">rnn</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../deep-n-grams-batch-generation/" rel="prev" title="Deep N-Grams: Batch Generation">Previous post</a></li>
<li class="next"><a href="../ner-pre-processing-the-data/" rel="next" title="NER: Pre-Processing the Data">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer"><a href="https://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://licensebuttons.net/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:cloisteredmonkey.jmark@slmail.me">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
