<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="A walk through the pytorch 60 Minute Blitz." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Pytorch 60 Minute Blitz | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../text/chatbot-tutorial/" rel="prev" title="Chatbot Tutorial" type="text/html">
<link href="../../fastai/dog-and-cat-breed-classification/" rel="next" title="Dog and Cat Breed Classification (What's Your Pet?)" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Pytorch 60 Minute Blitz" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/pytorch/pytorch-60-minute-blitz/" property="og:url">
<meta content="A walk through the pytorch 60 Minute Blitz." property="og:description">
<meta content="article" property="og:type">
<meta content="2019-04-03T12:36:06-07:00" property="article:published_time">
<meta content="pytorch" property="article:tag">
<meta content="tutorial" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/Neurotic-Networking/"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Pytorch 60 Minute Blitz</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2019-04-03T12:36:06-07:00" itemprop="datePublished" title="2019-04-03 12:36">2019-04-03 12:36</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orga3ca83d">The Departure</a>
<ul>
<li><a href="#orgc3fcab2">Imports</a>
<ul>
<li><a href="#org62f12a8">PyPi</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgbf53d3d">The Initiation</a>
<ul>
<li><a href="#org9302815">What is PyTorch?</a>
<ul>
<li><a href="#orga9a6595">Tensors</a></li>
<li><a href="#org25e8459">Operations</a></li>
<li><a href="#orgf7b05fb">Torch to Numpy</a></li>
<li><a href="#org7b0bb67">Numpy to Torch</a></li>
<li><a href="#orgc740b1a">Cuda</a></li>
</ul>
</li>
<li><a href="#org5aad2d4">Autograd: Automatic Differentiation</a>
<ul>
<li><a href="#org94c93f8">Backpropagation</a></li>
<li><a href="#orgb69df50">Context Manager</a></li>
</ul>
</li>
<li><a href="#org8b2c900">Neural Networks</a>
<ul>
<li><a href="#orgac3c5f8">A Typical Model Training Procedure</a></li>
<li><a href="#orged6d945">Defining the Network</a></li>
<li><a href="#orgd9a7502">The Loss Function</a></li>
<li><a href="#org5d86b43">Backpropagation</a></li>
<li><a href="#org1a86a07">Update the Weights</a></li>
</ul>
</li>
<li><a href="#orgfc6f12c">Training a Classifier</a></li>
<li><a href="#orgaf097cd">Data Parallelism</a></li>
</ul>
</li>
<li><a href="#org18f5b8d">The Return</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orga3ca83d">
<h2 id="orga3ca83d">The Departure</h2>
<div class="outline-text-2" id="text-orga3ca83d">
<p>This is a replication of <a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html">Deep Learning With Pytorch: A 60 Minute Blitz</a> to get me back into using <a href="https://pytorch.org">PyTorch</a>.</p>
</div>
<div class="outline-3" id="outline-container-orgc3fcab2">
<h3 id="orgc3fcab2">Imports</h3>
<div class="outline-text-3" id="text-orgc3fcab2"></div>
<div class="outline-4" id="outline-container-org62f12a8">
<h4 id="org62f12a8">PyPi</h4>
<div class="outline-text-4" id="text-org62f12a8">
<p>Although the project is called PyTorch, the package is named <code>torch</code>.</p>
<div class="highlight">
<pre><span></span>import torch
import torch.nn as neural_network
import torch.nn.functional as functional
</pre></div>
<p>And we're going to use numpy a little.</p>
<div class="highlight">
<pre><span></span>import numpy
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgbf53d3d">
<h2 id="orgbf53d3d">The Initiation</h2>
<div class="outline-text-2" id="text-orgbf53d3d"></div>
<div class="outline-3" id="outline-container-org9302815">
<h3 id="org9302815">What is PyTorch?</h3>
<div class="outline-text-3" id="text-org9302815"></div>
<div class="outline-4" id="outline-container-orga9a6595">
<h4 id="orga9a6595">Tensors</h4>
<div class="outline-text-4" id="text-orga9a6595">
<p>In PyTorch, <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">tensors</a> are similar to numpy's <a href="https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html">ndarrays</a> (n-dimensional arrays). You can create an unitialized one using the <code>empty</code> function.</p>
</div>
<ul class="org-ul">
<li><a id="orge8c9e59"></a>Empty<br>
<div class="outline-text-5" id="text-orge8c9e59">
<div class="highlight">
<pre><span></span>empty_tensor = torch.empty(5, 3)
print(empty_tensor)
</pre></div>
<pre class="example">
tensor([[-2.3492e+02,  4.5902e-41, -2.3492e+02],
        [ 4.5902e-41,  3.1766e+30,  1.7035e+25],
        [ 4.0498e-43,  0.0000e+00, -2.3492e+02],
        [ 4.5902e-41,  2.6417e-37,  0.0000e+00],
        [ 1.4607e-19,  1.8469e+25,  1.0901e+27]])
</pre>
<p>Here's the docstring for <code>empty</code>:</p>
<div class="highlight">
<pre><span></span>print(torch.empty.__doc__)
</pre></div>
<pre class="example">

empty(*sizes, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -&gt; Tensor

Returns a tensor filled with uninitialized data. The shape of the tensor is
defined by the variable argument :attr:`sizes`.

Args:
    sizes (int...): a sequence of integers defining the shape of the output tensor.
        Can be a variable number of arguments or a collection like a list or tuple.
    out (Tensor, optional): the output tensor
    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.
        Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).
    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.
        Default: ``torch.strided``.
    device (:class:`torch.device`, optional): the desired device of returned tensor.
        Default: if ``None``, uses the current device for the default tensor type
        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU
        for CPU tensor types and the current CUDA device for CUDA tensor types.
    requires_grad (bool, optional): If autograd should record operations on the
        returned tensor. Default: ``False``.

Example::

    &gt;&gt;&gt; torch.empty(2, 3)
    tensor(1.00000e-08 *
           [[ 6.3984,  0.0000,  0.0000],
            [ 0.0000,  0.0000,  0.0000]])


</pre></div>
</li>
<li><a id="org34dd594"></a>Random<br>
<div class="outline-text-5" id="text-org34dd594">
<div class="highlight">
<pre><span></span>print(torch.rand(5, 3))
</pre></div>
<pre class="example">
tensor([[0.1767, 0.9520, 0.1488],
        [0.5592, 0.4836, 0.2645],
        [0.8066, 0.8864, 0.1083],
        [0.9206, 0.7311, 0.1278],
        [0.0140, 0.5370, 0.3123]])
</pre>
<p>The arguments are the same as for empty.</p>
</div>
</li>
<li><a id="orgb96be78"></a>Zeros<br>
<div class="outline-text-5" id="text-orgb96be78">
<p>Here we'll create a tensor of zeros as long integers.</p>
<div class="highlight">
<pre><span></span>print(torch.zeros(5, 3, dtype=torch.long))
</pre></div>
<pre class="example">
tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
</pre>
<p>Once again the argument for <code>zeros</code> is the same as those for <code>empty</code>.</p>
</div>
</li>
<li><a id="org0a32905"></a>From Data<br>
<div class="outline-text-5" id="text-org0a32905">
<div class="highlight">
<pre><span></span>print(torch.tensor([5.5, 3]))
</pre></div>
<pre class="example">
tensor([5.5000, 3.0000])
</pre></div>
</li>
<li><a id="orga6ec34d"></a>From A Tensor<br>
<div class="outline-text-5" id="text-orga6ec34d">
<p>You can create a new tensor from a previously constructed one. This preserves any parameters you passed in that you don't subsequently override.</p>
<div class="highlight">
<pre><span></span>x = torch.tensor([5, 3], dtype=torch.int)
print(x)
y = x.new_ones(5, 3)
print(y)
</pre></div>
<pre class="example">
tensor([5, 3], dtype=torch.int32)
tensor([[1, 1, 1],
        [1, 1, 1],
        [1, 1, 1],
        [1, 1, 1],
        [1, 1, 1]], dtype=torch.int32)
</pre>
<p>PyTorch also has another syntax for creating a random tensor from another tensor.</p>
<div class="highlight">
<pre><span></span>print(torch.randn_like(x, dtype=torch.float))
</pre></div>
<pre class="example">
tensor([ 0.6447, -0.9750])
</pre>
<p>So in this case it kept the shape but used our dtype. The values seemed odd at first, but that's because the <code>randn</code> indicates it comes from a standard-normal distribution centered at 0, not some value in the range from zero to one (non-inclusive) like a regular random function would.</p>
</div>
</li>
<li><a id="org3387bc5"></a>Tensor Size<br>
<div class="outline-text-5" id="text-org3387bc5">
<p>Like pandas, the tensor has a shape, but confusingly it's called <code>Size</code> and can be accessed either from the <code>size</code> method of the <code>shape</code> attribute.</p>
<div class="highlight">
<pre><span></span>print(y.size())
</pre></div>
<pre class="example">
torch.Size([5, 3])
</pre>
<div class="highlight">
<pre><span></span>print(y.shape)
</pre></div>
<pre class="example">
torch.Size([5, 3])
</pre>
<div class="highlight">
<pre><span></span>print(torch.Size.__base__)
</pre></div>
<pre class="example">
&lt;class 'tuple'&gt;
</pre>
<p>The <code>Size</code> object inherits from tuples and supports all the tuple operations.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org25e8459">
<h4 id="org25e8459">Operations</h4>
<div class="outline-text-4" id="text-org25e8459"></div>
<ul class="org-ul">
<li><a id="org827b0f6"></a>Addition<br>
<div class="outline-text-5" id="text-org827b0f6">
<p>For some operations you can use either the operators (like <code>+</code>) or method calls. Here's two ways to do addition.</p>
<div class="highlight">
<pre><span></span>SIZE = (5, 3)
x = torch.rand(*SIZE)
y = torch.rand(*SIZE)
output = x + y
print(output)
print()
print(torch.add(x, y))
</pre></div>
<pre class="example">
tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])

tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])
</pre></div>
</li>
<li><a id="orgf3580d8"></a>Pre-Made Tensors<br>
<div class="outline-text-5" id="text-orgf3580d8">
<p>One advantage to using the function is that you can pass in a tensor, rather than having pytorch create the output-tensor for you.</p>
<div class="highlight">
<pre><span></span>summation = torch.empty(SIZE)
torch.add(x, y, out=summation)
print(summation)
</pre></div>
<pre class="example">
tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])
</pre></div>
</li>
<li><a id="org70be530"></a>In-Place Operations<br>
<div class="outline-text-5" id="text-org70be530">
<p>Tensors also have methods that let you update them instead of creating a new tensor.</p>
<div class="highlight">
<pre><span></span>x.add_(y)
print(x)
</pre></div>
<pre class="example">
tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])
</pre></div>
</li>
<li><a id="orgdbe4200"></a>Slicing<br>
<div class="outline-text-5" id="text-orgdbe4200">
<p>The slicing follows what numpy's arrays do. Here's how to get all the rows of the second column.</p>
<div class="highlight">
<pre><span></span>print(x[:, 1])
</pre></div>
<pre class="example">
tensor([1.4905, 0.9883, 0.6291, 1.1548, 0.9954])
</pre></div>
</li>
<li><a id="orgeb09951"></a>Reshaping<br>
<div class="outline-text-5" id="text-orgeb09951">
<p>You can create a new tensor with the same data but a different shape using the <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view">view</a> method.</p>
<div class="highlight">
<pre><span></span>y = x.view(15)
z = x.view(-1, 5)
print(x.shape)
print(y.shape)
print(z.shape)
</pre></div>
<pre class="example">
torch.Size([5, 3])
torch.Size([15])
torch.Size([3, 5])
</pre>
<p>Using <code>-1</code> tells pytorch to infer the dimension based on the original and the dimension that you did pass in.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgf7b05fb">
<h4 id="orgf7b05fb">Torch to Numpy</h4>
<div class="outline-text-4" id="text-orgf7b05fb">
<p>While there are advantages to using torch for operations (it can use the GPU, for instance), there might be times when you want to convert the tensor to a numpy array.</p>
<div class="highlight">
<pre><span></span>x = torch.zeros(5)
print(x)
y = x.numpy()
print(y)
x.add_(1)
print(x)
print(y)
print(type(y))
</pre></div>
<pre class="example">
tensor([0., 0., 0., 0., 0.])
[0. 0. 0. 0. 0.]
tensor([1., 1., 1., 1., 1.])
[1. 1. 1. 1. 1.]
&lt;class 'numpy.ndarray'&gt;
</pre>
<p>Somehow updating the tensor in place updates the numpy array as well, even though it's an ndarray.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org7b0bb67">
<h4 id="org7b0bb67">Numpy to Torch</h4>
<div class="outline-text-4" id="text-org7b0bb67">
<p>You can go the other way as well.</p>
<div class="highlight">
<pre><span></span>x = numpy.zeros(5)
print(x)
y = torch.from_numpy(x)
print(y)
x += 5
print(y)
</pre></div>
<pre class="example">
[0. 0. 0. 0. 0.]
tensor([0., 0., 0., 0., 0.], dtype=torch.float64)
tensor([5., 5., 5., 5., 5.], dtype=torch.float64)
</pre>
<p>So updating the array (in place) updates the tensor.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgc740b1a">
<h4 id="orgc740b1a">Cuda</h4>
<div class="outline-text-4" id="text-orgc740b1a">
<p>As I mentioned before, an advantage of pytorch tensors is that they can be run on the GPU - unfortunately the computer I'm on is old and CUDA doesn't run on it, but we can make a check to see if it will first using =torch.cuda.is_available()</p>
<div class="highlight">
<pre><span></span>device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
print(device)

x = torch.ones(5)

# pass in the device
y = torch.ones_like(x, device=device)

# or move the tensor to the device (not an inplace operation)
x = x.to(device)

z = x + y
print(z)
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org5aad2d4">
<h3 id="org5aad2d4">Autograd: Automatic Differentiation</h3>
<div class="outline-text-3" id="text-org5aad2d4">
<p>The <a href="https://pytorch.org/docs/stable/autograd.html">autograd</a> module in pytorch performs automatic differentiation for you. It works using <i>define-by-run</i>, meaning that as you run you forward-pass through the network, it tracks your calls so you don't have to explicitly define anything for backpropagation to work. To enable or disable it you set the <code>requires_grad</code> attribute of the tensor you want to train.</p>
<div class="highlight">
<pre><span></span>tense = torch.ones(2, 2, requires_grad=True)
print(tense)
</pre></div>
<pre class="example">
tensor([[1., 1.],
        [1., 1.]], requires_grad=True)
</pre>
<p>Now if you do a tensor operation:</p>
<div class="highlight">
<pre><span></span>tensed = tense + 1
print(tensed)
</pre></div>
<pre class="example">
tensor([[2., 2.],
        [2., 2.]], grad_fn=&lt;AddBackward0&gt;)
</pre>
<p>Our new tensor has a gradient function set for it. If you do more operations on <code>tensed</code>:</p>
<div class="highlight">
<pre><span></span>tenser = tensed * 5
print(tenser)
</pre></div>
<pre class="example">
tensor([[10., 10.],
        [10., 10.]], grad_fn=&lt;MulBackward0&gt;)
</pre>
<div class="highlight">
<pre><span></span>a = torch.ones(5, requires_grad=False)
b = a * 5
a.requires_grad_(True)
c = a * 6
print(b)
print(c)
</pre></div>
<pre class="example">
tensor([5., 5., 5., 5., 5.])
tensor([6., 6., 6., 6., 6.], grad_fn=&lt;MulBackward0&gt;)
</pre>
<p>Two things to note, one is that the gradient function is only set while the <code>requires_grad</code> attribute is true, the other is that this only works on the leafs in the graph - you can set it on <code>a</code> and <code>b</code> but not <code>c</code> - because since I set <code>requires_grad</code> to True on <code>a</code>, when I created <code>c</code> by multiplying <code>a</code> by 6, <code>c</code> became part of <code>a</code>'s graphâ€¦ I think. Anyway, you can't set it on tensors that are part of the backpropagation path.</p>
</div>
<div class="outline-4" id="outline-container-org94c93f8">
<h4 id="org94c93f8">Backpropagation</h4>
<div class="outline-text-4" id="text-org94c93f8">
<p>You run back-propagation by calling the <a href="https://pytorch.org/docs/stable/autograd.html#torch.Tensor.backward"><code>backward</code></a> method on the last tensor in the graph. In our case the last tensor we have (<code>tenser</code>) doesn't output numbers so we need to create a final tensor that does for back-propagation to work.</p>
<div class="highlight">
<pre><span></span>output = tenser.mean()
output.backward()
print(tense.grad)
</pre></div>
<pre class="example">
tensor([[1.2500, 1.2500],
        [1.2500, 1.2500]])
</pre>
<p>After one pass through the network (and back) our root-node tensor has some gradients.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgb69df50">
<h4 id="orgb69df50">Context Manager</h4>
<div class="outline-text-4" id="text-orgb69df50">
<p>If you need to temporarily turn the gradient tracking on or off you can use a context manager.</p>
<div class="highlight">
<pre><span></span>print((tense*2).requires_grad)
with torch.no_grad():
    print((tense* 2).requires_grad)
print((tense * 2).requires_grad)
</pre></div>
<pre class="example">
True
False
True
</pre>
<p>Note that the root-will still have <code>require_grad</code> as true, it's the output of operations working with it that don't get the gradient set.</p>
<div class="highlight">
<pre><span></span>print(tense.requires_grad)
with torch.no_grad():
    print(tense.requires_grad)
print(tense.requires_grad)
</pre></div>
<pre class="example">
True
True
True
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org8b2c900">
<h3 id="org8b2c900">Neural Networks</h3>
<div class="outline-text-3" id="text-org8b2c900"></div>
<div class="outline-4" id="outline-container-orgac3c5f8">
<h4 id="orgac3c5f8">A Typical Model Training Procedure</h4>
<div class="outline-text-4" id="text-orgac3c5f8">
<ol class="org-ol">
<li>Define the neural network</li>
<li>Iterate over a dataset of inputs</li>
<li>Process each input through the network</li>
<li>Compute the loss (how much error there is)</li>
<li>Update the weights of the network</li>
</ol>
<p>The most common way to update the weights is to use a simple formula. \[ weight = weight - textit{learning rate} \times gradient \]</p>
</div>
</div>
<div class="outline-4" id="outline-container-orged6d945">
<h4 id="orged6d945">Defining the Network</h4>
<div class="outline-text-4" id="text-orged6d945">
<p>This will be a network with five layers - two <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Convolutional_layer">convolutional layers</a> followed by three <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Fully_connected_layer">fully-connected layers</a>. For the convolutional layers we're going to use <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer">Max-Pooling</a> and for the fully-connected layers we'll use <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#ReLU_layer">ReLU</a> activation.</p>
</div>
<ul class="org-ul">
<li><a id="org205934d"></a>The Layers<br>
<div class="outline-text-5" id="text-org205934d">
<p>You can just create the layers in the constructor, but since I'm trying to re-learn what's going on I'm going to peel it apart a little more.</p>
<p>The first layer is the input layer, so the <code>inputs</code> have to match whatever data you are going to get. In our case we are going to look at a black and white image so it has one input-channel. The three required arguments to the <a href="https://pytorch.org/docs/stable/nn.html#convolution-layers">Conv2d</a> constructor are:</p>
<ul class="org-ul">
<li><code>in_channels</code></li>
<li><code>out_channels</code></li>
<li><code>kernel_size</code></li>
</ul>
<div class="highlight">
<pre><span></span>class LayerOne:
    inputs = 1
    outputs = 6
    convolution_size = 5
    layer = neural_network.Conv2d(inputs, outputs, convolution_size)
</pre></div>
<div class="highlight">
<pre><span></span>class LayerTwo:
    inputs = LayerOne.outputs
    outputs = 16
    convolution_size = 5
    layer = neural_network.Conv2d(inputs, outputs, convolution_size)
</pre></div>
<p>Layer Three is the first <a href="https://pytorch.org/docs/stable/nn.html#linear">Linear</a> layer. Linear layers do a linear transformation on the inputs.</p>
<p>\[ y = x W^T + b \]</p>
<p>Where <i>x</i> is the input, <i>W</i> is the weight matrix and <i>b</i> is a bias constant.</p>
<div class="highlight">
<pre><span></span>class LayerThree:
    inputs = (LayerTwo.outputs * LayerOne.convolution_size 
              * LayerTwo.convolution_size)
    outputs = 120
    layer = neural_network.Linear(inputs, outputs)
</pre></div>
<div class="highlight">
<pre><span></span>class LayerFour:
    inputs = LayerThree.outputs
    outputs = 84
    layer = neural_network.Linear(inputs, outputs)
</pre></div>
<p>This is the last layer so the outputs are the outputs for the model as a whole.</p>
<div class="highlight">
<pre><span></span>class LayerFive:
    inputs = LayerFour.outputs
    outputs = 10
    layer = neural_network.Linear(inputs, outputs)
</pre></div>
<p>For the forward-pass our convolutional layers will have their output pooled using <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.functional.max_pool2d">max_pool2d</a> and all the layers (except for the output layers) will use <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.functional.relu">relu</a> as the activation function to keep the model from being linear.</p>
<div class="highlight">
<pre><span></span>class NeuralNetwork(neural_network.Module):
    """A five-layer Convolutional Neural Network"""
    def __init__(self):
        super().__init__()
        self.layer_one = LayerOne.layer
        self.layer_two = LayerTwo.layer
        self.layer_three = LayerThree.layer
        self.layer_four = LayerFour.layer
        self.layer_five = LayerFive.layer
        return

    def flattened_features_counts(self, x):
        sizes = x.size()[1:]
        features = 1
        for size in sizes:
            features *= size
        return features

    def forward(self, x):
        """One forward pass through the network

        Args:
         x: a one-channel image

        Returns:
         a ten-output linear layer
        """
        x = functional.max_pool2d(functional.relu(self.layer_one(x)), (2, 2))
        x = functional.max_pool2d(functional.relu(self.layer_two(x)), 2)
        x = x.view(-1, self.flattened_features_counts(x))
        x = functional.relu(self.layer_three(x))
        x = functional.relu(self.layer_four(x))
        return self.layer_five(x)
</pre></div>
<div class="highlight">
<pre><span></span>model = NeuralNetwork()
print(model)
</pre></div>
<pre class="example">
NeuralNetwork(
  (layer_one): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
  (layer_two): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (layer_three): Linear(in_features=400, out_features=120, bias=True)
  (layer_four): Linear(in_features=120, out_features=84, bias=True)
  (layer_five): Linear(in_features=84, out_features=10, bias=True)
)
</pre>
<p>The output shows the parameters for each layer in our model.</p>
<p>A sample output.</p>
<div class="highlight">
<pre><span></span>INPUT_SIZE = 32
mock_image = torch.randn(1, 1, INPUT_SIZE, INPUT_SIZE)
output = model(mock_image)
print(output)
</pre></div>
<pre class="example">
tensor([[ 0.1163,  0.0882,  0.0529,  0.0546, -0.0196, -0.1215, -0.1736,  0.0659,
          0.0762, -0.0093]], grad_fn=&lt;AddmmBackward&gt;)
</pre>
<p>This is the output after one forward pass. Unfortunately we didn't want to train it on fake data so we should reset it.</p>
<div class="highlight">
<pre><span></span>model.zero_grad()
output.backward(torch.randn(1, 10))
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgd9a7502">
<h4 id="orgd9a7502">The Loss Function</h4>
</div>
<div class="outline-4" id="outline-container-org5d86b43">
<h4 id="org5d86b43">Backpropagation</h4>
</div>
<div class="outline-4" id="outline-container-org1a86a07">
<h4 id="org1a86a07">Update the Weights</h4>
</div>
</div>
<div class="outline-3" id="outline-container-orgfc6f12c">
<h3 id="orgfc6f12c">Training a Classifier</h3>
</div>
<div class="outline-3" id="outline-container-orgaf097cd">
<h3 id="orgaf097cd">Data Parallelism</h3>
</div>
</div>
<div class="outline-2" id="outline-container-org18f5b8d">
<h2 id="org18f5b8d">The Return</h2>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/pytorch/" rel="tag">pytorch</a></li>
<li><a class="tag p-category" href="../../../categories/tutorial/" rel="tag">tutorial</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../text/chatbot-tutorial/" rel="prev" title="Chatbot Tutorial">Previous post</a></li>
<li class="next"><a href="../../fastai/dog-and-cat-breed-classification/" rel="next" title="Dog and Cat Breed Classification (What's Your Pet?)">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script>
</body>
</html>
