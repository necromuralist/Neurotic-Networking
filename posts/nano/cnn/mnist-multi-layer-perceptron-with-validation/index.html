<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="This is a re-do fo the MNIST post with a validation set added." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>MNIST Multi-Layer Perceptron with Validation | Neurotic Networking</title>
<link href="../../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nano/cnn/mnist-multi-layer-perceptron-with-validation/index.html" rel="canonical"><!--[if lt IE 9]><script src="../../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../../dog-breed-classifier/dog-breed-classification/index.html" rel="prev" title="Dog Breed Classification" type="text/html">
<link href="../custom-filters/index.html" rel="next" title="Custom Filters" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="MNIST Multi-Layer Perceptron with Validation" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nano/cnn/mnist-multi-layer-perceptron-with-validation/index.html" property="og:url">
<meta content="This is a re-do fo the MNIST post with a validation set added." property="og:description">
<meta content="article" property="og:type">
<meta content="2018-11-27T12:02:56-08:00" property="article:published_time">
<meta content="classification" property="article:tag">
<meta content="cnn" property="article:tag">
<meta content="exercise" property="article:tag">
<meta content="validation" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../../pages/">Pages</a></li>
<li class="nav-item"><a class="nav-link" href="../../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../../rss.xml">RSS feed</a></li>
<li class="nav-item dropdown"><a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#">Monkey Pages</a>
<div class="dropdown-menu"><a class="dropdown-item" href="https://necromuralist.github.io/">The Cloistered Monkey</a> <a class="dropdown-item" href="https://necromuralist.github.io/Ape-Iron/">Ape Iron</a> <a class="dropdown-item" href="https://necromuralist.github.io/Bowling-For-Data/">Bowling For Data</a> <a class="dropdown-item" href="https://necromuralist.github.io/Beach-Pig-Thigh/">Beach-Pig Rump & Thigh</a> <a class="dropdown-item" href="https://necromuralist.github.io/Visions-Voices-Data/">Visions, Voices, Data</a></div>
</li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="#">MNIST Multi-Layer Perceptron with Validation</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="#" rel="bookmark"><time class="published dt-published" datetime="2018-11-27T12:02:56-08:00" itemprop="datePublished" title="2018-11-27 12:02">2018-11-27 12:02</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="index.html#org07f929f">Introduction</a></li>
<li><a href="index.html#orgc076fc5">Setup</a></li>
<li><a href="index.html#orgf35059c">The Data</a></li>
<li><a href="index.html#org3084f1e">Visualize a Batch of Training Data</a></li>
<li><a href="index.html#orgcf4414d">Define the Network Architecture</a></li>
<li><a href="index.html#org62a662e">Specify the Loss Function and Optimizer</a></li>
<li><a href="index.html#org5eb865e">Train the Network</a></li>
<li><a href="index.html#org19a5a14">Testing the Best Model</a></li>
<li><a href="index.html#orga324222">Visualize Test Results</a></li>
<li><a href="index.html#orge26da5d">Object-Oriented Trainer</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org07f929f">
<h2 id="org07f929f">Introduction</h2>
<div class="outline-text-2" id="text-org07f929f">
<p>This is from <a href="https://github.com/udacity/deep-learning-v2-pytorch.git">Udacity's Deep Learning Repository</a> which supports their Deep Learning Nanodegree.</p>
<p>We are going to train a <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">Multi-Layer Perceptron</a> to classify images from the <a href="http://yann.lecun.com/exdb/mnist/">MNIST database</a> of hand-written digits.</p>
</div>
</div>
<div class="outline-2" id="outline-container-orgc076fc5">
<h2 id="orgc076fc5">Setup</h2>
<div class="outline-text-2" id="text-orgc076fc5"></div>
<div class="outline-3" id="outline-container-org9d37524">
<h3 id="org9d37524">Imports</h3>
<div class="outline-text-3" id="text-org9d37524"></div>
<div class="outline-4" id="outline-container-org14c785f">
<h4 id="org14c785f">From Python</h4>
<div class="outline-text-4" id="text-org14c785f">
<div class="highlight">
<pre><span></span> <span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
 <span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>
 <span class="kn">import</span> <span class="nn">gc</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1b2a2e4">
<h4 id="org1b2a2e4">From PyPi</h4>
<div class="outline-text-4" id="text-org1b2a2e4">
<div class="highlight">
<pre><span></span> <span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
 <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
 <span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
 <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">pyplot</span>
 <span class="kn">import</span> <span class="nn">seaborn</span>
 <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
 <span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
 <span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
 <span class="kn">import</span> <span class="nn">torch</span>
 <span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgad6ffb0">
<h4 id="orgad6ffb0">This Project</h4>
<div class="outline-text-4" id="text-orgad6ffb0">
<div class="highlight">
<pre><span></span> <span class="kn">from</span> <span class="nn">neurotic.tangles.data_paths</span> <span class="kn">import</span> <span class="n">DataPathTwo</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org8ab9eb9">
<h3 id="org8ab9eb9">Setup the Plotting</h3>
<div class="outline-text-3" id="text-org8ab9eb9">
<div class="highlight">
<pre><span></span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">'matplotlib'</span><span class="p">,</span> <span class="s1">'inline'</span><span class="p">)</span>
 <span class="n">seaborn</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">"whitegrid"</span><span class="p">,</span>
             <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">"axes.grid"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="s2">"font.family"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"sans-serif"</span><span class="p">],</span>
                 <span class="s2">"font.sans-serif"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"Latin Modern Sans"</span><span class="p">,</span> <span class="s2">"Lato"</span><span class="p">],</span>
                 <span class="s2">"figure.figsize"</span><span class="p">:</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">12</span><span class="p">)},</span>
             <span class="n">font_scale</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc226952">
<h3 id="orgc226952">Types</h3>
<div class="outline-text-3" id="text-orgc226952">
<div class="highlight">
<pre><span></span> <span class="n">Outcome</span> <span class="o">=</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgf35059c">
<h2 id="orgf35059c">The Data</h2>
<div class="outline-text-2" id="text-orgf35059c"></div>
<div class="outline-3" id="outline-container-org0f93916">
<h3 id="org0f93916">The Path To the Data</h3>
<div class="outline-text-3" id="text-org0f93916">
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">()</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">DataPathTwo</span><span class="p">(</span><span class="n">folder_key</span><span class="o">=</span><span class="s2">"MNIST"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">folder</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">path</span><span class="o">.</span><span class="n">folder</span><span class="o">.</span><span class="n">exists</span><span class="p">()</span>
</pre></div>
<pre class="example">
/home/hades/datasets/MNIST
</pre></div>
</div>
<div class="outline-3" id="outline-container-org702bf85">
<h3 id="org702bf85">Some Settings</h3>
<div class="outline-text-3" id="text-org702bf85">
<p>Since I downloaded the data earlier for some other exercise forking sub-processes is probably unnecessary, and for the training and testing we'll use a relatively small batch-size of 20.</p>
<div class="highlight">
<pre><span></span><span class="n">WORKERS</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">VALIDATION_PROPORTION</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.01</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb478365">
<h3 id="orgb478365">A Transform</h3>
<div class="outline-text-3" id="text-orgb478365">
<p>We're just going to convert the images to tensors.</p>
<div class="highlight">
<pre><span></span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0e4f99a">
<h3 id="org0e4f99a">Split Up the Training and Testing Data</h3>
<div class="outline-text-3" id="text-org0e4f99a">
<div class="highlight">
<pre><span></span><span class="n">training_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">path</span><span class="o">.</span><span class="n">folder</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">path</span><span class="o">.</span><span class="n">folder</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1de5ee4">
<h3 id="org1de5ee4">Make a Validation Set</h3>
<div class="outline-text-3" id="text-org1de5ee4">
<p>Now we're going to re-split the training-data into training and validation data. First we're going to generate indices for each set using sklearn's <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"><code>train_test_split</code></a>.</p>
<div class="highlight">
<pre><span></span><span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)))</span>
<span class="n">training_indices</span><span class="p">,</span> <span class="n">validation_indices</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">VALIDATION_PROPORTION</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_indices</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_indices</span><span class="p">))</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_indices</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">==</span> <span class="n">VALIDATION_PROPORTION</span>
</pre></div>
<pre class="example">
48000
12000
</pre>
<p>Now that we have our indices we need to create some samplers that can be passed to the Data Loaders. We need them to create the batches from our data.</p>
<div class="highlight">
<pre><span></span><span class="n">training_sampler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">training_indices</span><span class="p">)</span>
<span class="n">validation_sampler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">validation_indices</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org084f4ba">
<h3 id="org084f4ba">Create The Data Loaders</h3>
<div class="outline-text-3" id="text-org084f4ba">
<p>Now we will create the batch-iterators.</p>
<div class="highlight">
<pre><span></span><span class="n">training_batches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">training_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">training_sampler</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">WORKERS</span><span class="p">)</span>
</pre></div>
<p>For the validation batch we pass in the training data and use the validation-sampler to create a separate set of batches.</p>
<div class="highlight">
<pre><span></span><span class="n">validation_batches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">training_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">validation_sampler</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">WORKERS</span><span class="p">)</span>
</pre></div>
<p>Since we're not splitting the testing data it doesn't get a sampler.</p>
<div class="highlight">
<pre><span></span><span class="n">test_batches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">WORKERS</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org3084f1e">
<h2 id="org3084f1e">Visualize a Batch of Training Data</h2>
<div class="outline-text-2" id="text-org3084f1e">
<p>Our first step is to take a look at the data, make sure it is loaded in correctly, then make any initial observations about patterns in that data.</p>
</div>
<div class="outline-3" id="outline-container-orgd3b2e4d">
<h3 id="orgd3b2e4d">Grab a batch</h3>
<div class="outline-text-3" id="text-orgd3b2e4d">
<div class="highlight">
<pre><span></span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">training_batches</span><span class="p">)</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
<p>Now that we have a batch we're going to plot the images in the batch, along with the corresponding labels.</p>
<div class="highlight">
<pre><span></span><span class="n">seaborn</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">figure</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"First Batch"</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">"bold"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">figure</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">]),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
    <span class="c1"># print out the correct label for each image</span>
    <span class="c1"># .item() gets the value contained in a Tensor</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
<div class="figure" id="orgc04313a">
<p><img alt="batch.png" src="batch.png"></p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org6ce662a">
<h3 id="org6ce662a">View a Single Image</h3>
<div class="outline-text-3" id="text-org6ce662a">
<p>Now we're going to take a closer look at the second image in the batch.</p>
<div class="highlight">
<pre><span></span><span class="n">image</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">"white"</span><span class="p">)</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span> 
<span class="n">figure</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()),</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">"xx-large"</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">"bold"</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">figure</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">/</span><span class="mf">2.5</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">width</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">height</span><span class="p">):</span>
        <span class="n">val</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="n">image</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span> <span class="o">!=</span><span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">val</span><span class="p">),</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">x</span><span class="p">),</span>
                    <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span>
                    <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="s1">'white'</span> <span class="k">if</span> <span class="n">image</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span><span class="o">&lt;</span><span class="n">threshold</span> <span class="k">else</span> <span class="s1">'black'</span><span class="p">)</span>
</pre></div>
<div class="figure" id="org0ac6168">
<p><img alt="image.png" src="image.png"></p>
</div>
<p>We're looking at a single image with the normalized values for each pixel superimposed on it. It looks like black is 0 and white is 1, although for this image most of the 'white' pixels are just a little less than one.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgcf4414d">
<h2 id="orgcf4414d">Define the Network <a href="http://pytorch.org/docs/stable/nn.html">Architecture</a></h2>
<div class="outline-text-2" id="text-orgcf4414d">
<p>The architecture will be responsible for seeing as input a 784-dim Tensor of pixel values for each image, and producing a Tensor of length 10 (our number of classes) that indicates the class scores for an input image. This particular example uses two hidden layers and dropout to avoid overfitting.</p>
<p>These values are based on the <a href="https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py">keras</a> example implementation.</p>
<div class="highlight">
<pre><span></span><span class="n">INPUT_NODES</span> <span class="o">=</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span>
<span class="n">HIDDEN_NODES_1</span> <span class="o">=</span> <span class="n">HIDDEN_NODES_2</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">DROPOUT</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">CLASSES</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">MultiLayerPerceptron</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""A Multi-Layer Perceptron</span>

<span class="sd">    This is a network with 2 hidden layers</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">fully_connected_layer_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">INPUT_NODES</span><span class="p">,</span> <span class="n">HIDDEN_NODES_1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fully_connected_layer_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_NODES_1</span><span class="p">,</span> <span class="n">HIDDEN_NODES_2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">HIDDEN_NODES_2</span><span class="p">,</span> <span class="n">CLASSES</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">DROPOUT</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""One feed-forward through the network</span>

<span class="sd">       Args:</span>
<span class="sd">        x: a 28 x 28 tensor</span>

<span class="sd">       Returns:</span>
<span class="sd">        tensor: output of the network without activation</span>
<span class="sd">       """</span>
        <span class="c1"># flatten image input</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">INPUT_NODES</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fully_connected_layer_1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fully_connected_layer_2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>        
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-org6ee99de">
<h3 id="org6ee99de">Initialize the Neural Network</h3>
<div class="outline-text-3" id="text-org6ee99de">
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MultiLayerPerceptron</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example">
MultiLayerPerceptron(
  (fully_connected_layer_1): Linear(in_features=784, out_features=512, bias=True)
  (fully_connected_layer_2): Linear(in_features=512, out_features=512, bias=True)
  (output): Linear(in_features=512, out_features=10, bias=True)
  (dropout): Dropout(p=0.2)
)
</pre></div>
</div>
<div class="outline-3" id="outline-container-orga5ae92b">
<h3 id="orga5ae92b">A Little CUDA</h3>
<div class="outline-text-3" id="text-orga5ae92b">
<p>This sets it up to use CUDA (if available).</p>
<div class="highlight">
<pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Using </span><span class="si">{}</span><span class="s2"> GPUs"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()))</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Only 1 GPU available"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Only 1 GPU available
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org62a662e">
<h2 id="org62a662e">Specify the <a href="http://pytorch.org/docs/stable/nn.html#loss-functions">Loss Function</a> and <a href="http://pytorch.org/docs/stable/optim.html">Optimizer</a></h2>
<div class="outline-text-2" id="text-org62a662e">
<p>We're going to use <a href="http://pytorch.org/docs/stable/nn.html#loss-functions">cross-entropy loss</a> for classification. PyTorch's cross entropy function applies a softmax function to the output layer <b>and</b> then calculates the log loss (so you don't want to do softmax as part of the model output).</p>
<div class="highlight">
<pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org5eb865e">
<h2 id="org5eb865e">Train the Network</h2>
<div class="outline-text-2" id="text-org5eb865e">
<p>We're going to do a quasi-search by optimizing over 50 epochs and keeping the model that has the best validation score.</p>
<div class="highlight">
<pre><span></span><span class="c1"># number of epochs to train the model</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">SAVED_MODEL</span><span class="o">=</span> <span class="s1">'multilayer_perceptron.pt'</span>
</pre></div>
<div class="highlight">
<pre><span></span> <span class="k">def</span> <span class="nf">process_batch</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                   <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Outcome</span><span class="p">:</span>
<span class="w">     </span><span class="sd">"""process one batch of the data</span>

<span class="sd">     Args:</span>
<span class="sd">      model: model to predict target</span>
<span class="sd">      data: data to use to predict target</span>
<span class="sd">      target: what we're trying to predict</span>
<span class="sd">      device: cpu or gpu</span>

<span class="sd">     Returns:</span>
<span class="sd">      outcome: loss and correct count</span>
<span class="sd">     """</span>
     <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
     <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
     <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
     <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
     <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
          <span class="n">batches</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
          <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Outcome</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Perform one forward pass through the batches</span>

<span class="sd">    Args:</span>
<span class="sd">     model: thing to train</span>
<span class="sd">     batches: batch-iterator of training data</span>
<span class="sd">     device: cpu or cuda device</span>

<span class="sd">    Returns:</span>
<span class="sd">     outcome: cumulative loss, accuracy for the batches</span>
<span class="sd">    """</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">correct</span> <span class="o">=</span> <span class="n">process_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">total_correct</span> <span class="o">+=</span> <span class="n">correct</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">total_correct</span><span class="o">/</span><span class="n">count</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">batches</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
             <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Outcome</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Calculate the loss for the model</span>

<span class="sd">    Args:</span>
<span class="sd">     model: the model to validate</span>
<span class="sd">     batches: the batch-iterator of validation data</span>
<span class="sd">     device: cuda or cpu</span>

<span class="sd">    Returns:</span>
<span class="sd">     Outcome: Cumulative loss, Accuracy over batches</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">total_correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">correct</span> <span class="o">=</span> <span class="n">process_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">total_correct</span> <span class="o">+=</span> <span class="n">correct</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">total_correct</span><span class="o">/</span><span class="n">count</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># initialize tracker for minimum validation loss</span>
<span class="n">lowest_validation_loss</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">Inf</span>
<span class="n">training_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">validation_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">training_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">validation_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">training_batches</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">training_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">mean_training_loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">training_batches</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">training_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>

    <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">validation_batches</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">validation_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">mean_validation_loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_batches</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">validation_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">mean_validation_loss</span> <span class="o">&lt;=</span> <span class="n">lowest_validation_loss</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch </span><span class="si">{}</span><span class="s1">: Validation loss decreased (</span><span class="si">{:.6f}</span><span class="s1"> --&gt; </span><span class="si">{:.6f}</span><span class="s1">).  Saving model ...'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">epoch</span><span class="p">,</span>
            <span class="n">lowest_validation_loss</span><span class="p">,</span>
            <span class="n">mean_validation_loss</span><span class="p">))</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">SAVED_MODEL</span><span class="p">)</span>
        <span class="n">lowest_validation_loss</span> <span class="o">=</span> <span class="n">mean_validation_loss</span>
</pre></div>
<pre class="example" id="org76dd4bb">
Epoch 1: Validation loss decreased (inf --&gt; 0.076556).  Saving model ...
Epoch 2: Validation loss decreased (0.076556 --&gt; 0.058478).  Saving model ...
Epoch 3: Validation loss decreased (0.058478 --&gt; 0.049405).  Saving model ...
Epoch 4: Validation loss decreased (0.049405 --&gt; 0.043155).  Saving model ...
Epoch 5: Validation loss decreased (0.043155 --&gt; 0.037079).  Saving model ...
Epoch 6: Validation loss decreased (0.037079 --&gt; 0.032932).  Saving model ...
Epoch 7: Validation loss decreased (0.032932 --&gt; 0.029682).  Saving model ...
Epoch 8: Validation loss decreased (0.029682 --&gt; 0.028046).  Saving model ...
Epoch 9: Validation loss decreased (0.028046 --&gt; 0.025318).  Saving model ...
Epoch 10: Validation loss decreased (0.025318 --&gt; 0.023867).  Saving model ...
Epoch 11: Validation loss decreased (0.023867 --&gt; 0.022447).  Saving model ...
Epoch 12: Validation loss decreased (0.022447 --&gt; 0.021411).  Saving model ...
Epoch 13: Validation loss decreased (0.021411 --&gt; 0.020793).  Saving model ...
Epoch 14: Validation loss decreased (0.020793 --&gt; 0.019830).  Saving model ...
Epoch 15: Validation loss decreased (0.019830 --&gt; 0.018676).  Saving model ...
Epoch 16: Validation loss decreased (0.018676 --&gt; 0.018644).  Saving model ...
Epoch 17: Validation loss decreased (0.018644 --&gt; 0.017666).  Saving model ...
Epoch 18: Validation loss decreased (0.017666 --&gt; 0.017635).  Saving model ...
Epoch 20: Validation loss decreased (0.017635 --&gt; 0.016688).  Saving model ...
Epoch 21: Validation loss decreased (0.016688 --&gt; 0.016489).  Saving model ...
Epoch 22: Validation loss decreased (0.016489 --&gt; 0.016364).  Saving model ...
Epoch 23: Validation loss decreased (0.016364 --&gt; 0.015944).  Saving model ...
Epoch 24: Validation loss decreased (0.015944 --&gt; 0.015633).  Saving model ...
Epoch 26: Validation loss decreased (0.015633 --&gt; 0.015446).  Saving model ...
Epoch 27: Validation loss decreased (0.015446 --&gt; 0.015257).  Saving model ...
Epoch 30: Validation loss decreased (0.015257 --&gt; 0.015216).  Saving model ...
Epoch 31: Validation loss decreased (0.015216 --&gt; 0.015175).  Saving model ...
Epoch 34: Validation loss decreased (0.015175 --&gt; 0.014866).  Saving model ...
Epoch 36: Validation loss decreased (0.014866 --&gt; 0.014530).  Saving model ...
</pre>
<p>The training and validation loss seems surprisingly good.</p>
<div class="highlight">
<pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_losses</span><span class="p">)))</span>
<span class="n">figure</span><span class="p">,</span> <span class="n">axe</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">figure</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"Loss Per Batch"</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">"bold"</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Training"</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">validation_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Validation"</span><span class="p">)</span>
<span class="n">legend</span> <span class="o">=</span> <span class="n">axe</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
<div class="figure" id="org3efb20f">
<p><img alt="losses.png" src="losses.png"></p>
</div>
<p>So it looks like it improves fairly quickly then after 36 epochs the model stops improving.</p>
</div>
</div>
<div class="outline-2" id="outline-container-org19a5a14">
<h2 id="org19a5a14">Testing the Best Model</h2>
<div class="outline-text-2" id="text-org19a5a14">
<div class="highlight">
<pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SAVED_MODEL</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">test_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">class_correct</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="mf">0.</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="n">class_total</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="mf">0.</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_batches</span><span class="p">:</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># calculate the loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="c1"># update test loss </span>
    <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># convert output probabilities to predicted class</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># compare predictions to true label</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">)))</span>
    <span class="c1"># calculate test accuracy for each object class</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">):</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">class_correct</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="n">correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">class_total</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># calculate and print avg test loss</span>
<span class="n">test_loss</span> <span class="o">=</span> <span class="n">test_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">test_batches</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Test Loss: </span><span class="si">{:.6f}</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_loss</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">class_total</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Test Accuracy of </span><span class="si">%5s</span><span class="s1">: </span><span class="si">%2d%%</span><span class="s1"> (</span><span class="si">%2d</span><span class="s1">/</span><span class="si">%2d</span><span class="s1">)'</span> <span class="o">%</span> <span class="p">(</span>
            <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">class_correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">class_total</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_correct</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_total</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Test Accuracy of </span><span class="si">%5s</span><span class="s1">: N/A (no training examples)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">classes</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></div>
<pre class="example" id="org50e0153">
Test Loss: 0.059497

Test Accuracy of     0: 99% (974/980)
Test Accuracy of     1: 99% (1127/1135)
Test Accuracy of     2: 97% (1009/1032)
Test Accuracy of     3: 98% (994/1010)
Test Accuracy of     4: 97% (960/982)
Test Accuracy of     5: 97% (867/892)
Test Accuracy of     6: 98% (941/958)
Test Accuracy of     7: 98% (1008/1028)
Test Accuracy of     8: 97% (947/974)
Test Accuracy of     9: 97% (986/1009)
</pre></div>
</div>
<div class="outline-2" id="outline-container-orga324222">
<h2 id="orga324222">Visualize Test Results</h2>
<div class="outline-text-2" id="text-orga324222">
<div class="highlight">
<pre><span></span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">test_batches</span><span class="p">)</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
<span class="c1"># matplotlib doesn't like the CUDA and the model doesn't like the CPU... too bad for the model.</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># prep images for display</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># plot the images in the batch, along with predicted and true labels</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">title</span> <span class="o">=</span> <span class="n">figure</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"Test Predictions"</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">"bold"</span><span class="p">,</span> <span class="n">position</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">))</span>

<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">figure</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">]),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"</span><span class="si">{}</span><span class="s2"> (</span><span class="si">{}</span><span class="s2">)"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()),</span> <span class="nb">str</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())),</span>
                 <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="s2">"green"</span> <span class="k">if</span> <span class="n">preds</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">==</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">else</span> <span class="s2">"red"</span><span class="p">))</span>
<span class="n">figure</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
<div class="figure" id="org5ccf086">
<p><img alt="test_results.png" src="test_results.png"></p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orge26da5d">
<h2 id="orge26da5d">Object-Oriented Trainer</h2>
<div class="outline-text-2" id="text-orge26da5d">
<p>This just bundles up the earlier stuff.</p>
<div class="highlight">
<pre><span></span> <span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
<span class="w">     </span><span class="sd">"""Train-test-validate the model</span>

<span class="sd">     Args:</span>
<span class="sd">      train: training batches</span>
<span class="sd">      validate: validation batches</span>
<span class="sd">      test: testing batches</span>
<span class="sd">      epochs: number of times to repeat training over the batches</span>
<span class="sd">      model_filename: name to save the hyperparameters of best model</span>
<span class="sd">      learning_rate: how much to update the weights</span>
<span class="sd">     """</span>
     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
                  <span class="n">validate</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
                  <span class="n">test</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
                  <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                  <span class="n">model_filename</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"multilayer_perceptron.pth"</span><span class="p">,</span>
                  <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">training_batches</span> <span class="o">=</span> <span class="n">train</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">validation_batches</span> <span class="o">=</span> <span class="n">validate</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">test_batches</span> <span class="o">=</span> <span class="n">test</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">save_as</span> <span class="o">=</span> <span class="n">model_filename</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="kc">None</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">_criterion</span> <span class="o">=</span> <span class="kc">None</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="kc">None</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="kc">None</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">validation_losses</span> <span class="o">=</span> <span class="p">[]</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">training_losses</span> <span class="o">=</span> <span class="p">[]</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">validation_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">training_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">best_parameters</span> <span class="o">=</span> <span class="kc">None</span>
         <span class="k">return</span>

     <span class="nd">@property</span>
     <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">         </span><span class="sd">"""The Multi-Layer Perceptron"""</span>
         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span> <span class="o">=</span> <span class="n">MultiLayerPerceptron</span><span class="p">()</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>

     <span class="nd">@property</span>
     <span class="k">def</span> <span class="nf">criterion</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">         </span><span class="sd">"""The Loss Measurer"""</span>
         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_criterion</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">_criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_criterion</span>

     <span class="nd">@property</span>
     <span class="k">def</span> <span class="nf">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">         </span><span class="sd">"""The gradient descent"""</span>
         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                                               <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span>

     <span class="nd">@property</span>
     <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">         </span><span class="sd">"""The CPU or GPU"""</span>
         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>


     <span class="k">def</span> <span class="nf">process_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Outcome</span><span class="p">:</span>
<span class="w">         </span><span class="sd">"""process one batch of the data</span>

<span class="sd">        Args:</span>
<span class="sd">         data: data to use to predict target</span>
<span class="sd">         target: what we're trying to predict</span>
<span class="sd">         device: cpu or gpu</span>

<span class="sd">        Returns:</span>
<span class="sd">         outcome: loss and correct count</span>
<span class="sd">        """</span>
         <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
         <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
         <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
         <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
         <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

     <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Outcome</span><span class="p">:</span>
<span class="w">         </span><span class="sd">"""Perform one forward pass through the batches</span>

<span class="sd">        Returns:</span>
<span class="sd">         outcome: cumulative loss, accuracy for the batches</span>
<span class="sd">        """</span>
         <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
         <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
         <span class="n">total_correct</span> <span class="o">=</span> <span class="mi">0</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
         <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_batches</span><span class="p">:</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
             <span class="n">loss</span><span class="p">,</span> <span class="n">correct</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
             <span class="n">count</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
             <span class="n">total_correct</span> <span class="o">+=</span> <span class="n">correct</span>
             <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span>
             <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
             <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
             <span class="k">del</span> <span class="n">loss</span>
         <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">total_loss</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="n">total_correct</span><span class="o">/</span><span class="n">count</span><span class="p">)</span>

     <span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Outcome</span><span class="p">:</span>
<span class="w">         </span><span class="sd">"""Calculate the loss for the model</span>

<span class="sd">        Returns:</span>
<span class="sd">         Outcome: Cumulative loss, Accuracy over batches</span>
<span class="sd">        """</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
         <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
         <span class="n">total_correct</span> <span class="o">=</span> <span class="mi">0</span>
         <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
         <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_batches</span><span class="p">:</span>
             <span class="n">loss</span><span class="p">,</span> <span class="n">correct</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
             <span class="n">count</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
             <span class="n">total_correct</span> <span class="o">+=</span> <span class="n">correct</span>
             <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
             <span class="k">del</span> <span class="n">loss</span>
         <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">total_loss</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="n">total_correct</span><span class="o">/</span><span class="n">count</span><span class="p">)</span>

     <span class="k">def</span> <span class="nf">run_training</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">         </span><span class="sd">"""Runs the training and validation"""</span>
         <span class="n">lowest_validation_loss</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">Inf</span>
         <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
             <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
             <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">training_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
             <span class="n">mean_training_loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_batches</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">training_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
             <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">validate</span><span class="p">()</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">validation_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
             <span class="n">mean_validation_loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_batches</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">validation_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>

             <span class="k">if</span> <span class="n">mean_validation_loss</span> <span class="o">&lt;=</span> <span class="n">lowest_validation_loss</span><span class="p">:</span>
                 <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch </span><span class="si">{}</span><span class="s1">: Validation loss decreased (</span><span class="si">{:.6f}</span><span class="s1"> --&gt; </span><span class="si">{:.6f}</span><span class="s1">).  Saving model ...'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                     <span class="n">epoch</span><span class="p">,</span>
                     <span class="n">lowest_validation_loss</span><span class="p">,</span>
                     <span class="n">mean_validation_loss</span><span class="p">))</span>
                 <span class="bp">self</span><span class="o">.</span><span class="n">best_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
                 <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_parameters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_as</span><span class="p">)</span>
                 <span class="n">lowest_validation_loss</span> <span class="o">=</span> <span class="n">mean_validation_loss</span>
         <span class="k">return</span>

     <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">         </span><span class="sd">"""Test Our Model"""</span>
         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
             <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">"call ``run_training`` or set ``best_parameters"</span><span class="p">)</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_parameters</span><span class="p">)</span>
         <span class="n">test_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
         <span class="n">digits</span> <span class="o">=</span> <span class="mi">10</span>
         <span class="n">class_correct</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">digits</span>
         <span class="n">class_total</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">digits</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

         <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_batches</span><span class="p">:</span>
             <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
             <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
             <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
             <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

             <span class="n">_</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
             <span class="n">correct</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span>
                 <span class="n">target</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">predictions</span><span class="p">)))</span>
             <span class="c1"># calculate test accuracy for each object class</span>
             <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
                 <span class="n">label</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                 <span class="n">class_correct</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="n">correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                 <span class="n">class_total</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

         <span class="c1"># calculate and print avg test loss</span>
         <span class="n">test_loss</span> <span class="o">=</span> <span class="n">test_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_batches</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
         <span class="nb">print</span><span class="p">(</span><span class="s1">'Test Loss: </span><span class="si">{:.6f}</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_loss</span><span class="p">))</span>

         <span class="k">for</span> <span class="n">digit</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
             <span class="k">if</span> <span class="n">class_total</span><span class="p">[</span><span class="n">digit</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                 <span class="nb">print</span><span class="p">(</span><span class="s1">'Test Accuracy of </span><span class="si">%5s</span><span class="s1">: </span><span class="si">%2d%%</span><span class="s1"> (</span><span class="si">%2d</span><span class="s1">/</span><span class="si">%2d</span><span class="s1">)'</span> <span class="o">%</span> <span class="p">(</span>
                     <span class="nb">str</span><span class="p">(</span><span class="n">digit</span><span class="p">),</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">class_correct</span><span class="p">[</span><span class="n">digit</span><span class="p">]</span> <span class="o">/</span> <span class="n">class_total</span><span class="p">[</span><span class="n">digit</span><span class="p">],</span>
                     <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_correct</span><span class="p">[</span><span class="n">digit</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_total</span><span class="p">[</span><span class="n">digit</span><span class="p">])))</span>
             <span class="k">else</span><span class="p">:</span>
                 <span class="nb">print</span><span class="p">(</span><span class="s1">'Test Accuracy of </span><span class="si">%5s</span><span class="s1">: N/A (no training examples)'</span> <span class="o">%</span> <span class="p">(</span><span class="n">classes</span><span class="p">[</span><span class="n">digit</span><span class="p">]))</span>
         <span class="k">return</span>
</pre></div>
<p>For some reason, this raises an error when the backward propagation step is run.</p>
<pre class="example" id="org09b81de">
RuntimeError: CUDA error: out of memory
</pre>
<p>So I can't run it until I figure out what's going on. <b>Update</b> - it looks like casting the outputs of the functions to floats solved the problem. Apparently even they look like floats, whatever the <code>item()</code> method returns prevents the freeing up of the memory, so casting them to floats fixes the memory problem.</p>
<div class="highlight">
<pre><span></span> <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">training_batches</span><span class="p">,</span> <span class="n">validation_batches</span><span class="p">,</span> <span class="n">test_batches</span><span class="p">)</span>
 <span class="n">trainer</span><span class="o">.</span><span class="n">run_training</span><span class="p">()</span>
</pre></div>
<pre class="example" id="org64172d5">
Epoch 1: Validation loss decreased (inf --&gt; 0.077417).  Saving model ...
Epoch 2: Validation loss decreased (0.077417 --&gt; 0.058746).  Saving model ...
Epoch 3: Validation loss decreased (0.058746 --&gt; 0.048325).  Saving model ...
Epoch 4: Validation loss decreased (0.048325 --&gt; 0.040851).  Saving model ...
Epoch 5: Validation loss decreased (0.040851 --&gt; 0.036083).  Saving model ...
Epoch 6: Validation loss decreased (0.036083 --&gt; 0.032722).  Saving model ...
Epoch 7: Validation loss decreased (0.032722 --&gt; 0.028545).  Saving model ...
Epoch 8: Validation loss decreased (0.028545 --&gt; 0.026376).  Saving model ...
Epoch 9: Validation loss decreased (0.026376 --&gt; 0.024063).  Saving model ...
Epoch 10: Validation loss decreased (0.024063 --&gt; 0.023637).  Saving model ...
Epoch 11: Validation loss decreased (0.023637 --&gt; 0.021980).  Saving model ...
Epoch 12: Validation loss decreased (0.021980 --&gt; 0.020723).  Saving model ...
Epoch 13: Validation loss decreased (0.020723 --&gt; 0.019802).  Saving model ...
Epoch 14: Validation loss decreased (0.019802 --&gt; 0.019013).  Saving model ...
Epoch 15: Validation loss decreased (0.019013 --&gt; 0.018458).  Saving model ...
Epoch 16: Validation loss decreased (0.018458 --&gt; 0.017919).  Saving model ...
Epoch 17: Validation loss decreased (0.017919 --&gt; 0.017918).  Saving model ...
Epoch 18: Validation loss decreased (0.017918 --&gt; 0.017127).  Saving model ...
Epoch 19: Validation loss decreased (0.017127 --&gt; 0.016704).  Saving model ...
Epoch 20: Validation loss decreased (0.016704 --&gt; 0.016167).  Saving model ...
Epoch 22: Validation loss decreased (0.016167 --&gt; 0.016154).  Saving model ...
Epoch 23: Validation loss decreased (0.016154 --&gt; 0.015817).  Saving model ...
Epoch 24: Validation loss decreased (0.015817 --&gt; 0.015352).  Saving model ...
Epoch 25: Validation loss decreased (0.015352 --&gt; 0.015075).  Saving model ...
Epoch 27: Validation loss decreased (0.015075 --&gt; 0.015059).  Saving model ...
Epoch 28: Validation loss decreased (0.015059 --&gt; 0.014940).  Saving model ...
Epoch 32: Validation loss decreased (0.014940 --&gt; 0.014644).  Saving model ...
Epoch 34: Validation loss decreased (0.014644 --&gt; 0.014383).  Saving model ...
Epoch 46: Validation loss decreased (0.014383 --&gt; 0.014357).  Saving model ...
</pre>
<div class="highlight">
<pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">training_accuracies</span><span class="p">)))</span>
<span class="n">figure</span><span class="p">,</span> <span class="n">axe</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">figure</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"Model Accuracy"</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">"bold"</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">training_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Training"</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">validation_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Validation"</span><span class="p">)</span>
<span class="n">legend</span> <span class="o">=</span> <span class="n">axe</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
<div class="figure" id="orgdffa086">
<p><img alt="accuracy.png" src="accuracy.png"></p>
</div>
<p>Although the validation loss decreases for a while, it nearly reaches its peak accuracy around 10 epochs. The training worked out a little differently this time, so here's the losses again.</p>
<div class="highlight">
<pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">training_losses</span><span class="p">)))</span>
<span class="n">figure</span><span class="p">,</span> <span class="n">axe</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">figure</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"Loss Per Batch"</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">"bold"</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">training_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Training"</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">validation_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Validation"</span><span class="p">)</span>
<span class="n">legend</span> <span class="o">=</span> <span class="n">axe</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
<div class="figure" id="orgc13ec5a">
<p><img alt="losses_2.png" src="losses_2.png"></p>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../../categories/classification/index.html" rel="tag">classification</a></li>
<li><a class="tag p-category" href="../../../../categories/cnn/index.html" rel="tag">cnn</a></li>
<li><a class="tag p-category" href="../../../../categories/exercise/index.html" rel="tag">exercise</a></li>
<li><a class="tag p-category" href="../../../../categories/validation/index.html" rel="tag">validation</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../../dog-breed-classifier/dog-breed-classification/index.html" rel="prev" title="Dog Breed Classification">Previous post</a></li>
<li class="next"><a href="../custom-filters/index.html" rel="next" title="Custom Filters">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Scribbles by <a href="mailto:cloisteredmonkey.jmark@slmail.me">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>
<div id="license" xmlns:cc="http://creativecommons.org/ns#">This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" rel="license noopener noreferrer" style="display:inline-block;" target="_blank">CC BY 4.0 <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></div>
</footer>
</div>
</div>
<script src="../../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
