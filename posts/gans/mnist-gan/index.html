<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="An MNIST GAN with pytorch." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>MNIST GAN | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/gans/mnist-gan/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../../nlp/neural-machine-translation-helper-functions/" rel="prev" title="Neural Machine Translation: Helper Functions" type="text/html">
<link href="../../pytorch/pytorch-linear-regression/" rel="next" title="PyTorch Linear Regression" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="MNIST GAN" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/gans/mnist-gan/" property="og:url">
<meta content="An MNIST GAN with pytorch." property="og:description">
<meta content="article" property="og:type">
<meta content="2021-04-06T17:48:17-07:00" property="article:published_time">
<meta content="gans" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">MNIST GAN</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2021-04-06T17:48:17-07:00" itemprop="datePublished" title="2021-04-06 17:48">2021-04-06 17:48</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org3c0e743">Beginning</a>
<ul>
<li><a href="#org43f55f8">Imports</a></li>
<li><a href="#org15d69f9">Some Setup</a></li>
</ul>
</li>
<li><a href="#orgdf2583d">Middle</a>
<ul>
<li><a href="#orgdc5ac8c">The MNIST Dataset</a></li>
<li><a href="#org9182168">The Generator</a>
<ul>
<li><a href="#org6ea95f3">Verify the generator block function</a></li>
<li><a href="#orgb992f37">Building the Generator Class</a></li>
<li><a href="#org8f9d1d7">Verify the Generator Class</a></li>
</ul>
</li>
<li><a href="#org30f3386">Noise</a>
<ul>
<li><a href="#org2c07608">Verify the noise vector function</a></li>
</ul>
</li>
<li><a href="#org6dd9fc1">The Discriminator</a>
<ul>
<li><a href="#orga27f2bd">Verify the discriminator block function</a></li>
<li><a href="#orge5d47b4">The Discriminator Class</a></li>
</ul>
</li>
<li><a href="#org68476b3">Training</a>
<ul>
<li><a href="#orgcd1b715">Set your parameters</a></li>
<li><a href="#org93096d5">Load MNIST dataset as tensors</a></li>
<li><a href="#org0482b62">Generator Loss</a></li>
<li><a href="#org5e49a93">All Together</a></li>
</ul>
</li>
<li><a href="#org24d4dcf">Looking at the Final model.</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org3c0e743">
<h2 id="org3c0e743">Beginning</h2>
<div class="outline-text-2" id="text-org3c0e743"></div>
<div class="outline-3" id="outline-container-org43f55f8">
<h3 id="org43f55f8">Imports</h3>
<div class="outline-text-3" id="text-org43f55f8">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># local code</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org15d69f9">
<h3 id="org15d69f9">Some Setup</h3>
<div class="outline-text-3" id="text-org15d69f9">
<p>First we'll set the manual seed to make this reproducible.</p>
<div class="highlight">
<pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
<p>This is a convenience object to time the training.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
<p>This is for plotting.</p>
<div class="highlight">
<pre><span></span><span class="n">slug</span> <span class="o">=</span> <span class="s2">"mnist-gan"</span>

<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/gans/</span><span class="si">{</span><span class="n">slug</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span>
                           <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">,</span> <span class="s2">"sizing_mode"</span><span class="p">],</span>
                  <span class="n">defaults</span><span class="o">=</span><span class="p">[</span>
                      <span class="mi">900</span><span class="p">,</span>
                      <span class="mi">556</span><span class="p">,</span>
                      <span class="mi">2</span><span class="p">,</span>
                      <span class="s2">"#ddb377"</span><span class="p">,</span>
                      <span class="s2">"#4687b7"</span><span class="p">,</span>
                      <span class="s2">"#ce7b6d"</span><span class="p">,</span>
                      <span class="s2">"scale_both"</span><span class="p">,</span>
                  <span class="p">])()</span>

<span class="n">GANParts</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"GANParts"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"generator"</span><span class="p">,</span> <span class="s2">"generator_optimizer"</span><span class="p">,</span>
                                   <span class="s2">"discriminator"</span><span class="p">,</span> <span class="s2">"discriminator_optimizer"</span><span class="p">])</span>

<span class="n">PlotData</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"PlotData"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"steps"</span><span class="p">,</span> <span class="s2">"generator_losses"</span><span class="p">,</span>
                                   <span class="s2">"discriminator_losses"</span><span class="p">,</span> <span class="s2">"best_loss"</span><span class="p">])</span>

<span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/gans/mnist.pth"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">INFINITY</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgdf2583d">
<h2 id="orgdf2583d">Middle</h2>
<div class="outline-text-2" id="text-orgdf2583d"></div>
<div class="outline-3" id="outline-container-orgdc5ac8c">
<h3 id="orgdc5ac8c">The MNIST Dataset</h3>
<div class="outline-text-3" id="text-orgdc5ac8c">
<p>The training images we will be using are from a dataset called <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>. The dataset contains 60,000 images of handwritten digits, from 0 to 9.</p>
<p>The images are 28 pixels x 28 pixels in size. The small size of its images makes MNIST ideal for simple training. Additionally, these images are also in black-and-white so only one dimension, or "color channel", is needed to represent them. Pytorch has a <a href="https://pytorch.org/vision/0.8/datasets.html#mnist">version of it</a> ready-made for their system so we'll use theirs.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org9182168">
<h3 id="org9182168">The Generator</h3>
<div class="outline-text-3" id="text-org9182168">
<p>The first step is to build the generator component.</p>
<p>We'll start by creating a function to make a single layer/block for the generator's neural network. Each block should include a <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html">linear transformation</a> (\(y=xA^T + b\)) to the input to another shape, <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">batch normalization</a> for stabilization, and finally a non-linear activation function (<a href="https://pytorch.org/docs/master/generated/torch.nn.ReLU.html">ReLU</a> in this case).</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">generator_block</span><span class="p">(</span><span class="n">input_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Creates a block of the generator's neural network</span>

<span class="sd">    Args:</span>
<span class="sd">      input_features: the dimension of the input vector</span>
<span class="sd">      output_features: the dimension of the output vector</span>

<span class="sd">    Returns:</span>
<span class="sd">       a generator neural network layer, with a linear transformation </span>
<span class="sd">         followed by a batch normalization and then a relu activation</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_features</span><span class="p">,</span> <span class="n">output_features</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">output_features</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org6ea95f3">
<h4 id="org6ea95f3">Verify the generator block function</h4>
<div class="outline-text-4" id="text-org6ea95f3">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_gen_block</span><span class="p">(</span><span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                   <span class="n">test_rows</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">"""Test the generator block creator</span>

<span class="sd">    Args:</span>
<span class="sd">     in_features: number of features for the block input</span>
<span class="sd">     out_features: the final number of features for it to output</span>
<span class="sd">     test_rows: how many rows to put in the test Tensor</span>

<span class="sd">    Raises:</span>
<span class="sd">     AssertionError: something isn't right</span>
<span class="sd">    """</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">generator_block</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

    <span class="c1"># Check the three parts</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">block</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">block</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">block</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span>

    <span class="c1"># Check the output shape</span>
    <span class="n">test_output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">test_rows</span><span class="p">,</span> <span class="n">in_features</span><span class="p">))</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">test_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">test_rows</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

    <span class="c1"># check the normalization</span>
    <span class="k">assert</span> <span class="mf">0.65</span> <span class="o">&gt;</span> <span class="n">test_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.55</span>
    <span class="k">return</span>

<span class="n">test_gen_block</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">test_gen_block</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb992f37">
<h4 id="orgb992f37">Building the Generator Class</h4>
<div class="outline-text-4" id="text-orgb992f37">
<p>Now that we have the block-builder we can define our Generator network. It's going to contain a sequence of blocks output by our block-building function and a final two layers that use the linear transformation again, but don't apply normalization and use a <a href="https://pytorch.org/docs/master/generated/torch.nn.Sigmoid.html">Sigmoid Function</a> instead of the ReLU. Each block will have an output double that of the previous one.</p>
<div class="figure">
<p><img alt="generator.png" src="generator.png"></p>
</div>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""Generator Class</span>

<span class="sd">    Args:</span>
<span class="sd">      input_dimension: the dimension of the noise vector</span>
<span class="sd">      image_dimension: the dimension of the images, fitted for the dataset used</span>
<span class="sd">        (MNIST images are 28 x 28 = 784 so that is the default)</span>
<span class="sd">      hidden_dimension: the initial hidden-layer dimension</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">image_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span>
                 <span class="n">hidden_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">generator_block</span><span class="p">(</span><span class="n">input_dimension</span><span class="p">,</span> <span class="n">hidden_dimension</span><span class="p">),</span>
            <span class="n">generator_block</span><span class="p">(</span><span class="n">hidden_dimension</span><span class="p">,</span> <span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="n">generator_block</span><span class="p">(</span><span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">generator_block</span><span class="p">(</span><span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">image_dimension</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">       Method for a forward pass of the generator</span>

<span class="sd">       Args:</span>
<span class="sd">        noise: a noise tensor with dimensions (n_samples, z_dim)</span>

<span class="sd">       Returns: </span>
<span class="sd">        generated images.</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8f9d1d7">
<h4 id="org8f9d1d7">Verify the Generator Class</h4>
<div class="outline-text-4" id="text-org8f9d1d7">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">im_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
                   <span class="n">num_test</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">"""Test the Generator Class</span>

<span class="sd">    Args:</span>
<span class="sd">     z_dim: the size of the input</span>
<span class="sd">     im_dim: the size of the image</span>
<span class="sd">     hidden_dim: the size of the initial hidden layer</span>

<span class="sd">    Raises:</span>
<span class="sd">     AssertionError: something is wrong</span>
<span class="sd">    """</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">im_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span><span class="o">.</span><span class="n">generator</span>

    <span class="c1"># Check there are six modules in the sequential part</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span> <span class="o">==</span> <span class="mi">6</span>
    <span class="n">test_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="n">test_output</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>

    <span class="c1"># Check that the output shape is correct</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">test_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">im_dim</span><span class="p">)</span>

    <span class="c1"># Chechk the output</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">test_output</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">"Make sure to use a sigmoid"</span>
    <span class="k">assert</span> <span class="n">test_output</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">"Don't use a block in your solution"</span>
    <span class="k">assert</span> <span class="mf">0.15</span> <span class="o">&gt;</span> <span class="n">test_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.05</span><span class="p">,</span> <span class="s2">"Don't use batchnorm here"</span>
    <span class="k">return</span>

<span class="n">test_generator</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">test_generator</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">24</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org30f3386">
<h3 id="org30f3386">Noise</h3>
<div class="outline-text-3" id="text-org30f3386">
<p>To be able to use the generator, we will need to be able to create noise vectors. The noise vector <code>z</code> has the important role of making sure the images generated from the same class don't all look the same â€“ think of it as a random seed. You will generate it randomly using PyTorch by sampling random numbers from the normal distribution. Since multiple images will be processed per pass, you will generate all the noise vectors at once.</p>
<p>Note that whenever you create a new tensor using torch.ones, torch.zeros, or <a href="https://pytorch.org/docs/master/generated/torch.randn.html">torch.randn</a>, you either need to create it on the target device, e.g. <code>torch.ones(3, 3, device=device)</code>, or move it onto the target device using <code>torch.ones(3, 3).to(device)</code>. You do not need to do this if you're creating a tensor by manipulating another tensor or by using a variation that defaults the device to the input, such as <code>torch.ones_like</code>. In general, use <code>torch.ones_like</code> and <code>torch.zeros_like</code> instead of <code>torch.ones</code> or <code>torch.zeros</code> where possible.</p>
<div class="highlight">
<pre><span></span><span class="n">get_noise</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org2c07608">
<h4 id="org2c07608">Verify the noise vector function</h4>
<div class="outline-text-4" id="text-org2c07608">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_get_noise</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">):</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">get_noise</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Make sure a normal distribution was used</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">noise</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">noise</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">0.01</span>
    <span class="k">assert</span> <span class="nb">str</span><span class="p">(</span><span class="n">noise</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">test_get_noise</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org6dd9fc1">
<h3 id="org6dd9fc1">The Discriminator</h3>
<div class="outline-text-3" id="text-org6dd9fc1">
<p>The second component that you need to construct is the discriminator. As with the generator component, you will start by creating a function that builds a neural network block for the discriminator.</p>
<p><b>Note: You use <a href="https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html">leaky ReLUs</a> to prevent the "dying ReLU" problem, which refers to the phenomenon where the parameters stop changing due to consistently negative values passed to a ReLU, which result in a zero gradient.</b></p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_discriminator_block</span><span class="p">(</span><span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                            <span class="n">negative_slope</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
    <span class="sd">"""Create the Discriminator block</span>

<span class="sd">    Args:</span>
<span class="sd">      input_dim: the dimension of the input vector, a scalar</span>
<span class="sd">      output_dim: the dimension of the output vector, a scalar</span>
<span class="sd">      negative_slope: angle for the negative slope</span>

<span class="sd">    Returns:</span>
<span class="sd">       a discriminator neural network layer, with a linear transformation </span>
<span class="sd">         followed by an nn.LeakyReLU activation with negative slope of 0.2 </span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orga27f2bd">
<h4 id="orga27f2bd">Verify the discriminator block function</h4>
<div class="outline-text-4" id="text-orga27f2bd">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_disc_block</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">num_test</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">get_discriminator_block</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

    <span class="c1"># Check there are two parts</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="n">test_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">in_features</span><span class="p">)</span>
    <span class="n">test_output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>

    <span class="c1"># Check that the shape is right</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">test_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

    <span class="c1"># Check that the LeakyReLU slope is about 0.2</span>
    <span class="k">assert</span> <span class="o">-</span><span class="n">test_output</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">/</span> <span class="n">test_output</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.1</span>
    <span class="k">assert</span> <span class="o">-</span><span class="n">test_output</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">/</span> <span class="n">test_output</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.3</span>
    <span class="k">assert</span> <span class="n">test_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.3</span>
    <span class="k">assert</span> <span class="n">test_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span>

<span class="n">test_disc_block</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">test_disc_block</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge5d47b4">
<h4 id="orge5d47b4">The Discriminator Class</h4>
<div class="outline-text-4" id="text-orge5d47b4">
<p>The discriminator class holds 2 values:</p>
<ul class="org-ul">
<li>The image dimension</li>
<li>The hidden dimension</li>
</ul>
<p>The discriminator will build a neural network with 4 layers. It will start with the image tensor and transform it until it returns a single number (1-dimension tensor) output. This output classifies whether an image is fake or real. Note that you do not need a sigmoid after the output layer since it is included in the loss function. Finally, to use your discrimator's neural network you are given a forward pass function that takes in an image tensor to be classified.</p>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""The Discriminator Class</span>

<span class="sd">    Args:</span>
<span class="sd">       im_dim: the dimension of the images, fitted for the dataset used, a scalar</span>
<span class="sd">           (MNIST images are 28x28 = 784 so that is your default)</span>
<span class="sd">       hidden_dim: the inner dimension, a scalar</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">get_discriminator_block</span><span class="p">(</span><span class="n">im_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">get_discriminator_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="n">get_discriminator_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""forward pass of the discriminator</span>

<span class="sd">       Args:</span>
<span class="sd">           image: a flattened image tensor with dimension (im_dim)</span>

<span class="sd">       Returns a 1-dimension tensor representing fake/real.</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">disc</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org9406fc8"></a>Verify the discriminator class<br>
<div class="outline-text-5" id="text-org9406fc8">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_discriminator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_test</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">disc</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span><span class="o">.</span><span class="n">disc</span>

    <span class="c1"># Check there are three parts</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">disc</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>

    <span class="c1"># Check the linear layer is correct</span>
    <span class="n">test_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="n">test_output</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">test_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Don't use a block</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">disc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">)</span>

<span class="n">test_discriminator</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">test_discriminator</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org68476b3">
<h3 id="org68476b3">Training</h3>
<div class="outline-text-3" id="text-org68476b3">
<p>First, you will set your parameters:</p>
<ul class="org-ul">
<li>criterion: the loss function (<a href="https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html?highlight=bcewithlogitsloss">BCEWithLogitsLoss</a>)</li>
<li>n_epochs: the number of times you iterate through the entire dataset when training</li>
<li>z_dim: the dimension of the noise vector</li>
<li>display_step: how often to display/visualize the images</li>
<li>batch_size: the number of images per forward/backward pass</li>
<li>lr: the learning rate</li>
<li>device: the device type, here using a GPU (which runs CUDA), not CPU</li>
</ul>
<p>Next, you will load the MNIST dataset as tensors using a dataloader.</p>
</div>
<div class="outline-4" id="outline-container-orgcd1b715">
<h4 id="orgcd1b715">Set your parameters</h4>
<div class="outline-text-4" id="text-orgcd1b715">
<div class="highlight">
<pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.00001</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org93096d5">
<h4 id="org93096d5">Load MNIST dataset as tensors</h4>
<div class="outline-text-4" id="text-org93096d5">
<div class="highlight">
<pre><span></span><span class="n">data_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/data/datasets/pytorch/"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_path</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<p>Now, you can initialize your generator, discriminator, and optimizers. Note that each optimizer only takes the parameters of one particular model, since we want each optimizer to optimize only one of the models.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">build_parts</span><span class="p">(</span><span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GANParts</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span>
    <span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">gen_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">discriminator</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
    <span class="n">disc_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">GANParts</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">gen_optimizer</span><span class="p">,</span> <span class="n">discriminator</span><span class="p">,</span> <span class="n">disc_optimizer</span><span class="p">)</span>

<span class="n">gen</span><span class="p">,</span> <span class="n">gen_opt</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">disc_opt</span> <span class="o">=</span> <span class="n">build_parts</span><span class="p">()</span>
</pre></div>
<p>This next bit is from <a href="https://stackoverflow.com/questions/48152674/how-to-check-if-pytorch-is-using-the-gpu">https://stackoverflow.com/questions/48152674/how-to-check-if-pytorch-is-using-the-gpu</a>.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">check_gpu</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
    <span class="n">current_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">current_device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="n">current_device</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Memory Usage:'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Allocated: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_allocated</span><span class="p">(</span><span class="n">current_device</span><span class="p">)</span><span class="o">/</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span>
          <span class="s2">" MB"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Cached:   </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_reserved</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> MB"</span><span class="p">)</span>
    <span class="k">return</span>

<span class="n">check_gpu</span><span class="p">()</span>
</pre></div>
<pre class="example">
0
1
NVIDIA GeForce GTX 1070 Ti
Memory Usage:
Allocated: 7.92138671875 MB
Cached:   22.0 MB
</pre>
<p>Before you train your GAN, you will need to create functions to calculate the discriminator's loss and the generator's loss. This is how the discriminator and generator will know how they are doing and improve themselves. Since the generator is needed when calculating the discriminator's loss, you will need to call .detach() on the generator result to ensure that only the discriminator is updated!</p>
<p>Remember that you have already defined a loss function earlier (<code>criterion</code>) and you are encouraged to use <a href="https://pytorch.org/docs/master/generated/torch.ones_like.html?highlight=ones_like#torch.ones_like"><code>torch.ones_like</code></a> and <a href="https://pytorch.org/docs/master/generated/torch.zeros_like.html?highlight=zeros_like#torch.zeros_like"><code>torch.zeros_like</code></a> instead of <code>torch.ones</code> or <code>torch.zeros</code>. If you use <code>torch.ones</code> or <code>torch.zeros</code>, you'll need to pass <code>device=device</code> to them.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">:</span> <span class="n">Generator</span><span class="p">,</span> <span class="n">disc</span><span class="p">:</span> <span class="n">Discriminator</span><span class="p">,</span>
                  <span class="n">criterion</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">,</span>
                  <span class="n">real</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                  <span class="n">num_images</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
                  <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Get the loss of the discriminator given inputs.</span>

<span class="sd">    Args:</span>
<span class="sd">       gen: the generator model, which returns an image given z-dimensional noise</span>
<span class="sd">       disc: the discriminator model, which returns a single-dimensional prediction of real/fake</span>
<span class="sd">       criterion: the loss function, which should be used to compare </span>
<span class="sd">              the discriminator's predictions to the ground truth reality of the images </span>
<span class="sd">              (e.g. fake = 0, real = 1)</span>
<span class="sd">       real: a batch of real images</span>
<span class="sd">       num_images: the number of images the generator should produce, </span>
<span class="sd">               which is also the length of the real images</span>
<span class="sd">       z_dim: the dimension of the noise vector, a scalar</span>
<span class="sd">       device: the device type</span>

<span class="sd">    Returns:</span>
<span class="sd">       disc_loss: a torch scalar loss value for the current batch</span>
<span class="sd">    """</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">fakes</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

    <span class="n">fake_prediction</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">fakes</span><span class="p">)</span>
    <span class="n">fake_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">fake_prediction</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">fake_prediction</span><span class="p">))</span>

    <span class="n">real_prediction</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>
    <span class="n">real_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">real_prediction</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">real_prediction</span><span class="p">))</span>
    <span class="n">disc_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">fake_loss</span> <span class="o">+</span> <span class="n">real_loss</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">disc_loss</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_disc_reasonable</span><span class="p">(</span><span class="n">num_images</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Don't use explicit casts to cuda - use the device argument</span>
    <span class="kn">import</span> <span class="nn">inspect</span><span class="o">,</span> <span class="nn">re</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getsource</span><span class="p">(</span><span class="n">get_disc_loss</span><span class="p">)</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">"to\(.cuda.\)"</span><span class="p">,</span> <span class="n">lines</span><span class="p">))</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\.cuda\(\)"</span><span class="p">,</span> <span class="n">lines</span><span class="p">))</span> <span class="ow">is</span> <span class="kc">None</span>

    <span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span> <span class="c1"># Multiply</span>
    <span class="n">real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="n">disc_loss</span> <span class="o">=</span> <span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">disc_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="n">gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span> <span class="c1"># Multiply</span>
    <span class="n">real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="n">gen</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="mi">10</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span> <span class="c1"># Multiply</span>
    <span class="n">real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="mi">5</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="n">gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
    <span class="n">disc</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
    <span class="n">disc_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">disc_loss</span> <span class="o">=</span> <span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">disc_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="mf">11.25</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">3.75</span><span class="p">))</span>
    <span class="k">return</span>

<span class="n">test_disc_reasonable</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span>
<span class="k">def</span> <span class="nf">test_disc_loss</span><span class="p">(</span><span class="n">max_tests</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">gen_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
    <span class="n">disc_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">real</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">cur_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>
        <span class="n">real</span> <span class="o">=</span> <span class="n">real</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1">### Update discriminator ###</span>
        <span class="c1"># Zero out the gradient before backpropagation</span>
        <span class="n">disc_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Calculate discriminator loss</span>
        <span class="n">disc_loss</span> <span class="o">=</span> <span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span><span class="n">disc_loss</span> <span class="o">-</span> <span class="mf">0.68</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">disc_loss</span>

        <span class="c1"># Update gradients</span>
        <span class="n">disc_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Check that they detached correctly</span>
        <span class="k">assert</span> <span class="n">gen</span><span class="o">.</span><span class="n">generator</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span>

        <span class="c1"># Update optimizer</span>
        <span class="n">old_weight</span> <span class="o">=</span> <span class="n">disc</span><span class="o">.</span><span class="n">disc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">disc_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="n">disc</span><span class="o">.</span><span class="n">disc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>

        <span class="c1"># Check that some discriminator weights changed</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">old_weight</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">))</span>
        <span class="n">num_steps</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">num_steps</span> <span class="o">&gt;=</span> <span class="n">max_tests</span><span class="p">:</span>
            <span class="k">break</span>

<span class="n">test_disc_loss</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org0482b62">
<h4 id="org0482b62">Generator Loss</h4>
<div class="outline-text-4" id="text-org0482b62">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_generator_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">:</span> <span class="n">Generator</span><span class="p">,</span>
                       <span class="n">disc</span><span class="p">:</span> <span class="n">Discriminator</span><span class="p">,</span>
                       <span class="n">criterion</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">,</span>
                       <span class="n">num_images</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                       <span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">"""Calculates the loss for the generator</span>

<span class="sd">    Args:</span>
<span class="sd">       gen: the generator model, which returns an image given z-dimensional noise</span>
<span class="sd">       disc: the discriminator model, which returns a single-dimensional prediction of real/fake</span>
<span class="sd">       criterion: the loss function, which should be used to compare </span>
<span class="sd">              the discriminator's predictions to the ground truth reality of the images </span>
<span class="sd">              (e.g. fake = 0, real = 1)</span>
<span class="sd">       num_images: the number of images the generator should produce, </span>
<span class="sd">               which is also the length of the real images</span>
<span class="sd">       z_dim: the dimension of the noise vector, a scalar</span>
<span class="sd">       device: the device type</span>
<span class="sd">    Returns:</span>
<span class="sd">       gen_loss: a torch scalar loss value for the current batch</span>
<span class="sd">    """</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">fakes</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
    <span class="n">fake_prediction</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">fakes</span><span class="p">)</span>
    <span class="n">gen_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">fake_prediction</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">fake_prediction</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">gen_loss</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_gen_reasonable</span><span class="p">(</span><span class="n">num_images</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Don't use explicit casts to cuda - use the device argument</span>
    <span class="kn">import</span> <span class="nn">inspect</span><span class="o">,</span> <span class="nn">re</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getsource</span><span class="p">(</span><span class="n">get_gen_loss</span><span class="p">)</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">"to\(.cuda.\)"</span><span class="p">,</span> <span class="n">lines</span><span class="p">))</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\.cuda\(\)"</span><span class="p">,</span> <span class="n">lines</span><span class="p">))</span> <span class="ow">is</span> <span class="kc">None</span>

    <span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span> <span class="c1"># Multiply</span>
    <span class="n">gen_loss_tensor</span> <span class="o">=</span> <span class="n">get_gen_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">gen_loss_tensor</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">)</span>
    <span class="c1">#Verify shape. Related to gen_noise parametrization</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">gen_loss_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>

    <span class="n">gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span> <span class="c1"># Multiply</span>
    <span class="n">real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">gen_loss_tensor</span> <span class="o">=</span> <span class="n">get_gen_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">gen_loss_tensor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">)</span>
    <span class="c1">#Verify shape. Related to gen_noise parametrization</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">gen_loss_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="k">return</span>
<span class="n">test_gen_reasonable</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_gen_loss</span><span class="p">(</span><span class="n">num_images</span><span class="p">):</span>
    <span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">gen_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
    <span class="n">disc_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

    <span class="n">gen_loss</span> <span class="o">=</span> <span class="n">get_generator_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="c1"># Check that the loss is reasonable</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">gen_loss</span> <span class="o">-</span> <span class="mf">0.7</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.1</span>
    <span class="n">gen_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">old_weight</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">generator</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">gen_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">new_weight</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">generator</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">old_weight</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">))</span>
<span class="n">test_gen_loss</span><span class="p">(</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5e49a93">
<h4 id="org5e49a93">All Together</h4>
<div class="outline-text-4" id="text-org5e49a93">
<p>For each epoch, you will process the entire dataset in batches. For every batch, you will need to update the discriminator and generator using their loss. Batches are sets of images that will be predicted on before the loss functions are calculated (instead of calculating the loss function after each image). Note that you may see a loss to be greater than 1, this is okay since binary cross entropy loss can be any positive number for a sufficiently confident wrong guess.</p>
<p>Itâ€™s also often the case that the discriminator will outperform the generator, especially at the start, because its job is easier. It's important that neither one gets too good (that is, near-perfect accuracy), which would cause the entire model to stop learning. Balancing the two models is actually remarkably hard to do in a standard GAN and something you will see more of in later lectures and assignments.</p>
<p>After you've submitted a working version with the original architecture, feel free to play around with the architecture if you want to see how different architectural choices can lead to better or worse GANs. For example, consider changing the size of the hidden dimension, or making the networks shallower or deeper by changing the number of layers.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">gen</span><span class="p">:</span> <span class="n">Generator</span><span class="o">=</span><span class="n">gen</span><span class="p">,</span>
          <span class="n">gen_opt</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="o">=</span><span class="n">gen_opt</span><span class="p">,</span>
          <span class="n">disc</span><span class="p">:</span> <span class="n">Discriminator</span><span class="o">=</span><span class="n">disc</span><span class="p">,</span>
          <span class="n">disc_opt</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="o">=</span><span class="n">disc_opt</span><span class="p">,</span>
          <span class="n">start_step</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
          <span class="n">best_loss</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">INFINITY</span><span class="p">,</span>
          <span class="n">test_the_generator</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">display_step</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">4500</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PlotData</span><span class="p">:</span>
    <span class="sd">"""Train a batch</span>

<span class="sd">    Args:</span>
<span class="sd">     epochs: number of epochs to train</span>
<span class="sd">     gen: the Generator object</span>
<span class="sd">     gen_opt: optimizer for the generator</span>
<span class="sd">     disc: the Discriminator object</span>
<span class="sd">     disc_opt: the optimizer for the discriminator</span>
<span class="sd">     start_step: where we are in the training if this is called more than once</span>
<span class="sd">     best_loss: what the best loss for the generator has been so far</span>
<span class="sd">     test_the_generator: whether to double-check the generator is changing</span>
<span class="sd">     display_step: how often to emit messages</span>
<span class="sd">    """</span>
    <span class="n">current_step</span> <span class="o">=</span> <span class="n">start_step</span>
    <span class="n">mean_generator_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">mean_discriminator_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">generator_loss</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">error</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">generator_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">discriminator_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>

            <span class="c1"># Dataloader returns the batches</span>
            <span class="k">for</span> <span class="n">real</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
                <span class="n">cur_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>

                <span class="c1"># Flatten the batch of real images from the dataset</span>
                <span class="n">real</span> <span class="o">=</span> <span class="n">real</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="c1">### Update discriminator ###</span>
                <span class="c1"># Zero out the gradients before backpropagation</span>
                <span class="n">disc_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># Calculate discriminator loss</span>
                <span class="n">disc_loss</span> <span class="o">=</span> <span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span>
                                          <span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

                <span class="c1"># Update gradients</span>
                <span class="n">disc_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                <span class="c1"># Update optimizer</span>
                <span class="n">disc_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># For testing purposes, to keep track of the generator weights</span>
                <span class="k">if</span> <span class="n">test_generator</span><span class="p">:</span>
                    <span class="n">old_generator_weights</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">generator</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

                <span class="c1">### Update generator ###</span>
                <span class="n">gen_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">generator_loss</span> <span class="o">=</span> <span class="n">get_generator_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
                <span class="n">generator_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">gen_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># check if it's the best so far</span>
                <span class="k">if</span> <span class="n">generator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
                    <span class="n">best_loss</span> <span class="o">=</span> <span class="n">generator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Saving model with best loss so far (</span><span class="si">{</span><span class="n">best_loss</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>

                    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">MODEL_PATH</span><span class="p">)</span>
                <span class="c1"># For testing purposes, to check that your code changes the generator weights</span>
                <span class="k">if</span> <span class="n">test_generator</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="k">assert</span> <span class="n">lr</span> <span class="o">&gt;</span> <span class="mf">0.0000002</span> <span class="ow">or</span> <span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">generator</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.0005</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
                        <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">generator</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="o">!=</span> <span class="n">old_generator_weights</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="n">error</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">"Runtime tests have failed"</span><span class="p">)</span>

                <span class="c1"># Keep track of the average discriminator loss</span>
                <span class="n">mean_discriminator_loss</span> <span class="o">+=</span> <span class="n">disc_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">display_step</span>

                <span class="c1"># Keep track of the average generator loss</span>
                <span class="n">mean_generator_loss</span> <span class="o">+=</span> <span class="n">generator_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">display_step</span>

                <span class="k">if</span> <span class="n">current_step</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">current_step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, step </span><span class="si">{</span><span class="n">current_step</span><span class="si">}</span><span class="s2">: Generator loss:"</span>
                            <span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">mean_generator_loss</span><span class="si">}</span><span class="s2">, discriminator loss:"</span>
                            <span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">mean_discriminator_loss</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                    <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_step</span><span class="p">)</span>
                    <span class="n">generator_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_generator_loss</span><span class="p">)</span>
                    <span class="n">discriminator_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_discriminator_loss</span><span class="p">)</span>

                    <span class="n">mean_generator_loss</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">mean_discriminator_loss</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">current_step</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">PlotData</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span> <span class="n">generator_losses</span><span class="o">=</span><span class="n">generator_losses</span><span class="p">,</span>
                    <span class="n">discriminator_losses</span><span class="o">=</span><span class="n">discriminator_losses</span><span class="p">,</span> <span class="n">best_loss</span><span class="o">=</span><span class="n">best_loss</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
<pre class="example">
Started: 2021-12-12 21:18:06.595695
Saving model with best loss so far (3.82)
Saving model with best loss so far (3.77)
Saving model with best loss so far (3.75)
Saving model with best loss so far (3.58)
Saving model with best loss so far (3.54)
Saving model with best loss so far (3.50)
Saving model with best loss so far (3.25)
Epoch 9, step 4500: Generator loss: 4.100310390790306, discriminator loss: 0.053616619475599675
Ended: 2021-12-12 21:19:19.963121
Elapsed: 0:01:13.367426
PlotData(steps=[4500], generator_losses=[4.100310390790306], discriminator_losses=[0.053616619475599675], best_loss=3.2485642433166504)
</pre>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">run_batch</span><span class="p">(</span><span class="n">parts</span><span class="p">:</span> <span class="n">GANParts</span><span class="p">,</span> <span class="n">plot_data</span><span class="p">:</span> <span class="n">PlotData</span><span class="p">,</span>
              <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PlotData</span><span class="p">:</span>
    <span class="sd">"""Run a smaller batch of epochs</span>

<span class="sd">    Args:</span>
<span class="sd">     parts: the GAN parts</span>
<span class="sd">     plot_data: the accumulated output of the training</span>

<span class="sd">    Returns:</span>
<span class="sd">     updated plot_data</span>
<span class="sd">    """</span>
    <span class="n">next_step</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">plot_data</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">plot_data</span><span class="o">.</span><span class="n">steps</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">best_loss</span> <span class="o">=</span> <span class="n">plot_data</span><span class="o">.</span><span class="n">best_loss</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">gen</span><span class="o">=</span><span class="n">parts</span><span class="o">.</span><span class="n">generator</span><span class="p">,</span>
                   <span class="n">gen_opt</span><span class="o">=</span><span class="n">parts</span><span class="o">.</span><span class="n">generator_optimizer</span><span class="p">,</span>
                   <span class="n">disc</span><span class="o">=</span><span class="n">parts</span><span class="o">.</span><span class="n">discriminator</span><span class="p">,</span>
                   <span class="n">disc_opt</span><span class="o">=</span><span class="n">parts</span><span class="o">.</span><span class="n">discriminator_optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                   <span class="n">start_step</span><span class="o">=</span><span class="n">next_step</span><span class="p">,</span> <span class="n">best_loss</span><span class="o">=</span><span class="n">best_loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">PlotData</span><span class="p">(</span>
        <span class="n">steps</span><span class="o">=</span><span class="n">plot_data</span><span class="o">.</span><span class="n">steps</span> <span class="o">+</span> <span class="n">output</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span>
        <span class="n">generator_losses</span><span class="o">=</span><span class="n">plot_data</span><span class="o">.</span><span class="n">generator_losses</span> <span class="o">+</span> <span class="n">output</span><span class="o">.</span><span class="n">generator_losses</span><span class="p">,</span>
        <span class="n">discriminator_losses</span><span class="o">=</span><span class="p">(</span><span class="n">plot_data</span><span class="o">.</span><span class="n">discriminator_losses</span> <span class="o">+</span>
                              <span class="n">output</span><span class="o">.</span><span class="n">discriminator_losses</span><span class="p">),</span> <span class="n">best_loss</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">best_loss</span><span class="p">)</span>
</pre></div>
<p>At about one epoch a minute, this should take about an hour and forty minutes or so.</p>
<div class="highlight">
<pre><span></span><span class="n">parts</span> <span class="o">=</span> <span class="n">build_parts</span><span class="p">()</span>
<span class="n">plot_data</span> <span class="o">=</span> <span class="n">run_batch</span><span class="p">(</span><span class="n">parts</span><span class="p">,</span> <span class="n">PlotData</span><span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="n">best_loss</span><span class="o">=</span><span class="n">INFINITY</span><span class="p">))</span>
</pre></div>
<pre class="example">
Started: 2021-12-12 22:41:21.823164
Saving model with best loss so far (0.68)
Epoch 9, step 4500: Generator loss: 2.0671158762905333, discriminator loss: 0.2002916043450438
Epoch 19, step 9000: Generator loss: 3.894586259894906, discriminator loss: 0.07030286101831354
Epoch 28, step 13500: Generator loss: 4.128244651317588, discriminator loss: 0.07312827965741342
Epoch 38, step 18000: Generator loss: 3.679966155105171, discriminator loss: 0.11400978071076953
Epoch 47, step 22500: Generator loss: 3.396804347621069, discriminator loss: 0.1500528004517162
Epoch 57, step 27000: Generator loss: 3.1040636014938245, discriminator loss: 0.17772292008996066
Epoch 67, step 31500: Generator loss: 2.8721981742117144, discriminator loss: 0.20018046746320184
Epoch 76, step 36000: Generator loss: 2.6418062130610167, discriminator loss: 0.22749259825216356
Epoch 86, step 40500: Generator loss: 2.5520630269580473, discriminator loss: 0.2384359383367829
Epoch 95, step 45000: Generator loss: 2.2842552210754827, discriminator loss: 0.2856089066366352
Ended: 2021-12-12 22:53:26.813378
Elapsed: 0:12:04.990214
</pre>
<p>Twelve minutesâ€¦ something's wrong with my math (or my code).</p>
<div class="highlight">
<pre><span></span><span class="n">plot_data</span> <span class="o">=</span> <span class="n">run_batch</span><span class="p">(</span><span class="n">parts</span><span class="p">,</span> <span class="n">plot_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2021-12-12 22:56:24.985796
Epoch 9, step 49500: Generator loss: 1.9961646406915445, discriminator loss: 0.3290849660535635
Epoch 19, step 54000: Generator loss: 1.8578781396812813, discriminator loss: 0.352255903386407
Epoch 28, step 58500: Generator loss: 1.7970310585498779, discriminator loss: 0.35997216095195933
Epoch 38, step 63000: Generator loss: 1.790595402267244, discriminator loss: 0.35704792838626415
Epoch 47, step 67500: Generator loss: 1.6337452937761876, discriminator loss: 0.399976011382207
Epoch 57, step 72000: Generator loss: 1.553067971309023, discriminator loss: 0.4149618665973359
Epoch 67, step 76500: Generator loss: 1.530716036346228, discriminator loss: 0.41230284125937433
Epoch 76, step 81000: Generator loss: 1.4763377503554027, discriminator loss: 0.42583107221126515
Epoch 86, step 85500: Generator loss: 1.4468076727655206, discriminator loss: 0.43238778846131376
Epoch 95, step 90000: Generator loss: 1.341741836388908, discriminator loss: 0.4629372137056456
Epoch 105, step 94500: Generator loss: 1.3321984058486116, discriminator loss: 0.4620412641101409
Epoch 115, step 99000: Generator loss: 1.2581868343618232, discriminator loss: 0.48384387395116984
Epoch 124, step 103500: Generator loss: 1.2193222048944967, discriminator loss: 0.4943520678679146
Epoch 134, step 108000: Generator loss: 1.210901861535182, discriminator loss: 0.4949321229921447
Epoch 143, step 112500: Generator loss: 1.1491395987007338, discriminator loss: 0.5172655161817865
Epoch 153, step 117000: Generator loss: 1.1057299662033748, discriminator loss: 0.5293599960472835
Epoch 163, step 121500: Generator loss: 1.0677826208141108, discriminator loss: 0.5450594869587152
Epoch 172, step 126000: Generator loss: 1.0314588887823974, discriminator loss: 0.5558468225730787
Epoch 182, step 130500: Generator loss: 0.988256526258255, discriminator loss: 0.5727653868463289
Epoch 191, step 135000: Generator loss: 0.9866233132415357, discriminator loss: 0.5702601793143482
Epoch 201, step 139500: Generator loss: 0.9552508686383555, discriminator loss: 0.5773511084649297
Epoch 211, step 144000: Generator loss: 0.9940739690330269, discriminator loss: 0.5602315128578074
Epoch 220, step 148500: Generator loss: 0.957331194546487, discriminator loss: 0.5762877901130254
Epoch 230, step 153000: Generator loss: 0.940105734388034, discriminator loss: 0.5758193738725437
Epoch 239, step 157500: Generator loss: 0.9115204359822786, discriminator loss: 0.5869797533286937
Epoch 249, step 162000: Generator loss: 0.9108314050965834, discriminator loss: 0.5894923475186025
Epoch 259, step 166500: Generator loss: 0.8571861512131169, discriminator loss: 0.6157774040169194
Epoch 268, step 171000: Generator loss: 0.9255197024875222, discriminator loss: 0.5831143510672784
Epoch 278, step 175500: Generator loss: 0.9227028174797725, discriminator loss: 0.5861976487901457
Epoch 287, step 180000: Generator loss: 0.9116632200082172, discriminator loss: 0.5921973378062267
Epoch 297, step 184500: Generator loss: 0.896604921857515, discriminator loss: 0.5983437673317067
Epoch 307, step 189000: Generator loss: 0.8876715467108619, discriminator loss: 0.5988295680549406
Epoch 316, step 193500: Generator loss: 0.8981850113338913, discriminator loss: 0.596900998810927
Epoch 326, step 198000: Generator loss: 0.9132995079225976, discriminator loss: 0.5932699956099183
Saving model with best loss so far (0.67)
Saving model with best loss so far (0.66)
Saving model with best loss so far (0.66)
Saving model with best loss so far (0.65)
Saving model with best loss so far (0.64)
Saving model with best loss so far (0.63)
Saving model with best loss so far (0.62)
Epoch 335, step 202500: Generator loss: 0.8218274900118518, discriminator loss: 0.6400571531719623
Epoch 345, step 207000: Generator loss: 0.9687661434412017, discriminator loss: 0.5792819880843164
Saving model with best loss so far (0.62)
Saving model with best loss so far (0.61)
Saving model with best loss so far (0.59)
Saving model with best loss so far (0.59)
Saving model with best loss so far (0.58)
Saving model with best loss so far (0.58)
Saving model with best loss so far (0.57)
Saving model with best loss so far (0.56)
Saving model with best loss so far (0.56)
Saving model with best loss so far (0.53)
Saving model with best loss so far (0.51)
Saving model with best loss so far (0.50)
Epoch 355, step 211500: Generator loss: 0.7063771485355128, discriminator loss: 0.7654304582807753
Epoch 364, step 216000: Generator loss: 0.8059421989785318, discriminator loss: 0.6302714381350409
Epoch 374, step 220500: Generator loss: 0.9056880848937555, discriminator loss: 0.5996440589427954
Epoch 383, step 225000: Generator loss: 0.9476164460844481, discriminator loss: 0.5872065601017749
Epoch 393, step 229500: Generator loss: 0.8700628989405085, discriminator loss: 0.614429159349864
Epoch 402, step 234000: Generator loss: 0.9316757869985379, discriminator loss: 0.5935855323341168
Epoch 412, step 238500: Generator loss: 0.9884794838296045, discriminator loss: 0.5769219878051017
Epoch 422, step 243000: Generator loss: 0.9787677707009845, discriminator loss: 0.5881667502986057
Epoch 431, step 247500: Generator loss: 0.9812438432375566, discriminator loss: 0.5934927140739243
Epoch 441, step 252000: Generator loss: 0.9866997564368781, discriminator loss: 0.5696533908512852
Epoch 450, step 256500: Generator loss: 1.0139115802447014, discriminator loss: 0.5784266778760502
Epoch 460, step 261000: Generator loss: 0.9905964203940505, discriminator loss: 0.5876510691973909
Epoch 470, step 265500: Generator loss: 0.9866478079954776, discriminator loss: 0.5789911089009697
Epoch 479, step 270000: Generator loss: 0.9699252954191648, discriminator loss: 0.593749921997389
Epoch 489, step 274500: Generator loss: 0.9484661724964777, discriminator loss: 0.5820076752834854
Epoch 498, step 279000: Generator loss: 0.9874062088992859, discriminator loss: 0.5781058085229654
Ended: 2021-12-12 23:56:45.487848
Elapsed: 1:00:20.502052
</pre>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="n">plot</span><span class="p">,</span> <span class="n">element</span><span class="p">):</span>
    <span class="n">figure</span> <span class="o">=</span> <span class="n">plot</span><span class="o">.</span><span class="n">state</span>
    <span class="n">figure</span><span class="p">[</span><span class="s2">"layout"</span><span class="p">][</span><span class="s2">"sizing_mode"</span><span class="p">]</span> <span class="o">=</span> <span class="n">Plot</span><span class="o">.</span><span class="n">sizing_mode</span>
    <span class="k">return</span>

<span class="k">def</span> <span class="nf">plot_losses</span><span class="p">(</span><span class="n">plot_data</span><span class="p">:</span> <span class="n">PlotData</span><span class="p">,</span> <span class="n">file_name</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"losses"</span><span class="p">,</span>
                <span class="n">title</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"Training Loss"</span><span class="p">):</span>
    <span class="sd">"""Plot the losses in Holoviews</span>

<span class="sd">    Args:</span>
<span class="sd">     plot_data: namedtuple with the losses over time</span>
<span class="sd">     file_name: name to save the plot (without extension)</span>
<span class="sd">     title: title for the plot</span>
<span class="sd">    """</span>
    <span class="n">plotting</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
        <span class="s2">"Step"</span><span class="p">:</span> <span class="n">plot_data</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span>
        <span class="s2">"Generator Loss"</span><span class="p">:</span> <span class="n">plot_data</span><span class="o">.</span><span class="n">generator_losses</span><span class="p">,</span>
        <span class="s2">"Discriminator Loss"</span><span class="p">:</span> <span class="n">plot_data</span><span class="o">.</span><span class="n">discriminator_losses</span>
    <span class="p">})</span>

    <span class="n">gen_plot</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Step"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Generator Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span>
    <span class="n">disc_plot</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Step"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Discriminator Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">red</span><span class="p">)</span>

    <span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">gen_plot</span> <span class="o">*</span> <span class="n">disc_plot</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
                                       <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
                                       <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                       <span class="n">ylabel</span><span class="o">=</span><span class="s2">"Loss"</span><span class="p">,</span>
                                       <span class="n">hooks</span><span class="o">=</span><span class="p">[</span><span class="n">hook</span><span class="p">],</span>
                                       <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">fontscale</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="n">file_name</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">plot_losses</span><span class="p">(</span><span class="n">plot_data</span><span class="p">)</span>
</pre></div>
<object data="losses.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<div class="highlight">
<pre><span></span><span class="n">plot_data</span> <span class="o">=</span> <span class="n">run_batch</span><span class="p">(</span><span class="n">parts</span><span class="p">,</span> <span class="n">plot_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">plot_losses</span><span class="p">(</span><span class="n">plot_data</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"losses_2"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Training Loss 2"</span><span class="p">)</span>
</pre></div>
<object data="losses_2.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object></div>
</div>
</div>
<div class="outline-3" id="outline-container-org24d4dcf">
<h3 id="org24d4dcf">Looking at the Final model.</h3>
<div class="outline-text-3" id="text-org24d4dcf">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">plot_image</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                <span class="n">title</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                <span class="n">num_images</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
                <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span>
                <span class="n">folder</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"files/posts/gans/mnist-gan/"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">"""Plot the image and save it</span>

<span class="sd">    Args:</span>
<span class="sd">     image: the tensor with the image to plot</span>
<span class="sd">     filename: name for the final image file</span>
<span class="sd">     title: title to put on top of the image</span>
<span class="sd">     num_images: how many images to put in the composite image</span>
<span class="sd">     size: the size for the image</span>
<span class="sd">     folder: sub-folder to save the file in</span>
<span class="sd">    """</span>
    <span class="n">unflattened_image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">size</span><span class="p">)</span>
    <span class="n">image_grid</span> <span class="o">=</span> <span class="n">make_grid</span><span class="p">(</span><span class="n">unflattened_image</span><span class="p">[:</span><span class="n">num_images</span><span class="p">],</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image_grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>

    <span class="n">pyplot</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelbottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                       <span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelleft</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">folder</span> <span class="o">+</span> <span class="n">filename</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[[file:</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">]]"</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">fake_noise</span> <span class="o">=</span> <span class="n">get_noise</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">parts</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">MODEL_PATH</span><span class="p">))</span>
<span class="n">fake</span> <span class="o">=</span> <span class="n">parts</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">fake_noise</span><span class="p">)</span>
<span class="n">plot_image</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">fake</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">"fake_digits.png"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Fake Digits"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="fake_digits.png" src="fake_digits.png"></p>
</div>
<p>It's interesting that there's that crossover point where the generator's loss dips below the discriminator's and then they diverge again and the generator seems to stop improving. The digits for the best model do look passable as human-written digits, in most cases (depending on the human it might be in all cases).</p>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/gans/" rel="tag">gans</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../../nlp/neural-machine-translation-helper-functions/" rel="prev" title="Neural Machine Translation: Helper Functions">Previous post</a></li>
<li class="next"><a href="../../pytorch/pytorch-linear-regression/" rel="next" title="PyTorch Linear Regression">Next post</a></li>
</ul>
</nav>
</aside>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script></article>
<!--End of body content-->
<footer id="footer"><a href="https://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://licensebuttons.net/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:cloisteredmonkey.jmark@slmail.me">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
