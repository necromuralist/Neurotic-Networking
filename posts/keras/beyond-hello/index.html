<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content='A follow-up to the Keras "hello world".' name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Beyond Hello | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/keras/beyond-hello/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../hello-there/" rel="prev" title="Hello There" type="text/html">
<link href="../handwriting-recognition-exercise/" rel="next" title="Handwriting Recognition Exercise" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Beyond Hello" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/keras/beyond-hello/" property="og:url">
<meta content='A follow-up to the Keras "hello world".' property="og:description">
<meta content="article" property="og:type">
<meta content="2019-06-27T11:52:14-07:00" property="article:published_time">
<meta content="deep learning" property="article:tag">
<meta content="keras" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Beyond Hello</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2019-06-27T11:52:14-07:00" itemprop="datePublished" title="2019-06-27 11:52">2019-06-27 11:52</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orga745676">Beginning</a>
<ul>
<li><a href="#org2192711">Imports</a></li>
<li><a href="#org879cc4e">The Timer</a></li>
<li><a href="#orgd0d0889">The Plotting</a></li>
<li><a href="#org064d2ef">The Data Set</a></li>
</ul>
</li>
<li><a href="#orgc595dfd">Middle</a>
<ul>
<li><a href="#org27db507">Looking At The dataset</a></li>
<li><a href="#orgedf77b1">The Example</a></li>
<li><a href="#org3cd1df3">Exercises</a></li>
</ul>
</li>
<li><a href="#org72c22e5">End</a>
<ul>
<li><a href="#org53b8906">Source</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orga745676">
<h2 id="orga745676">Beginning</h2>
<div class="outline-text-2" id="text-orga745676">
<p>This is going to use <a href="https://keras.io/">keras</a> (and <a href="https://www.tensorflow.org/">tensorflow</a>) to learn to categorize images in the <a href="https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/">Fashion MNIST</a> dataset.</p>
</div>
<div class="outline-3" id="outline-container-org2192711">
<h3 id="org2192711">Imports</h3>
<div class="outline-text-3" id="text-org2192711"></div>
<div class="outline-4" id="outline-container-org972fa8c">
<h4 id="org972fa8c">Python</h4>
<div class="outline-text-4" id="text-org972fa8c">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">import</span> <span class="nn">random</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgdb6f956">
<h4 id="orgdb6f956">PyPi</h4>
<div class="outline-text-4" id="text-orgdb6f956">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>
<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf2f0c6b">
<h4 id="orgf2f0c6b">My Stuff</h4>
<div class="outline-text-4" id="text-orgf2f0c6b">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae.visualization.embed</span> <span class="kn">import</span> <span class="n">EmbedHoloview</span>
<span class="kn">from</span> <span class="nn">graeae.timers</span> <span class="kn">import</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org879cc4e">
<h3 id="org879cc4e">The Timer</h3>
<div class="outline-text-3" id="text-org879cc4e">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgd0d0889">
<h3 id="orgd0d0889">The Plotting</h3>
<div class="outline-text-3" id="text-orgd0d0889">
<div class="highlight">
<pre><span></span><span class="n">embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloview</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="s2">"../../files/posts/keras/beyond-hello/"</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">size</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">holoviews</span><span class="o">.</span><span class="n">extension</span><span class="p">(</span><span class="s2">"bokeh"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org064d2ef">
<h3 id="org064d2ef">The Data Set</h3>
<div class="outline-text-3" id="text-org064d2ef">
<p>Keras includes the fashion mnist dataset and can be retrieved using the <a href="https://keras.io/datasets/#fashion-mnist-database-of-fashion-articles">datasets.fashion_mnist</a> property.</p>
<div class="highlight">
<pre><span></span><span class="p">(</span><span class="n">training_images</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>
<p>Unfortunately the function doesn't let you pass in the path to where you're going to store the files (it's stored in <code>~/.keras/datasets/fashion-mnist/</code>).</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgc595dfd">
<h2 id="orgc595dfd">Middle</h2>
<div class="outline-text-2" id="text-orgc595dfd"></div>
<div class="outline-3" id="outline-container-org27db507">
<h3 id="org27db507">Looking At The dataset</h3>
<div class="outline-text-3" id="text-org27db507"></div>
<div class="outline-4" id="outline-container-org664343b">
<h4 id="org664343b">The Labels</h4>
<div class="outline-text-4" id="text-org664343b">
<p>There are 10 categories of images encoded as integers in the label sets. The keras site lists them as these:</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Label</th>
<th class="org-left" scope="col">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-left">T-Shirt/Top</td>
</tr>
<tr>
<td class="org-right">1</td>
<td class="org-left">Trouser</td>
</tr>
<tr>
<td class="org-right">2</td>
<td class="org-left">Pullover</td>
</tr>
<tr>
<td class="org-right">3</td>
<td class="org-left">Dress</td>
</tr>
<tr>
<td class="org-right">4</td>
<td class="org-left">Coat</td>
</tr>
<tr>
<td class="org-right">5</td>
<td class="org-left">Sandal</td>
</tr>
<tr>
<td class="org-right">6</td>
<td class="org-left">Shirt</td>
</tr>
<tr>
<td class="org-right">7</td>
<td class="org-left">Sneaker</td>
</tr>
<tr>
<td class="org-right">8</td>
<td class="org-left">Bag</td>
</tr>
<tr>
<td class="org-right">9</td>
<td class="org-left">Ankle Boot</td>
</tr>
</tbody>
</table>
<p>To make it easier to interpret later on I'll make a secret decoder ring.</p>
<div class="highlight">
<pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s2">"T-Shirt/Top"</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s2">"Trouser"</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s2">"Pullover"</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s2">"Dress"</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">:</span> <span class="s2">"Coat"</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="s2">"Sandal"</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="s2">"Shirt"</span><span class="p">,</span>
    <span class="mi">7</span> <span class="p">:</span> <span class="s2">"Sneaker"</span><span class="p">,</span>
    <span class="mi">8</span><span class="p">:</span> <span class="s2">"Bag"</span><span class="p">,</span>
    <span class="mi">9</span> <span class="p">:</span> <span class="s2">"Ankle Boot"</span>
    <span class="p">}</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org9db9103">
<h4 id="org9db9103">The Number Of Images</h4>
<div class="outline-text-4" id="text-org9db9103">
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">training_images</span><span class="p">))</span>
<span class="n">rows</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">training_images</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"rows: </span><span class="si">{</span><span class="n">rows</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> image: </span><span class="si">{</span><span class="n">width</span><span class="si">}</span><span class="s2"> x </span><span class="si">{</span><span class="n">height</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">rows</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">testing_images</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"rows: </span><span class="si">{</span><span class="n">rows</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> image: </span><span class="si">{</span><span class="n">width</span><span class="si">}</span><span class="s2"> x </span><span class="si">{</span><span class="n">height</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
&lt;class 'numpy.ndarray'&gt;
rows: 60,000 image: 28 x 28
rows: 10,000 image: 28 x 28
</pre>
<p>We have 60,000 grayscale 28 by 28 pixel images to use for training (it would be 28 x 28 x 3 if the images were RGB) and 10,000 grayscale 28 by 28 pixel images to use for testing.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org659c094">
<h4 id="org659c094">A Sample Image</h4>
<div class="outline-text-4" id="text-org659c094">
<div class="highlight">
<pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_images</span><span class="p">))</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">training_images</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span>
    <span class="n">image</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="s2">"hover"</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Label </span><span class="si">{</span><span class="n">training_labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">training_labels</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span><span class="si">}</span><span class="s2">)"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"sample_image"</span><span class="p">)()</span>
</pre></div>
<object data="sample_image.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>Although it looks like it's a color image that's because holoviews adds artificial coloring to it. If you hover over the images the <code>x</code> and <code>y</code> values are the pixel coordinates and the <code>z</code> values are the grayscale values (so if you hover over black it should be 0, and if you hover over a white pixel it should be 255).</p>
</div>
</div>
<div class="outline-4" id="outline-container-org66db320">
<h4 id="org66db320">Normalizing The Data</h4>
<div class="outline-text-4" id="text-org66db320">
<p>Since the pixel values are from 0 (black) to 255 (white) we need to normalize them to values from 0 to 1 to work with a neural network.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"minimum value: </span><span class="si">{</span><span class="n">training_images</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2"> maximum value: </span><span class="si">{</span><span class="n">training_images</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">training_images_normalized</span> <span class="o">=</span> <span class="n">training_images</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">testing_images_normalized</span> <span class="o">=</span> <span class="n">testing_images</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"minimum value: </span><span class="si">{</span><span class="n">training_images_normalized</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2"> maximum value: </span><span class="si">{</span><span class="n">training_images_normalized</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
minimum value: 0 maximum value: 255
minimum value: 0.0 maximum value: 1.0
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgedf77b1">
<h3 id="orgedf77b1">The Example</h3>
<div class="outline-text-3" id="text-orgedf77b1">
<p>This is a worked example given in the original notebook.</p>
</div>
<div class="outline-4" id="outline-container-orged9dbdf">
<h4 id="orged9dbdf">Define The Model</h4>
<div class="outline-text-4" id="text-orged9dbdf">
<p>Once again the network will be a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/sequential">Sequential</a> one - a linear stack of layers, and there will be three layers, a <a href="https://www.tensorflow.org/api_docs/python/tf/layers/flatten">Flatten</a> layer to flatten our image into a vector with 784 cells (instead of a 28 x 28 matrix), followed by two <a href="https://www.tensorflow.org/api_docs/python/tf/layers/dense">dense</a>, or fully-connected, layers.</p>
<p>Each of the dense layers will get an activation function. The first dense layer (the hidden layer) gets a <a href="//www.tensorflow.org/api_docs/python/tf/nn/relu">ReLU</a> (<a href="//www.wikiwand.com/en/rectifier_(neural_networks)">Rectified Linear Unit</a>) function which makes it non-linear by returning the input only if it is greater than 0, otherwise it returns 0 (so it filters out negative numbers), and the second dense layer gets a <a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax">softmax</a> function to identify the biggest value (and thus our most likely label for the input).</p>
<div class="highlight">
<pre><span></span> <span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
 <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
 <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>
 <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">))</span>
</pre></div>
<p>There are 10 labels to predict so the last layer has 10 neurons.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgbccbf33">
<h4 id="orgbccbf33">Compile The Model</h4>
<div class="outline-text-4" id="text-orgbccbf33">
<p>This time we're going to compile the model using the <a href="https://www.tensorflow.org/api_docs/python/tf/train/adamoptimizer">adam optimizer</a>. confusingly, there's two of them in tensorflow, the "regular" one, and a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/adam">keras</a> version. we'll use the non-keras version. The loss, however, is the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparsecategoricalcrossentropy">keras version</a> as is the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/accuracy">accuracy</a>, which is just the number correct divided by the total count.</p>
<div class="highlight">
<pre><span></span> <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s2">"adam"</span><span class="p">,</span>
               <span class="n">loss</span> <span class="o">=</span> <span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span>
               <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
</pre></div>
<p>And now we fit it.</p>
<div class="highlight">
<pre><span></span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_images_normalized</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgb890bb9">
Epoch 1/5
60000/60000 - 2s - loss: 0.5015 - acc: 0.8242
Epoch 2/5
60000/60000 - 2s - loss: 0.3796 - acc: 0.8635
Epoch 3/5
60000/60000 - 2s - loss: 0.3420 - acc: 0.8754
Epoch 4/5
60000/60000 - 2s - loss: 0.3176 - acc: 0.8830
Epoch 5/5
60000/60000 - 2s - loss: 0.2975 - acc: 0.8908
</pre>
<p>At the end of training the model is about 89% accurate.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgcde11ee">
<h4 id="orgcde11ee">Check The Model Against The Test-Data</h4>
<div class="outline-text-4" id="text-orgcde11ee">
<p>The sequential model's <a href="https://www.tensorflow.org/api_docs/python/tf/keras/sequential#evaluate">evaluate</a> method will let us test it against the test set.</p>
<div class="highlight">
<pre><span></span> <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> 
                                 <span class="n">testing_labels</span><span class="p">,</span> 
                                 <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
 <span class="n">outcomes</span> <span class="o">=</span> <span class="p">{</span><span class="mi">128</span><span class="p">:</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)}</span>
 <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
loss: 53.34 accuracy: 0.86
</pre>
<p>It had an accuracy of about 85%.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org3cd1df3">
<h3 id="org3cd1df3">Exercises</h3>
<div class="outline-text-3" id="text-org3cd1df3"></div>
<div class="outline-4" id="outline-container-orgd97de2f">
<h4 id="orgd97de2f">Exercise 1</h4>
<div class="outline-text-4" id="text-orgd97de2f">
<p>What does the output of the next code-block mean?</p>
<div class="highlight">
<pre><span></span><span class="n">classifications</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classifications</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
</pre>
<p>Since we used the softmax method, the output is a vector representing the 10 labels, with a 1 where the predicted label is (so in this case it predicts 9).</p>
<div class="highlight">
<pre><span></span><span class="n">image</span> <span class="o">=</span> <span class="n">testing_images</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span>
    <span class="n">image</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="s2">"hover"</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Label </span><span class="si">{</span><span class="n">testing_labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">testing_labels</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span><span class="si">}</span><span class="s2">)"</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"exercise_1_image"</span><span class="p">)()</span>
</pre></div>
<object data="exercise_1_image.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Expected Label: </span><span class="si">{</span><span class="n">testing_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">testing_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Actual Label: </span><span class="si">{</span><span class="n">classifications</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">classifications</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">()]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Expected Label: 9, Ankle Boot
Actual Label: 9, Ankle Boot
</pre>
<p>So our model predicts that the first image is an <i>ankle boot</i>, which is correct.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org9062529">
<h4 id="org9062529">Exercise 2</h4>
<div class="outline-text-4" id="text-org9062529">
<p>Experiment with different values for the number of <i>units</i> in the <b>dense</b> layer.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">create_and_test_model</span><span class="p">(</span><span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""creates, trains and tests the model</span>

<span class="sd">    args:</span>
<span class="sd">     units: number of units for the dense layer</span>
<span class="sd">     epochs: number of times to train the model</span>
<span class="sd">    """</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"building a model with </span><span class="si">{</span><span class="n">units</span><span class="si">}</span><span class="s2"> units in the dense layer"</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="c1"># add the matrix -&gt; vector layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

    <span class="c1"># add the layer that does the work</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">units</span><span class="p">,</span>
                                            <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> 
                                            <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s2">"adam"</span><span class="p">,</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
    <span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"finished training the model"</span>
    <span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_images_normalized</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span> 
                  <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"testing: loss=</span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">, accuracy=</span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">accuracy</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
    <span class="n">classifications</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classifications</span><span class="p">))</span>
    <span class="n">selected</span> <span class="o">=</span> <span class="n">classifications</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">selected</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"expected label: </span><span class="si">{</span><span class="n">testing_labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="si">}</span><span class="s2">, "</span>
          <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">testing_labels</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"actual label: </span><span class="si">{</span><span class="n">selected</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">selected</span><span class="o">.</span><span class="n">argmax</span><span class="p">()]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org86c2183"></a>512 Neurons<br>
<div class="outline-text-5" id="text-org86c2183">
<div class="highlight">
<pre><span></span><span class="n">units</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">create_and_test_model</span><span class="p">(</span><span class="n">units</span><span class="p">)</span>
<span class="n">outcomes</span><span class="p">[</span><span class="n">units</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgb65e734">
2019-06-30 11:40:58,135 graeae.timers.timer start: Started: 2019-06-30 11:40:58.135283
I0630 11:40:58.135326 140129240835904 timer.py:70] Started: 2019-06-30 11:40:58.135283
building a model with 512 units in the dense layer
Epoch 1/5
60000/60000 - 2s - loss: 0.4738 - acc: 0.8316
Epoch 2/5
60000/60000 - 2s - loss: 0.3585 - acc: 0.8680
Epoch 3/5
60000/60000 - 2s - loss: 0.3218 - acc: 0.8819
Epoch 4/5
60000/60000 - 2s - loss: 0.2971 - acc: 0.8904
Epoch 5/5
60000/60000 - 2s - loss: 0.2808 - acc: 0.8963
2019-06-30 11:41:09,089 graeae.timers.timer end: Ended: 2019-06-30 11:41:09.089237
I0630 11:41:09.089263 140129240835904 timer.py:77] Ended: 2019-06-30 11:41:09.089237
2019-06-30 11:41:09,089 graeae.timers.timer end: Elapsed: 0:00:10.953954
I0630 11:41:09.089937 140129240835904 timer.py:78] Elapsed: 0:00:10.953954

testing: loss=65.45295433635712, accuracy=84.96999740600586%
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
expected label: 8, Bag
actual label: 8, Bag
</pre>
<p>The model with the 512 neuron layer has less loss and better accuracy when compared to the original model with a 128 neuron layer.</p>
</div>
</li>
<li><a id="orgd35c48b"></a>1020 Neurons<br>
<div class="outline-text-5" id="text-orgd35c48b">
<div class="highlight">
<pre><span></span><span class="n">units</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">create_and_test_model</span><span class="p">(</span><span class="n">units</span><span class="p">)</span>
<span class="n">outcomes</span><span class="p">[</span><span class="n">units</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org9489b4e">
2019-06-30 11:41:11,857 graeae.timers.timer start: Started: 2019-06-30 11:41:11.857953
I0630 11:41:11.857974 140129240835904 timer.py:70] Started: 2019-06-30 11:41:11.857953
building a model with 1024 units in the dense layer
Epoch 1/5
60000/60000 - 3s - loss: 0.4707 - acc: 0.8323
Epoch 2/5
60000/60000 - 3s - loss: 0.3588 - acc: 0.8696
Epoch 3/5
60000/60000 - 2s - loss: 0.3229 - acc: 0.8815
Epoch 4/5
60000/60000 - 3s - loss: 0.2973 - acc: 0.8891
Epoch 5/5
60000/60000 - 2s - loss: 0.2786 - acc: 0.8957
2019-06-30 11:41:25,030 graeae.timers.timer end: Ended: 2019-06-30 11:41:25.030862
I0630 11:41:25.030889 140129240835904 timer.py:77] Ended: 2019-06-30 11:41:25.030862
2019-06-30 11:41:25,031 graeae.timers.timer end: Elapsed: 0:00:13.172909
I0630 11:41:25.031725 140129240835904 timer.py:78] Elapsed: 0:00:13.172909

testing: loss=54.632147045129535, accuracy=86.79999709129333%
[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
expected label: 9, Ankle Boot
actual label: 7, Sneaker
</pre>
<p>The model did slightly better than the original 128 unit model, probably because fewer nodes don't give it enough "knobs" to tune to make an accurate match. Oddly it didn't do as well as the 512 unit model, perhaps because with that many neurons we need more data (or more epochs?). On this run it got the prediction for the single case wrong, although it doesn't usually (it should happen around 13 % of the time if the accuracy holds up).</p>
<div class="highlight">
<pre><span></span><span class="n">units</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">create_and_test_model</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">outcomes</span><span class="p">[</span><span class="n">units</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org09281c8">
2019-06-30 11:41:27,717 graeae.timers.timer start: Started: 2019-06-30 11:41:27.717040
I0630 11:41:27.717062 140129240835904 timer.py:70] Started: 2019-06-30 11:41:27.717040
building a model with 1024 units in the dense layer
Epoch 1/10
60000/60000 - 3s - loss: 0.4665 - acc: 0.8330
Epoch 2/10
60000/60000 - 3s - loss: 0.3593 - acc: 0.8675
Epoch 3/10
60000/60000 - 3s - loss: 0.3181 - acc: 0.8830
Epoch 4/10
60000/60000 - 3s - loss: 0.2964 - acc: 0.8899
Epoch 5/10
60000/60000 - 3s - loss: 0.2763 - acc: 0.8965
Epoch 6/10
60000/60000 - 3s - loss: 0.2621 - acc: 0.9021
Epoch 7/10
60000/60000 - 2s - loss: 0.2496 - acc: 0.9052
Epoch 8/10
60000/60000 - 3s - loss: 0.2384 - acc: 0.9109
Epoch 9/10
60000/60000 - 2s - loss: 0.2279 - acc: 0.9149
Epoch 10/10
60000/60000 - 2s - loss: 0.2209 - acc: 0.9165
2019-06-30 11:41:54,160 graeae.timers.timer end: Ended: 2019-06-30 11:41:54.160517
I0630 11:41:54.160544 140129240835904 timer.py:77] Ended: 2019-06-30 11:41:54.160517
2019-06-30 11:41:54,161 graeae.timers.timer end: Elapsed: 0:00:26.443477
I0630 11:41:54.161170 140129240835904 timer.py:78] Elapsed: 0:00:26.443477

testing: loss=64.08433327770233, accuracy=86.41999959945679%
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
expected label: 0, T-Shirt/Top
actual label: 0, T-Shirt/Top
</pre>
<p>It seems to be overfitting the data, it looks like we'd need more data for this many nodes. According to the original notebook, this should be more accurate, but that's not true of the test-set. Maybe they meant in comparison to the original 128 unit network, not the 512 unit network.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"|Units | Loss | Accuracy|"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"|-+-+-|"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">units</span><span class="p">,</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span> <span class="ow">in</span> <span class="n">outcomes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"|</span><span class="si">{</span><span class="n">units</span><span class="si">}</span><span class="s2">| </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">| </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2"> .2f</span><span class="si">}</span><span class="s2">|"</span><span class="p">)</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Units</th>
<th class="org-right" scope="col">Loss</th>
<th class="org-right" scope="col">Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">128</td>
<td class="org-right">53.34</td>
<td class="org-right">0.86</td>
</tr>
<tr>
<td class="org-right">512</td>
<td class="org-right">65.45</td>
<td class="org-right">0.85</td>
</tr>
<tr>
<td class="org-right">1024</td>
<td class="org-right">64.08</td>
<td class="org-right">0.86</td>
</tr>
</tbody>
</table>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org7f6406a">
<h4 id="org7f6406a">Exercise: Another Layer</h4>
<div class="outline-text-4" id="text-org7f6406a">
<p>What happens if you add another layer between the 512 unit layer and the output?</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"Adding an extra layer with 256 units"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
                                        <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                                        <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(),</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_images_normalized</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing: loss=</span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">, accuracy=</span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">accuracy</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="n">classifications</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classifications</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Expected Label: </span><span class="si">{</span><span class="n">testing_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">testing_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Actual Label: </span><span class="si">{</span><span class="n">classifications</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">classifications</span><span class="o">.</span><span class="n">argmax</span><span class="p">()]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgc5b2ddb">
Adding an extra layer with 256 units
Epoch 1/5
60000/60000 - 3s - loss: 0.4672 - acc: 0.8305
Epoch 2/5
60000/60000 - 3s - loss: 0.3549 - acc: 0.8695
Epoch 3/5
60000/60000 - 4s - loss: 0.3202 - acc: 0.8819
Epoch 4/5
60000/60000 - 4s - loss: 0.2975 - acc: 0.8904
Epoch 5/5
60000/60000 - 4s - loss: 0.2787 - acc: 0.8960

Testing: loss=46.68517806854248, accuracy=87.18000054359436%
[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
Expected Label: 9, Ankle Boot
Actual Label: 9, Ankle Boot
</pre>
<p>The testing accuracy was slightly lower (pretty much the same) but it improved the loss.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org4339140">
<h4 id="org4339140">Exercise: More Epochs</h4>
<div class="outline-text-4" id="text-org4339140">
<p>What happens if you train for 15 or 30 epochs?</p>
</div>
<ul class="org-ul">
<li><a id="orge4491e2"></a>15 Epochs<br>
<div class="outline-text-5" id="text-orge4491e2">
<div class="highlight">
<pre><span></span><span class="n">create_and_test_model</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org17fc3a9">
2019-06-30 11:42:17,312 graeae.timers.timer start: Started: 2019-06-30 11:42:17.312462
I0630 11:42:17.312490 140129240835904 timer.py:70] Started: 2019-06-30 11:42:17.312462
building a model with 512 units in the dense layer
Epoch 1/15
60000/60000 - 4s - loss: 0.4746 - acc: 0.8299
Epoch 2/15
60000/60000 - 3s - loss: 0.3558 - acc: 0.8697
Epoch 3/15
60000/60000 - 2s - loss: 0.3230 - acc: 0.8804
Epoch 4/15
60000/60000 - 2s - loss: 0.2969 - acc: 0.8892
Epoch 5/15
60000/60000 - 2s - loss: 0.2804 - acc: 0.8954
Epoch 6/15
60000/60000 - 2s - loss: 0.2644 - acc: 0.9022
Epoch 7/15
60000/60000 - 2s - loss: 0.2526 - acc: 0.9058
Epoch 8/15
60000/60000 - 2s - loss: 0.2427 - acc: 0.9093
Epoch 9/15
60000/60000 - 2s - loss: 0.2331 - acc: 0.9122
Epoch 10/15
60000/60000 - 2s - loss: 0.2217 - acc: 0.9166
Epoch 11/15
60000/60000 - 2s - loss: 0.2136 - acc: 0.9191
Epoch 12/15
60000/60000 - 2s - loss: 0.2046 - acc: 0.9232
Epoch 13/15
60000/60000 - 2s - loss: 0.1997 - acc: 0.9250
Epoch 14/15
60000/60000 - 2s - loss: 0.1919 - acc: 0.9279
Epoch 15/15
60000/60000 - 2s - loss: 0.1863 - acc: 0.9294
2019-06-30 11:42:54,542 graeae.timers.timer end: Ended: 2019-06-30 11:42:54.542345
I0630 11:42:54.542373 140129240835904 timer.py:77] Ended: 2019-06-30 11:42:54.542345
2019-06-30 11:42:54,543 graeae.timers.timer end: Elapsed: 0:00:37.229883
I0630 11:42:54.543807 140129240835904 timer.py:78] Elapsed: 0:00:37.229883

testing: loss=59.34430006275177, accuracy=87.44999766349792%
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
expected label: 3, Dress
actual label: 3, Dress
</pre>
<p>The accuracy went up slightly, but the loss went up even more.</p>
</div>
</li>
<li><a id="org55c3d1e"></a>30 Epochs<br>
<div class="outline-text-5" id="text-org55c3d1e">
<div class="highlight">
<pre><span></span><span class="n">create_and_test_model</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org5c92d51">
2019-06-30 11:42:57,431 graeae.timers.timer start: Started: 2019-06-30 11:42:57.431973
I0630 11:42:57.431994 140129240835904 timer.py:70] Started: 2019-06-30 11:42:57.431973
building a model with 512 units in the dense layer
Epoch 1/30
60000/60000 - 2s - loss: 0.4750 - acc: 0.8312
Epoch 2/30
60000/60000 - 2s - loss: 0.3623 - acc: 0.8686
Epoch 3/30
60000/60000 - 2s - loss: 0.3226 - acc: 0.8818
Epoch 4/30
60000/60000 - 3s - loss: 0.2990 - acc: 0.8901
Epoch 5/30
60000/60000 - 2s - loss: 0.2814 - acc: 0.8961
Epoch 6/30
60000/60000 - 2s - loss: 0.2644 - acc: 0.9017
Epoch 7/30
60000/60000 - 2s - loss: 0.2529 - acc: 0.9061
Epoch 8/30
60000/60000 - 2s - loss: 0.2433 - acc: 0.9089
Epoch 9/30
60000/60000 - 2s - loss: 0.2305 - acc: 0.9124
Epoch 10/30
60000/60000 - 2s - loss: 0.2211 - acc: 0.9164
Epoch 11/30
60000/60000 - 2s - loss: 0.2133 - acc: 0.9186
Epoch 12/30
60000/60000 - 2s - loss: 0.2065 - acc: 0.9222
Epoch 13/30
60000/60000 - 2s - loss: 0.1998 - acc: 0.9243
Epoch 14/30
60000/60000 - 2s - loss: 0.1905 - acc: 0.9284
Epoch 15/30
60000/60000 - 2s - loss: 0.1828 - acc: 0.9307
Epoch 16/30
60000/60000 - 2s - loss: 0.1782 - acc: 0.9322
Epoch 17/30
60000/60000 - 2s - loss: 0.1714 - acc: 0.9348
Epoch 18/30
60000/60000 - 2s - loss: 0.1672 - acc: 0.9367
Epoch 19/30
60000/60000 - 2s - loss: 0.1622 - acc: 0.9390
Epoch 20/30
60000/60000 - 2s - loss: 0.1556 - acc: 0.9405
Epoch 21/30
60000/60000 - 2s - loss: 0.1518 - acc: 0.9422
Epoch 22/30
60000/60000 - 2s - loss: 0.1463 - acc: 0.9445
Epoch 23/30
60000/60000 - 2s - loss: 0.1451 - acc: 0.9441
Epoch 24/30
60000/60000 - 2s - loss: 0.1408 - acc: 0.9468
Epoch 25/30
60000/60000 - 2s - loss: 0.1340 - acc: 0.9499
Epoch 26/30
60000/60000 - 2s - loss: 0.1325 - acc: 0.9488
Epoch 27/30
60000/60000 - 2s - loss: 0.1271 - acc: 0.9520
Epoch 28/30
60000/60000 - 2s - loss: 0.1246 - acc: 0.9532
Epoch 29/30
60000/60000 - 2s - loss: 0.1235 - acc: 0.9539
Epoch 30/30
60000/60000 - 2s - loss: 0.1199 - acc: 0.9550
2019-06-30 11:44:03,867 graeae.timers.timer end: Ended: 2019-06-30 11:44:03.867668
I0630 11:44:03.867694 140129240835904 timer.py:77] Ended: 2019-06-30 11:44:03.867668
2019-06-30 11:44:03,868 graeae.timers.timer end: Elapsed: 0:01:06.435695
I0630 11:44:03.868357 140129240835904 timer.py:78] Elapsed: 0:01:06.435695

testing: loss=96.21011676330566, accuracy=87.44999766349792%
[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
expected label: 1, Trouser
actual label: 1, Trouser
</pre>
<p>The accuracy seems to be around the same, but the loss is getting pretty high.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org3060c50">
<h4 id="org3060c50">Early Stopping</h4>
<div class="outline-text-4" id="text-org3060c50">
<p>What if you want to stop when the loss reaches a certain point? In Keras/tensorflow <a href="https://www.tensorflow.org/beta/guide/keras/custom_callback">you can set a callback</a> that stops the training (and other things, like plot images or store the values as you progress for later plotting.)</p>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Stop</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="p">{}):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.4</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Stopping point reached at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
<p>The <code>logs</code> dict will contain all the metrics, so even though we used loss, you could also, in this case, use <i>Mean Absolute Error</i>.</p>
<div class="highlight">
<pre><span></span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">Stop</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
  <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
  <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">),</span>
  <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span> 
              <span class="n">loss</span><span class="o">=</span><span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_images_normalized</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
          <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callbacks</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">outcomes</span><span class="p">[</span><span class="s2">"512 (early stopping)"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing: Loss=</span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">, Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">classifications</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">)</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classifications</span><span class="p">))</span>
<span class="n">selected</span> <span class="o">=</span> <span class="n">classifications</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">selected</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"expected label: </span><span class="si">{</span><span class="n">testing_labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">testing_labels</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"actual label: </span><span class="si">{</span><span class="n">selected</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">selected</span><span class="o">.</span><span class="n">argmax</span><span class="p">()]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org48235d9">
Epoch 1/5
60000/60000 - 2s - loss: 0.4765 - acc: 0.8295
Epoch 2/5
Stopping point reached at epoch 1
60000/60000 - 2s - loss: 0.3597 - acc: 0.8679

Testing: Loss=58.14345246582031, Accuracy: 0.8514999747276306
[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
expected label: 9, Ankle Boot
actual label: 9, Ankle Boot
</pre>
<p>By setting a threshold for the loss we were able to stop after two epochs instead of going to the full five epochs, which saves on training time, but also sometimes reduces the performance on the testing set slightly (the training that went the full five epochs stopped at a loss of 0.28, not 0.4). I just noticed that the 512 unit network actually didn't do better this time (each time I run this notebook things change slightly) but normally it is the model that performs the best.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"|Units | Loss | Accuracy|"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"|-+-+-|"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">units</span><span class="p">,</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span> <span class="ow">in</span> <span class="n">outcomes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"|</span><span class="si">{</span><span class="n">units</span><span class="si">}</span><span class="s2">| </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">| </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2"> .2f</span><span class="si">}</span><span class="s2">|"</span><span class="p">)</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Units</th>
<th class="org-right" scope="col">Loss</th>
<th class="org-right" scope="col">Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">128</td>
<td class="org-right">53.34</td>
<td class="org-right">0.86</td>
</tr>
<tr>
<td class="org-right">512</td>
<td class="org-right">65.45</td>
<td class="org-right">0.85</td>
</tr>
<tr>
<td class="org-right">1024</td>
<td class="org-right">64.08</td>
<td class="org-right">0.86</td>
</tr>
<tr>
<td class="org-right">512 (early stopping)</td>
<td class="org-right">58.14</td>
<td class="org-right">0.85</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org72c22e5">
<h2 id="org72c22e5">End</h2>
<div class="outline-text-2" id="text-org72c22e5"></div>
<div class="outline-3" id="outline-container-org53b8906">
<h3 id="org53b8906">Source</h3>
<div class="outline-text-3" id="text-org53b8906">
<p>This is a re-do of the <a href="https://github.com/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%204%20-%20Lesson%202%20-%20Notebook.ipynb">Beyond Hello World, A Computer Vision Example</a> notebook on github by <a href="https://github.com/lmoroney">Laurence Moroney</a>.</p>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/deep-learning/" rel="tag">deep learning</a></li>
<li><a class="tag p-category" href="../../../categories/keras/" rel="tag">keras</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../hello-there/" rel="prev" title="Hello There">Previous post</a></li>
<li class="next"><a href="../handwriting-recognition-exercise/" rel="next" title="Handwriting Recognition Exercise">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Scribbles by <a href="mailto:cloisteredmonkey.jmark@slmail.me">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>
<div id="license" xmlns:cc="http://creativecommons.org/ns#">This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" rel="license noopener noreferrer" style="display:inline-block;" target="_blank">CC BY 4.0 <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></div>
</footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
