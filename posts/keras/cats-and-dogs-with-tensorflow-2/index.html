<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Classifying Cats and Dogs." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Cats and Dogs with TensorFlow 2 | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/keras/cats-and-dogs-with-tensorflow-2/index.html" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../dogs-vs-cats-with-transfer-learning/index.html" rel="prev" title="Dogs Vs Cats With Transfer Learning" type="text/html">
<link href="../horse-or-human-using-tensorflow-20/index.html" rel="next" title="Horse Or Human Using TensorFlow 2.0" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Cats and Dogs with TensorFlow 2" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/keras/cats-and-dogs-with-tensorflow-2/index.html" property="og:url">
<meta content="Classifying Cats and Dogs." property="og:description">
<meta content="article" property="og:type">
<meta content="2019-08-04T13:24:59-07:00" property="article:published_time">
<meta content="cnn" property="article:tag">
<meta content="keras" property="article:tag">
<meta content="tensorflow" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../pages/">Pages</a></li>
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item dropdown"><a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#">Monkey Pages</a>
<div class="dropdown-menu"><a class="dropdown-item" href="https://necromuralist.github.io/">The Cloistered Monkey</a> <a class="dropdown-item" href="https://necromuralist.github.io/Ape-Iron/">Ape Iron</a> <a class="dropdown-item" href="https://necromuralist.github.io/Bowling-For-Data/">Bowling For Data</a> <a class="dropdown-item" href="https://necromuralist.github.io/Beach-Pig-Thigh/">Beach-Pig Rump & Thigh</a> <a class="dropdown-item" href="https://necromuralist.github.io/Visions-Voices-Data/">Visions, Voices, Data</a></div>
</li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="#">Cats and Dogs with TensorFlow 2</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="#" rel="bookmark"><time class="published dt-published" datetime="2019-08-04T13:24:59-07:00" itemprop="datePublished" title="2019-08-04 13:24">2019-08-04 13:24</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="index.html#orgc88d87d">Beginning</a>
<ul>
<li><a href="index.html#org3ccb736">Imports</a>
<ul>
<li><a href="index.html#org22ab494">Python</a></li>
<li><a href="index.html#org414bd9a">PyPi</a></li>
<li><a href="index.html#org57ab190">My Stuff</a></li>
</ul>
</li>
<li><a href="index.html#org321ec55">Setup</a>
<ul>
<li><a href="index.html#org0fed214">Plotting</a></li>
<li><a href="index.html#org716e59d">Datasets</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="index.html#orgd7fed4d">Middle</a>
<ul>
<li><a href="index.html#org224ba97">The Dataset</a>
<ul>
<li><a href="index.html#org1802558">Format the Data</a></li>
</ul>
</li>
<li><a href="index.html#orgab96562">The Base Model</a>
<ul>
<li><a href="index.html#org038bbcd">Add The End Layers</a></li>
</ul>
</li>
<li><a href="index.html#org25be516">The Model</a>
<ul>
<li><a href="index.html#org5df96e6">Compile it</a></li>
</ul>
</li>
<li><a href="index.html#org07e13c7">Train the Model</a></li>
</ul>
</li>
<li><a href="index.html#orgc4e5ac6">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgc88d87d">
<h2 id="orgc88d87d">Beginning</h2>
<div class="outline-text-2" id="text-orgc88d87d">
<p>This is transfer learning using tensorflow 2.</p>
</div>
<div class="outline-3" id="outline-container-org3ccb736">
<h3 id="org3ccb736">Imports</h3>
<div class="outline-text-3" id="text-org3ccb736"></div>
<div class="outline-4" id="outline-container-org22ab494">
<h4 id="org22ab494">Python</h4>
<div class="outline-text-4" id="text-org22ab494">
<div class="highlight">
<pre><span></span>from functools import partial
from pathlib import Path
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org414bd9a">
<h4 id="org414bd9a">PyPi</h4>
<div class="outline-text-4" id="text-org414bd9a">
<div class="highlight">
<pre><span></span>import hvplot.pandas
import matplotlib.pyplot as pyplot
import pandas
import seaborn
import tensorflow
import tensorflow_datasets
keras = tensorflow.keras
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org57ab190">
<h4 id="org57ab190">My Stuff</h4>
<div class="outline-text-4" id="text-org57ab190">
<div class="highlight">
<pre><span></span>from graeae import EmbedHoloviews
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org321ec55">
<h3 id="org321ec55">Setup</h3>
<div class="outline-text-3" id="text-org321ec55"></div>
<div class="outline-4" id="outline-container-org0fed214">
<h4 id="org0fed214">Plotting</h4>
<div class="outline-text-4" id="text-org0fed214">
<div class="highlight">
<pre><span></span>Embed = partial(
    EmbedHoloviews,
    folder_path="../../files/posts/keras/cats-and-dogs-with-tensorflow-2")
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org716e59d">
<h4 id="org716e59d">Datasets</h4>
<div class="outline-text-4" id="text-org716e59d">
<div class="highlight">
<pre><span></span>tensorflow_datasets.disable_progress_bar()
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgd7fed4d">
<h2 id="orgd7fed4d">Middle</h2>
<div class="outline-text-2" id="text-orgd7fed4d"></div>
<div class="outline-3" id="outline-container-org224ba97">
<h3 id="org224ba97">The Dataset</h3>
<div class="outline-text-3" id="text-org224ba97">
<p>Previously I had downloaded the <i>Cats vs Dogs</i> dataset from kaggle or Microsoft, but this time I'll download it using <a href="https://www.tensorflow.org/datasets">TensorFlow Datasets</a>.</p>
<p>The <i>Dogs vs Cats</i> data set doesn't define train-validation-splits so we have to do that by passing in the first digit of the percentage we want (e.g. 8 means 80% so (8, 1, 1) means (80%, 10%, 10%)).</p>
<div class="highlight">
<pre><span></span>SPLIT_WEIGHTS = (8, 1, 1)
splits = tensorflow_datasets.Split.TRAIN.subsplit(weighted=SPLIT_WEIGHTS)

(raw_train, raw_validation, raw_test), metadata = tensorflow_datasets.load(
    "cats_vs_dogs", 
    split=list(splits), 
    with_info=True, 
    as_supervised=True)
</pre></div>
<pre class="example">
Downloading and preparing dataset cats_vs_dogs (786.68 MiB) to /home/athena/tensorflow_datasets/cats_vs_dogs/2.0.1...
/home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/urllib3/connectionpool.py:851: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)
WARNING: Logging before flag parsing goes to stderr.
W0804 14:02:41.729103 140458756540224 cats_vs_dogs.py:117] 1738 images were corrupted and were skipped
W0804 14:02:41.734799 140458756540224 deprecation.py:323] From /home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`
Dataset cats_vs_dogs downloaded and prepared to /home/athena/tensorflow_datasets/cats_vs_dogs/2.0.1. Subsequent calls will reuse this data.
</pre>
<div class="highlight">
<pre><span></span>print(raw_train)
print(raw_validation)
print(raw_test)
</pre></div>
<pre class="example">
&lt;_OptionsDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)&gt;
&lt;_OptionsDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)&gt;
&lt;_OptionsDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)&gt;
</pre>
<div class="highlight">
<pre><span></span>get_label_name = metadata.features["label"].int2str
for image, label in raw_train.take(2):
    pyplot.figure()
    pyplot.imshow(image)
    pyplot.title(get_label_name(label))
</pre></div>
<div class="figure" id="org8b93cc5">
<p><img alt="sample_images.png" src="../../files/posts/keras/cats-and-dogs-with-tensorflow-2/sample_images.png"></p>
</div>
<p><a href="sample_images.png">Sample Images</a></p>
</div>
<div class="outline-4" id="outline-container-org1802558">
<h4 id="org1802558">Format the Data</h4>
<div class="outline-text-4" id="text-org1802558">
<div class="highlight">
<pre><span></span>IMAGE_SIZE = 160
def format_example(image, label):
    image = tensorflow.cast(image, tensorflow.float32)
    image = (image/127.5) - 1
    image = tensorflow.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))
    return image, label
</pre></div>
<div class="highlight">
<pre><span></span>train = raw_train.map(format_example)
validation = raw_validation.map(format_example)
test = raw_test.map(format_example)
</pre></div>
<div class="highlight">
<pre><span></span>BATCH_SIZE = 32
SHUFFLE_BUFFER_SIZE = 1000

train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)
validation_batches = validation.batch(BATCH_SIZE)
test_batches = test.batch(BATCH_SIZE)
</pre></div>
<div class="highlight">
<pre><span></span>for image_batch, label_batch in train_batches.take(1):
    print(image_batch.shape)
</pre></div>
<pre class="example">
(32, 160, 160, 3)
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgab96562">
<h3 id="orgab96562">The Base Model</h3>
<div class="outline-text-3" id="text-orgab96562">
<div class="highlight">
<pre><span></span>IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)
base_model = tensorflow.keras.applications.MobileNetV2(
    input_shape=IMAGE_SHAPE,
    include_top=False,
    weights="imagenet"
)
</pre></div>
<div class="highlight">
<pre><span></span>IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)
base_model = tensorflow.keras.applications.InceptionV3(
    input_shape=IMAGE_SHAPE,
    include_top=False,
    weights="imagenet"
)
</pre></div>
<div class="highlight">
<pre><span></span>feature_batch = base_model(image_batch)
print(feature_batch.shape)
</pre></div>
<pre class="example">
(32, 3, 3, 2048)
</pre>
<div class="highlight">
<pre><span></span>base_model.trainable = False
print(base_model.summary())
</pre></div>
<pre class="example" id="org40d1681">
Model: "inception_v3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 160, 160, 3) 0                                            
__________________________________________________________________________________________________
conv2d_94 (Conv2D)              (None, 79, 79, 32)   864         input_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_94 (BatchNo (None, 79, 79, 32)   96          conv2d_94[0][0]                  
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 79, 79, 32)   0           batch_normalization_94[0][0]     
__________________________________________________________________________________________________
conv2d_95 (Conv2D)              (None, 77, 77, 32)   9216        activation_94[0][0]              
__________________________________________________________________________________________________
batch_normalization_95 (BatchNo (None, 77, 77, 32)   96          conv2d_95[0][0]                  
__________________________________________________________________________________________________
activation_95 (Activation)      (None, 77, 77, 32)   0           batch_normalization_95[0][0]     
__________________________________________________________________________________________________
conv2d_96 (Conv2D)              (None, 77, 77, 64)   18432       activation_95[0][0]              
__________________________________________________________________________________________________
batch_normalization_96 (BatchNo (None, 77, 77, 64)   192         conv2d_96[0][0]                  
__________________________________________________________________________________________________
activation_96 (Activation)      (None, 77, 77, 64)   0           batch_normalization_96[0][0]     
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 38, 38, 64)   0           activation_96[0][0]              
__________________________________________________________________________________________________
conv2d_97 (Conv2D)              (None, 38, 38, 80)   5120        max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
batch_normalization_97 (BatchNo (None, 38, 38, 80)   240         conv2d_97[0][0]                  
__________________________________________________________________________________________________
activation_97 (Activation)      (None, 38, 38, 80)   0           batch_normalization_97[0][0]     
__________________________________________________________________________________________________
conv2d_98 (Conv2D)              (None, 36, 36, 192)  138240      activation_97[0][0]              
__________________________________________________________________________________________________
batch_normalization_98 (BatchNo (None, 36, 36, 192)  576         conv2d_98[0][0]                  
__________________________________________________________________________________________________
activation_98 (Activation)      (None, 36, 36, 192)  0           batch_normalization_98[0][0]     
__________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D)  (None, 17, 17, 192)  0           activation_98[0][0]              
__________________________________________________________________________________________________
conv2d_102 (Conv2D)             (None, 17, 17, 64)   12288       max_pooling2d_5[0][0]            
__________________________________________________________________________________________________
batch_normalization_102 (BatchN (None, 17, 17, 64)   192         conv2d_102[0][0]                 
__________________________________________________________________________________________________
activation_102 (Activation)     (None, 17, 17, 64)   0           batch_normalization_102[0][0]    
__________________________________________________________________________________________________
conv2d_100 (Conv2D)             (None, 17, 17, 48)   9216        max_pooling2d_5[0][0]            
__________________________________________________________________________________________________
conv2d_103 (Conv2D)             (None, 17, 17, 96)   55296       activation_102[0][0]             
__________________________________________________________________________________________________
batch_normalization_100 (BatchN (None, 17, 17, 48)   144         conv2d_100[0][0]                 
__________________________________________________________________________________________________
batch_normalization_103 (BatchN (None, 17, 17, 96)   288         conv2d_103[0][0]                 
__________________________________________________________________________________________________
activation_100 (Activation)     (None, 17, 17, 48)   0           batch_normalization_100[0][0]    
__________________________________________________________________________________________________
activation_103 (Activation)     (None, 17, 17, 96)   0           batch_normalization_103[0][0]    
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 17, 17, 192)  0           max_pooling2d_5[0][0]            
__________________________________________________________________________________________________
conv2d_99 (Conv2D)              (None, 17, 17, 64)   12288       max_pooling2d_5[0][0]            
__________________________________________________________________________________________________
conv2d_101 (Conv2D)             (None, 17, 17, 64)   76800       activation_100[0][0]             
__________________________________________________________________________________________________
conv2d_104 (Conv2D)             (None, 17, 17, 96)   82944       activation_103[0][0]             
__________________________________________________________________________________________________
conv2d_105 (Conv2D)             (None, 17, 17, 32)   6144        average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
batch_normalization_99 (BatchNo (None, 17, 17, 64)   192         conv2d_99[0][0]                  
__________________________________________________________________________________________________
batch_normalization_101 (BatchN (None, 17, 17, 64)   192         conv2d_101[0][0]                 
__________________________________________________________________________________________________
batch_normalization_104 (BatchN (None, 17, 17, 96)   288         conv2d_104[0][0]                 
__________________________________________________________________________________________________
batch_normalization_105 (BatchN (None, 17, 17, 32)   96          conv2d_105[0][0]                 
__________________________________________________________________________________________________
activation_99 (Activation)      (None, 17, 17, 64)   0           batch_normalization_99[0][0]     
__________________________________________________________________________________________________
activation_101 (Activation)     (None, 17, 17, 64)   0           batch_normalization_101[0][0]    
__________________________________________________________________________________________________
activation_104 (Activation)     (None, 17, 17, 96)   0           batch_normalization_104[0][0]    
__________________________________________________________________________________________________
activation_105 (Activation)     (None, 17, 17, 32)   0           batch_normalization_105[0][0]    
__________________________________________________________________________________________________
mixed0 (Concatenate)            (None, 17, 17, 256)  0           activation_99[0][0]              
                                                                 activation_101[0][0]             
                                                                 activation_104[0][0]             
                                                                 activation_105[0][0]             
__________________________________________________________________________________________________
conv2d_109 (Conv2D)             (None, 17, 17, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
batch_normalization_109 (BatchN (None, 17, 17, 64)   192         conv2d_109[0][0]                 
__________________________________________________________________________________________________
activation_109 (Activation)     (None, 17, 17, 64)   0           batch_normalization_109[0][0]    
__________________________________________________________________________________________________
conv2d_107 (Conv2D)             (None, 17, 17, 48)   12288       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_110 (Conv2D)             (None, 17, 17, 96)   55296       activation_109[0][0]             
__________________________________________________________________________________________________
batch_normalization_107 (BatchN (None, 17, 17, 48)   144         conv2d_107[0][0]                 
__________________________________________________________________________________________________
batch_normalization_110 (BatchN (None, 17, 17, 96)   288         conv2d_110[0][0]                 
__________________________________________________________________________________________________
activation_107 (Activation)     (None, 17, 17, 48)   0           batch_normalization_107[0][0]    
__________________________________________________________________________________________________
activation_110 (Activation)     (None, 17, 17, 96)   0           batch_normalization_110[0][0]    
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 17, 17, 256)  0           mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_106 (Conv2D)             (None, 17, 17, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_108 (Conv2D)             (None, 17, 17, 64)   76800       activation_107[0][0]             
__________________________________________________________________________________________________
conv2d_111 (Conv2D)             (None, 17, 17, 96)   82944       activation_110[0][0]             
__________________________________________________________________________________________________
conv2d_112 (Conv2D)             (None, 17, 17, 64)   16384       average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
batch_normalization_106 (BatchN (None, 17, 17, 64)   192         conv2d_106[0][0]                 
__________________________________________________________________________________________________
batch_normalization_108 (BatchN (None, 17, 17, 64)   192         conv2d_108[0][0]                 
__________________________________________________________________________________________________
batch_normalization_111 (BatchN (None, 17, 17, 96)   288         conv2d_111[0][0]                 
__________________________________________________________________________________________________
batch_normalization_112 (BatchN (None, 17, 17, 64)   192         conv2d_112[0][0]                 
__________________________________________________________________________________________________
activation_106 (Activation)     (None, 17, 17, 64)   0           batch_normalization_106[0][0]    
__________________________________________________________________________________________________
activation_108 (Activation)     (None, 17, 17, 64)   0           batch_normalization_108[0][0]    
__________________________________________________________________________________________________
activation_111 (Activation)     (None, 17, 17, 96)   0           batch_normalization_111[0][0]    
__________________________________________________________________________________________________
activation_112 (Activation)     (None, 17, 17, 64)   0           batch_normalization_112[0][0]    
__________________________________________________________________________________________________
mixed1 (Concatenate)            (None, 17, 17, 288)  0           activation_106[0][0]             
                                                                 activation_108[0][0]             
                                                                 activation_111[0][0]             
                                                                 activation_112[0][0]             
__________________________________________________________________________________________________
conv2d_116 (Conv2D)             (None, 17, 17, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
batch_normalization_116 (BatchN (None, 17, 17, 64)   192         conv2d_116[0][0]                 
__________________________________________________________________________________________________
activation_116 (Activation)     (None, 17, 17, 64)   0           batch_normalization_116[0][0]    
__________________________________________________________________________________________________
conv2d_114 (Conv2D)             (None, 17, 17, 48)   13824       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_117 (Conv2D)             (None, 17, 17, 96)   55296       activation_116[0][0]             
__________________________________________________________________________________________________
batch_normalization_114 (BatchN (None, 17, 17, 48)   144         conv2d_114[0][0]                 
__________________________________________________________________________________________________
batch_normalization_117 (BatchN (None, 17, 17, 96)   288         conv2d_117[0][0]                 
__________________________________________________________________________________________________
activation_114 (Activation)     (None, 17, 17, 48)   0           batch_normalization_114[0][0]    
__________________________________________________________________________________________________
activation_117 (Activation)     (None, 17, 17, 96)   0           batch_normalization_117[0][0]    
__________________________________________________________________________________________________
average_pooling2d_11 (AveragePo (None, 17, 17, 288)  0           mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_113 (Conv2D)             (None, 17, 17, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_115 (Conv2D)             (None, 17, 17, 64)   76800       activation_114[0][0]             
__________________________________________________________________________________________________
conv2d_118 (Conv2D)             (None, 17, 17, 96)   82944       activation_117[0][0]             
__________________________________________________________________________________________________
conv2d_119 (Conv2D)             (None, 17, 17, 64)   18432       average_pooling2d_11[0][0]       
__________________________________________________________________________________________________
batch_normalization_113 (BatchN (None, 17, 17, 64)   192         conv2d_113[0][0]                 
__________________________________________________________________________________________________
batch_normalization_115 (BatchN (None, 17, 17, 64)   192         conv2d_115[0][0]                 
__________________________________________________________________________________________________
batch_normalization_118 (BatchN (None, 17, 17, 96)   288         conv2d_118[0][0]                 
__________________________________________________________________________________________________
batch_normalization_119 (BatchN (None, 17, 17, 64)   192         conv2d_119[0][0]                 
__________________________________________________________________________________________________
activation_113 (Activation)     (None, 17, 17, 64)   0           batch_normalization_113[0][0]    
__________________________________________________________________________________________________
activation_115 (Activation)     (None, 17, 17, 64)   0           batch_normalization_115[0][0]    
__________________________________________________________________________________________________
activation_118 (Activation)     (None, 17, 17, 96)   0           batch_normalization_118[0][0]    
__________________________________________________________________________________________________
activation_119 (Activation)     (None, 17, 17, 64)   0           batch_normalization_119[0][0]    
__________________________________________________________________________________________________
mixed2 (Concatenate)            (None, 17, 17, 288)  0           activation_113[0][0]             
                                                                 activation_115[0][0]             
                                                                 activation_118[0][0]             
                                                                 activation_119[0][0]             
__________________________________________________________________________________________________
conv2d_121 (Conv2D)             (None, 17, 17, 64)   18432       mixed2[0][0]                     
__________________________________________________________________________________________________
batch_normalization_121 (BatchN (None, 17, 17, 64)   192         conv2d_121[0][0]                 
__________________________________________________________________________________________________
activation_121 (Activation)     (None, 17, 17, 64)   0           batch_normalization_121[0][0]    
__________________________________________________________________________________________________
conv2d_122 (Conv2D)             (None, 17, 17, 96)   55296       activation_121[0][0]             
__________________________________________________________________________________________________
batch_normalization_122 (BatchN (None, 17, 17, 96)   288         conv2d_122[0][0]                 
__________________________________________________________________________________________________
activation_122 (Activation)     (None, 17, 17, 96)   0           batch_normalization_122[0][0]    
__________________________________________________________________________________________________
conv2d_120 (Conv2D)             (None, 8, 8, 384)    995328      mixed2[0][0]                     
__________________________________________________________________________________________________
conv2d_123 (Conv2D)             (None, 8, 8, 96)     82944       activation_122[0][0]             
__________________________________________________________________________________________________
batch_normalization_120 (BatchN (None, 8, 8, 384)    1152        conv2d_120[0][0]                 
__________________________________________________________________________________________________
batch_normalization_123 (BatchN (None, 8, 8, 96)     288         conv2d_123[0][0]                 
__________________________________________________________________________________________________
activation_120 (Activation)     (None, 8, 8, 384)    0           batch_normalization_120[0][0]    
__________________________________________________________________________________________________
activation_123 (Activation)     (None, 8, 8, 96)     0           batch_normalization_123[0][0]    
__________________________________________________________________________________________________
max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 288)    0           mixed2[0][0]                     
__________________________________________________________________________________________________
mixed3 (Concatenate)            (None, 8, 8, 768)    0           activation_120[0][0]             
                                                                 activation_123[0][0]             
                                                                 max_pooling2d_6[0][0]            
__________________________________________________________________________________________________
conv2d_128 (Conv2D)             (None, 8, 8, 128)    98304       mixed3[0][0]                     
__________________________________________________________________________________________________
batch_normalization_128 (BatchN (None, 8, 8, 128)    384         conv2d_128[0][0]                 
__________________________________________________________________________________________________
activation_128 (Activation)     (None, 8, 8, 128)    0           batch_normalization_128[0][0]    
__________________________________________________________________________________________________
conv2d_129 (Conv2D)             (None, 8, 8, 128)    114688      activation_128[0][0]             
__________________________________________________________________________________________________
batch_normalization_129 (BatchN (None, 8, 8, 128)    384         conv2d_129[0][0]                 
__________________________________________________________________________________________________
activation_129 (Activation)     (None, 8, 8, 128)    0           batch_normalization_129[0][0]    
__________________________________________________________________________________________________
conv2d_125 (Conv2D)             (None, 8, 8, 128)    98304       mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_130 (Conv2D)             (None, 8, 8, 128)    114688      activation_129[0][0]             
__________________________________________________________________________________________________
batch_normalization_125 (BatchN (None, 8, 8, 128)    384         conv2d_125[0][0]                 
__________________________________________________________________________________________________
batch_normalization_130 (BatchN (None, 8, 8, 128)    384         conv2d_130[0][0]                 
__________________________________________________________________________________________________
activation_125 (Activation)     (None, 8, 8, 128)    0           batch_normalization_125[0][0]    
__________________________________________________________________________________________________
activation_130 (Activation)     (None, 8, 8, 128)    0           batch_normalization_130[0][0]    
__________________________________________________________________________________________________
conv2d_126 (Conv2D)             (None, 8, 8, 128)    114688      activation_125[0][0]             
__________________________________________________________________________________________________
conv2d_131 (Conv2D)             (None, 8, 8, 128)    114688      activation_130[0][0]             
__________________________________________________________________________________________________
batch_normalization_126 (BatchN (None, 8, 8, 128)    384         conv2d_126[0][0]                 
__________________________________________________________________________________________________
batch_normalization_131 (BatchN (None, 8, 8, 128)    384         conv2d_131[0][0]                 
__________________________________________________________________________________________________
activation_126 (Activation)     (None, 8, 8, 128)    0           batch_normalization_126[0][0]    
__________________________________________________________________________________________________
activation_131 (Activation)     (None, 8, 8, 128)    0           batch_normalization_131[0][0]    
__________________________________________________________________________________________________
average_pooling2d_12 (AveragePo (None, 8, 8, 768)    0           mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_124 (Conv2D)             (None, 8, 8, 192)    147456      mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_127 (Conv2D)             (None, 8, 8, 192)    172032      activation_126[0][0]             
__________________________________________________________________________________________________
conv2d_132 (Conv2D)             (None, 8, 8, 192)    172032      activation_131[0][0]             
__________________________________________________________________________________________________
conv2d_133 (Conv2D)             (None, 8, 8, 192)    147456      average_pooling2d_12[0][0]       
__________________________________________________________________________________________________
batch_normalization_124 (BatchN (None, 8, 8, 192)    576         conv2d_124[0][0]                 
__________________________________________________________________________________________________
batch_normalization_127 (BatchN (None, 8, 8, 192)    576         conv2d_127[0][0]                 
__________________________________________________________________________________________________
batch_normalization_132 (BatchN (None, 8, 8, 192)    576         conv2d_132[0][0]                 
__________________________________________________________________________________________________
batch_normalization_133 (BatchN (None, 8, 8, 192)    576         conv2d_133[0][0]                 
__________________________________________________________________________________________________
activation_124 (Activation)     (None, 8, 8, 192)    0           batch_normalization_124[0][0]    
__________________________________________________________________________________________________
activation_127 (Activation)     (None, 8, 8, 192)    0           batch_normalization_127[0][0]    
__________________________________________________________________________________________________
activation_132 (Activation)     (None, 8, 8, 192)    0           batch_normalization_132[0][0]    
__________________________________________________________________________________________________
activation_133 (Activation)     (None, 8, 8, 192)    0           batch_normalization_133[0][0]    
__________________________________________________________________________________________________
mixed4 (Concatenate)            (None, 8, 8, 768)    0           activation_124[0][0]             
                                                                 activation_127[0][0]             
                                                                 activation_132[0][0]             
                                                                 activation_133[0][0]             
__________________________________________________________________________________________________
conv2d_138 (Conv2D)             (None, 8, 8, 160)    122880      mixed4[0][0]                     
__________________________________________________________________________________________________
batch_normalization_138 (BatchN (None, 8, 8, 160)    480         conv2d_138[0][0]                 
__________________________________________________________________________________________________
activation_138 (Activation)     (None, 8, 8, 160)    0           batch_normalization_138[0][0]    
__________________________________________________________________________________________________
conv2d_139 (Conv2D)             (None, 8, 8, 160)    179200      activation_138[0][0]             
__________________________________________________________________________________________________
batch_normalization_139 (BatchN (None, 8, 8, 160)    480         conv2d_139[0][0]                 
__________________________________________________________________________________________________
activation_139 (Activation)     (None, 8, 8, 160)    0           batch_normalization_139[0][0]    
__________________________________________________________________________________________________
conv2d_135 (Conv2D)             (None, 8, 8, 160)    122880      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_140 (Conv2D)             (None, 8, 8, 160)    179200      activation_139[0][0]             
__________________________________________________________________________________________________
batch_normalization_135 (BatchN (None, 8, 8, 160)    480         conv2d_135[0][0]                 
__________________________________________________________________________________________________
batch_normalization_140 (BatchN (None, 8, 8, 160)    480         conv2d_140[0][0]                 
__________________________________________________________________________________________________
activation_135 (Activation)     (None, 8, 8, 160)    0           batch_normalization_135[0][0]    
__________________________________________________________________________________________________
activation_140 (Activation)     (None, 8, 8, 160)    0           batch_normalization_140[0][0]    
__________________________________________________________________________________________________
conv2d_136 (Conv2D)             (None, 8, 8, 160)    179200      activation_135[0][0]             
__________________________________________________________________________________________________
conv2d_141 (Conv2D)             (None, 8, 8, 160)    179200      activation_140[0][0]             
__________________________________________________________________________________________________
batch_normalization_136 (BatchN (None, 8, 8, 160)    480         conv2d_136[0][0]                 
__________________________________________________________________________________________________
batch_normalization_141 (BatchN (None, 8, 8, 160)    480         conv2d_141[0][0]                 
__________________________________________________________________________________________________
activation_136 (Activation)     (None, 8, 8, 160)    0           batch_normalization_136[0][0]    
__________________________________________________________________________________________________
activation_141 (Activation)     (None, 8, 8, 160)    0           batch_normalization_141[0][0]    
__________________________________________________________________________________________________
average_pooling2d_13 (AveragePo (None, 8, 8, 768)    0           mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_134 (Conv2D)             (None, 8, 8, 192)    147456      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_137 (Conv2D)             (None, 8, 8, 192)    215040      activation_136[0][0]             
__________________________________________________________________________________________________
conv2d_142 (Conv2D)             (None, 8, 8, 192)    215040      activation_141[0][0]             
__________________________________________________________________________________________________
conv2d_143 (Conv2D)             (None, 8, 8, 192)    147456      average_pooling2d_13[0][0]       
__________________________________________________________________________________________________
batch_normalization_134 (BatchN (None, 8, 8, 192)    576         conv2d_134[0][0]                 
__________________________________________________________________________________________________
batch_normalization_137 (BatchN (None, 8, 8, 192)    576         conv2d_137[0][0]                 
__________________________________________________________________________________________________
batch_normalization_142 (BatchN (None, 8, 8, 192)    576         conv2d_142[0][0]                 
__________________________________________________________________________________________________
batch_normalization_143 (BatchN (None, 8, 8, 192)    576         conv2d_143[0][0]                 
__________________________________________________________________________________________________
activation_134 (Activation)     (None, 8, 8, 192)    0           batch_normalization_134[0][0]    
__________________________________________________________________________________________________
activation_137 (Activation)     (None, 8, 8, 192)    0           batch_normalization_137[0][0]    
__________________________________________________________________________________________________
activation_142 (Activation)     (None, 8, 8, 192)    0           batch_normalization_142[0][0]    
__________________________________________________________________________________________________
activation_143 (Activation)     (None, 8, 8, 192)    0           batch_normalization_143[0][0]    
__________________________________________________________________________________________________
mixed5 (Concatenate)            (None, 8, 8, 768)    0           activation_134[0][0]             
                                                                 activation_137[0][0]             
                                                                 activation_142[0][0]             
                                                                 activation_143[0][0]             
__________________________________________________________________________________________________
conv2d_148 (Conv2D)             (None, 8, 8, 160)    122880      mixed5[0][0]                     
__________________________________________________________________________________________________
batch_normalization_148 (BatchN (None, 8, 8, 160)    480         conv2d_148[0][0]                 
__________________________________________________________________________________________________
activation_148 (Activation)     (None, 8, 8, 160)    0           batch_normalization_148[0][0]    
__________________________________________________________________________________________________
conv2d_149 (Conv2D)             (None, 8, 8, 160)    179200      activation_148[0][0]             
__________________________________________________________________________________________________
batch_normalization_149 (BatchN (None, 8, 8, 160)    480         conv2d_149[0][0]                 
__________________________________________________________________________________________________
activation_149 (Activation)     (None, 8, 8, 160)    0           batch_normalization_149[0][0]    
__________________________________________________________________________________________________
conv2d_145 (Conv2D)             (None, 8, 8, 160)    122880      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_150 (Conv2D)             (None, 8, 8, 160)    179200      activation_149[0][0]             
__________________________________________________________________________________________________
batch_normalization_145 (BatchN (None, 8, 8, 160)    480         conv2d_145[0][0]                 
__________________________________________________________________________________________________
batch_normalization_150 (BatchN (None, 8, 8, 160)    480         conv2d_150[0][0]                 
__________________________________________________________________________________________________
activation_145 (Activation)     (None, 8, 8, 160)    0           batch_normalization_145[0][0]    
__________________________________________________________________________________________________
activation_150 (Activation)     (None, 8, 8, 160)    0           batch_normalization_150[0][0]    
__________________________________________________________________________________________________
conv2d_146 (Conv2D)             (None, 8, 8, 160)    179200      activation_145[0][0]             
__________________________________________________________________________________________________
conv2d_151 (Conv2D)             (None, 8, 8, 160)    179200      activation_150[0][0]             
__________________________________________________________________________________________________
batch_normalization_146 (BatchN (None, 8, 8, 160)    480         conv2d_146[0][0]                 
__________________________________________________________________________________________________
batch_normalization_151 (BatchN (None, 8, 8, 160)    480         conv2d_151[0][0]                 
__________________________________________________________________________________________________
activation_146 (Activation)     (None, 8, 8, 160)    0           batch_normalization_146[0][0]    
__________________________________________________________________________________________________
activation_151 (Activation)     (None, 8, 8, 160)    0           batch_normalization_151[0][0]    
__________________________________________________________________________________________________
average_pooling2d_14 (AveragePo (None, 8, 8, 768)    0           mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_144 (Conv2D)             (None, 8, 8, 192)    147456      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_147 (Conv2D)             (None, 8, 8, 192)    215040      activation_146[0][0]             
__________________________________________________________________________________________________
conv2d_152 (Conv2D)             (None, 8, 8, 192)    215040      activation_151[0][0]             
__________________________________________________________________________________________________
conv2d_153 (Conv2D)             (None, 8, 8, 192)    147456      average_pooling2d_14[0][0]       
__________________________________________________________________________________________________
batch_normalization_144 (BatchN (None, 8, 8, 192)    576         conv2d_144[0][0]                 
__________________________________________________________________________________________________
batch_normalization_147 (BatchN (None, 8, 8, 192)    576         conv2d_147[0][0]                 
__________________________________________________________________________________________________
batch_normalization_152 (BatchN (None, 8, 8, 192)    576         conv2d_152[0][0]                 
__________________________________________________________________________________________________
batch_normalization_153 (BatchN (None, 8, 8, 192)    576         conv2d_153[0][0]                 
__________________________________________________________________________________________________
activation_144 (Activation)     (None, 8, 8, 192)    0           batch_normalization_144[0][0]    
__________________________________________________________________________________________________
activation_147 (Activation)     (None, 8, 8, 192)    0           batch_normalization_147[0][0]    
__________________________________________________________________________________________________
activation_152 (Activation)     (None, 8, 8, 192)    0           batch_normalization_152[0][0]    
__________________________________________________________________________________________________
activation_153 (Activation)     (None, 8, 8, 192)    0           batch_normalization_153[0][0]    
__________________________________________________________________________________________________
mixed6 (Concatenate)            (None, 8, 8, 768)    0           activation_144[0][0]             
                                                                 activation_147[0][0]             
                                                                 activation_152[0][0]             
                                                                 activation_153[0][0]             
__________________________________________________________________________________________________
conv2d_158 (Conv2D)             (None, 8, 8, 192)    147456      mixed6[0][0]                     
__________________________________________________________________________________________________
batch_normalization_158 (BatchN (None, 8, 8, 192)    576         conv2d_158[0][0]                 
__________________________________________________________________________________________________
activation_158 (Activation)     (None, 8, 8, 192)    0           batch_normalization_158[0][0]    
__________________________________________________________________________________________________
conv2d_159 (Conv2D)             (None, 8, 8, 192)    258048      activation_158[0][0]             
__________________________________________________________________________________________________
batch_normalization_159 (BatchN (None, 8, 8, 192)    576         conv2d_159[0][0]                 
__________________________________________________________________________________________________
activation_159 (Activation)     (None, 8, 8, 192)    0           batch_normalization_159[0][0]    
__________________________________________________________________________________________________
conv2d_155 (Conv2D)             (None, 8, 8, 192)    147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_160 (Conv2D)             (None, 8, 8, 192)    258048      activation_159[0][0]             
__________________________________________________________________________________________________
batch_normalization_155 (BatchN (None, 8, 8, 192)    576         conv2d_155[0][0]                 
__________________________________________________________________________________________________
batch_normalization_160 (BatchN (None, 8, 8, 192)    576         conv2d_160[0][0]                 
__________________________________________________________________________________________________
activation_155 (Activation)     (None, 8, 8, 192)    0           batch_normalization_155[0][0]    
__________________________________________________________________________________________________
activation_160 (Activation)     (None, 8, 8, 192)    0           batch_normalization_160[0][0]    
__________________________________________________________________________________________________
conv2d_156 (Conv2D)             (None, 8, 8, 192)    258048      activation_155[0][0]             
__________________________________________________________________________________________________
conv2d_161 (Conv2D)             (None, 8, 8, 192)    258048      activation_160[0][0]             
__________________________________________________________________________________________________
batch_normalization_156 (BatchN (None, 8, 8, 192)    576         conv2d_156[0][0]                 
__________________________________________________________________________________________________
batch_normalization_161 (BatchN (None, 8, 8, 192)    576         conv2d_161[0][0]                 
__________________________________________________________________________________________________
activation_156 (Activation)     (None, 8, 8, 192)    0           batch_normalization_156[0][0]    
__________________________________________________________________________________________________
activation_161 (Activation)     (None, 8, 8, 192)    0           batch_normalization_161[0][0]    
__________________________________________________________________________________________________
average_pooling2d_15 (AveragePo (None, 8, 8, 768)    0           mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_154 (Conv2D)             (None, 8, 8, 192)    147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_157 (Conv2D)             (None, 8, 8, 192)    258048      activation_156[0][0]             
__________________________________________________________________________________________________
conv2d_162 (Conv2D)             (None, 8, 8, 192)    258048      activation_161[0][0]             
__________________________________________________________________________________________________
conv2d_163 (Conv2D)             (None, 8, 8, 192)    147456      average_pooling2d_15[0][0]       
__________________________________________________________________________________________________
batch_normalization_154 (BatchN (None, 8, 8, 192)    576         conv2d_154[0][0]                 
__________________________________________________________________________________________________
batch_normalization_157 (BatchN (None, 8, 8, 192)    576         conv2d_157[0][0]                 
__________________________________________________________________________________________________
batch_normalization_162 (BatchN (None, 8, 8, 192)    576         conv2d_162[0][0]                 
__________________________________________________________________________________________________
batch_normalization_163 (BatchN (None, 8, 8, 192)    576         conv2d_163[0][0]                 
__________________________________________________________________________________________________
activation_154 (Activation)     (None, 8, 8, 192)    0           batch_normalization_154[0][0]    
__________________________________________________________________________________________________
activation_157 (Activation)     (None, 8, 8, 192)    0           batch_normalization_157[0][0]    
__________________________________________________________________________________________________
activation_162 (Activation)     (None, 8, 8, 192)    0           batch_normalization_162[0][0]    
__________________________________________________________________________________________________
activation_163 (Activation)     (None, 8, 8, 192)    0           batch_normalization_163[0][0]    
__________________________________________________________________________________________________
mixed7 (Concatenate)            (None, 8, 8, 768)    0           activation_154[0][0]             
                                                                 activation_157[0][0]             
                                                                 activation_162[0][0]             
                                                                 activation_163[0][0]             
__________________________________________________________________________________________________
conv2d_166 (Conv2D)             (None, 8, 8, 192)    147456      mixed7[0][0]                     
__________________________________________________________________________________________________
batch_normalization_166 (BatchN (None, 8, 8, 192)    576         conv2d_166[0][0]                 
__________________________________________________________________________________________________
activation_166 (Activation)     (None, 8, 8, 192)    0           batch_normalization_166[0][0]    
__________________________________________________________________________________________________
conv2d_167 (Conv2D)             (None, 8, 8, 192)    258048      activation_166[0][0]             
__________________________________________________________________________________________________
batch_normalization_167 (BatchN (None, 8, 8, 192)    576         conv2d_167[0][0]                 
__________________________________________________________________________________________________
activation_167 (Activation)     (None, 8, 8, 192)    0           batch_normalization_167[0][0]    
__________________________________________________________________________________________________
conv2d_164 (Conv2D)             (None, 8, 8, 192)    147456      mixed7[0][0]                     
__________________________________________________________________________________________________
conv2d_168 (Conv2D)             (None, 8, 8, 192)    258048      activation_167[0][0]             
__________________________________________________________________________________________________
batch_normalization_164 (BatchN (None, 8, 8, 192)    576         conv2d_164[0][0]                 
__________________________________________________________________________________________________
batch_normalization_168 (BatchN (None, 8, 8, 192)    576         conv2d_168[0][0]                 
__________________________________________________________________________________________________
activation_164 (Activation)     (None, 8, 8, 192)    0           batch_normalization_164[0][0]    
__________________________________________________________________________________________________
activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_168[0][0]    
__________________________________________________________________________________________________
conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             
__________________________________________________________________________________________________
conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             
__________________________________________________________________________________________________
batch_normalization_165 (BatchN (None, 3, 3, 320)    960         conv2d_165[0][0]                 
__________________________________________________________________________________________________
batch_normalization_169 (BatchN (None, 3, 3, 192)    576         conv2d_169[0][0]                 
__________________________________________________________________________________________________
activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_165[0][0]    
__________________________________________________________________________________________________
activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_169[0][0]    
__________________________________________________________________________________________________
max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     
__________________________________________________________________________________________________
mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             
                                                                 activation_169[0][0]             
                                                                 max_pooling2d_7[0][0]            
__________________________________________________________________________________________________
conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_174 (BatchN (None, 3, 3, 448)    1344        conv2d_174[0][0]                 
__________________________________________________________________________________________________
activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_174[0][0]    
__________________________________________________________________________________________________
conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             
__________________________________________________________________________________________________
batch_normalization_171 (BatchN (None, 3, 3, 384)    1152        conv2d_171[0][0]                 
__________________________________________________________________________________________________
batch_normalization_175 (BatchN (None, 3, 3, 384)    1152        conv2d_175[0][0]                 
__________________________________________________________________________________________________
activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_171[0][0]    
__________________________________________________________________________________________________
activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_175[0][0]    
__________________________________________________________________________________________________
conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             
__________________________________________________________________________________________________
conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             
__________________________________________________________________________________________________
conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             
__________________________________________________________________________________________________
conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             
__________________________________________________________________________________________________
average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 
__________________________________________________________________________________________________
batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 
__________________________________________________________________________________________________
batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 
__________________________________________________________________________________________________
batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 
__________________________________________________________________________________________________
conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       
__________________________________________________________________________________________________
batch_normalization_170 (BatchN (None, 3, 3, 320)    960         conv2d_170[0][0]                 
__________________________________________________________________________________________________
activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    
__________________________________________________________________________________________________
activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    
__________________________________________________________________________________________________
activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    
__________________________________________________________________________________________________
activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    
__________________________________________________________________________________________________
batch_normalization_178 (BatchN (None, 3, 3, 192)    576         conv2d_178[0][0]                 
__________________________________________________________________________________________________
activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_170[0][0]    
__________________________________________________________________________________________________
mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             
                                                                 activation_173[0][0]             
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             
                                                                 activation_177[0][0]             
__________________________________________________________________________________________________
activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_178[0][0]    
__________________________________________________________________________________________________
mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             
                                                                 mixed9_0[0][0]                   
                                                                 concatenate_2[0][0]              
                                                                 activation_178[0][0]             
__________________________________________________________________________________________________
conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_183 (BatchN (None, 3, 3, 448)    1344        conv2d_183[0][0]                 
__________________________________________________________________________________________________
activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_183[0][0]    
__________________________________________________________________________________________________
conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             
__________________________________________________________________________________________________
batch_normalization_180 (BatchN (None, 3, 3, 384)    1152        conv2d_180[0][0]                 
__________________________________________________________________________________________________
batch_normalization_184 (BatchN (None, 3, 3, 384)    1152        conv2d_184[0][0]                 
__________________________________________________________________________________________________
activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_180[0][0]    
__________________________________________________________________________________________________
activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_184[0][0]    
__________________________________________________________________________________________________
conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             
__________________________________________________________________________________________________
conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             
__________________________________________________________________________________________________
conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             
__________________________________________________________________________________________________
conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             
__________________________________________________________________________________________________
average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 
__________________________________________________________________________________________________
batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 
__________________________________________________________________________________________________
batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 
__________________________________________________________________________________________________
batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 
__________________________________________________________________________________________________
conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       
__________________________________________________________________________________________________
batch_normalization_179 (BatchN (None, 3, 3, 320)    960         conv2d_179[0][0]                 
__________________________________________________________________________________________________
activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    
__________________________________________________________________________________________________
activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    
__________________________________________________________________________________________________
activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    
__________________________________________________________________________________________________
activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    
__________________________________________________________________________________________________
batch_normalization_187 (BatchN (None, 3, 3, 192)    576         conv2d_187[0][0]                 
__________________________________________________________________________________________________
activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_179[0][0]    
__________________________________________________________________________________________________
mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             
                                                                 activation_182[0][0]             
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             
                                                                 activation_186[0][0]             
__________________________________________________________________________________________________
activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_187[0][0]    
__________________________________________________________________________________________________
mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             
                                                                 mixed9_1[0][0]                   
                                                                 concatenate_3[0][0]              
                                                                 activation_187[0][0]             
==================================================================================================
Total params: 21,802,784
Trainable params: 0
Non-trainable params: 21,802,784
__________________________________________________________________________________________________
None
</pre></div>
<div class="outline-4" id="outline-container-org038bbcd">
<h4 id="org038bbcd">Add The End Layers</h4>
<div class="outline-text-4" id="text-org038bbcd">
<div class="highlight">
<pre><span></span>global_average_layer = tensorflow.keras.layers.GlobalAveragePooling2D()
feature_batch_average = global_average_layer(feature_batch)
print(feature_batch_average.shape)
</pre></div>
<pre class="example">
(32, 2048)
</pre>
<div class="highlight">
<pre><span></span>prediction_layer = keras.layers.Dense(1)
prediction_batch = prediction_layer(feature_batch_average)
print(prediction_batch.shape)
</pre></div>
<pre class="example">
(32, 1)
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org25be516">
<h3 id="org25be516">The Model</h3>
<div class="outline-text-3" id="text-org25be516">
<div class="highlight">
<pre><span></span>model = tensorflow.keras.Sequential([
    base_model,
    global_average_layer,
    prediction_layer,
])
</pre></div>
</div>
<div class="outline-4" id="outline-container-org5df96e6">
<h4 id="org5df96e6">Compile it</h4>
<div class="outline-text-4" id="text-org5df96e6">
<div class="highlight">
<pre><span></span>base_learning_rate = 0.0001
model.compile(optimizer=tensorflow.keras.optimizers.RMSprop(lr=base_learning_rate),
              loss="binary_crossentropy",
              metrics=["accuracy"])
print(model.summary())
</pre></div>
<pre class="example" id="orgc2a6ef9">
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
inception_v3 (Model)         (None, 3, 3, 2048)        21802784  
_________________________________________________________________
global_average_pooling2d_2 ( (None, 2048)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 2049      
=================================================================
Total params: 21,804,833
Trainable params: 2,049
Non-trainable params: 21,802,784
_________________________________________________________________
None
</pre>
<div class="highlight">
<pre><span></span>print(len(model.trainable_variables))
</pre></div>
<pre class="example">
2
</pre>
<p>The two trainable variables are the <i>weights</i> and the <i>biases</i>.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org07e13c7">
<h3 id="org07e13c7">Train the Model</h3>
<div class="outline-text-3" id="text-org07e13c7">
<div class="highlight">
<pre><span></span>number_train, number_val, number_test = (
    metadata.splits["train"].num_examples * weight / 10
    for weight in SPLIT_WEIGHTS
)
</pre></div>
<div class="highlight">
<pre><span></span>epochs = 10
steps_per_epoch = round(number_train)//BATCH_SIZE
validation_steps = 20

loss, accuracy = model.evaluate(validation_batches, steps = validation_steps)
print(f"Starting Loss: {loss:.2f}")
print(f"Starting Accuracy: {accuracy:.2f}")
</pre></div>
<pre class="example">

 1/20 [&gt;.............................] - ETA: 38s - loss: 4.4074 - accuracy: 0.6875
 2/20 [==&gt;...........................] - ETA: 18s - loss: 4.9268 - accuracy: 0.6250
 3/20 [===&gt;..........................] - ETA: 12s - loss: 4.8930 - accuracy: 0.6458
 4/20 [=====&gt;........................] - ETA: 8s - loss: 5.0363 - accuracy: 0.6328 
 5/20 [======&gt;.......................] - ETA: 6s - loss: 5.0895 - accuracy: 0.6375
 6/20 [========&gt;.....................] - ETA: 5s - loss: 5.0549 - accuracy: 0.6406
 7/20 [=========&gt;....................] - ETA: 4s - loss: 5.1643 - accuracy: 0.6384
 8/20 [===========&gt;..................] - ETA: 3s - loss: 5.5128 - accuracy: 0.6094
 9/20 [============&gt;.................] - ETA: 3s - loss: 5.6081 - accuracy: 0.6007
10/20 [==============&gt;...............] - ETA: 2s - loss: 5.4980 - accuracy: 0.6031
11/20 [===============&gt;..............] - ETA: 2s - loss: 5.4492 - accuracy: 0.6023
12/20 [=================&gt;............] - ETA: 1s - loss: 5.2914 - accuracy: 0.6120
13/20 [==================&gt;...........] - ETA: 1s - loss: 5.2644 - accuracy: 0.6130
14/20 [====================&gt;.........] - ETA: 1s - loss: 5.3703 - accuracy: 0.6094
15/20 [=====================&gt;........] - ETA: 0s - loss: 5.4075 - accuracy: 0.6042
16/20 [=======================&gt;......] - ETA: 0s - loss: 5.4311 - accuracy: 0.6055
17/20 [========================&gt;.....] - ETA: 0s - loss: 5.4268 - accuracy: 0.6066
18/20 [==========================&gt;...] - ETA: 0s - loss: 5.4514 - accuracy: 0.6042
19/20 [===========================&gt;..] - ETA: 0s - loss: 5.4500 - accuracy: 0.6053
20/20 [==============================] - 3s 154ms/step - loss: 5.4252 - accuracy: 0.6047
Starting Loss: 5.43
Starting Accuracy: 0.60
</pre>
<div class="highlight">
<pre><span></span>history = model.fit(train_batches, 
                    epochs=epochs, 
                    validation_data=validation_batches,
                    verbose=2,
)
</pre></div>
<pre class="example" id="org87d354a">
Epoch 1/10
582/582 - 73s - loss: 1.9513 - accuracy: 0.6666 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00
Epoch 2/10
582/582 - 70s - loss: 1.2932 - accuracy: 0.7352 - val_loss: 0.9332 - val_accuracy: 0.9164
Epoch 3/10
582/582 - 70s - loss: 1.0500 - accuracy: 0.7730 - val_loss: 0.9082 - val_accuracy: 0.9241
Epoch 4/10
582/582 - 67s - loss: 0.9344 - accuracy: 0.7945 - val_loss: 0.7346 - val_accuracy: 0.9358
Epoch 5/10
582/582 - 70s - loss: 0.8509 - accuracy: 0.8076 - val_loss: 0.7172 - val_accuracy: 0.9375
Epoch 6/10
582/582 - 69s - loss: 0.7973 - accuracy: 0.8178 - val_loss: 0.6902 - val_accuracy: 0.9414
Epoch 7/10
582/582 - 70s - loss: 0.7563 - accuracy: 0.8268 - val_loss: 0.6368 - val_accuracy: 0.9457
Epoch 8/10
582/582 - 69s - loss: 0.7063 - accuracy: 0.8374 - val_loss: 0.6246 - val_accuracy: 0.9453
Epoch 9/10
582/582 - 69s - loss: 0.6833 - accuracy: 0.8444 - val_loss: 0.5738 - val_accuracy: 0.9474
Epoch 10/10
582/582 - 66s - loss: 0.6503 - accuracy: 0.8490 - val_loss: 0.5956 - val_accuracy: 0.9483
</pre>
<div class="highlight">
<pre><span></span>MODELS = Path("~/models/dogs-vs-cats/").expanduser()
checkpoint = tensorflow.keras.callbacks.ModelCheckpoint(
    str(MODELS/"mobilenet_transfer.hdf5"), monitor="val_acc", verbose=1, 
    save_best_only=True)
model.fit(train_batches, 
          epochs=epochs, 
          validation_data=validation_batches, 
          verbose=2, 
          callbacks=[checkpoint])
</pre></div>
<pre class="example" id="org3ba55a1">
Epoch 1/10
W0804 20:23:10.072212 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 64s - loss: 0.6035 - accuracy: 0.8511 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00
Epoch 2/10
W0804 20:24:19.531489 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 69s - loss: 0.5911 - accuracy: 0.8553 - val_loss: 0.5240 - val_accuracy: 0.9522
Epoch 3/10
W0804 20:25:24.658446 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 65s - loss: 0.5786 - accuracy: 0.8586 - val_loss: 0.5165 - val_accuracy: 0.9526
Epoch 4/10
W0804 20:26:31.952232 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 67s - loss: 0.5733 - accuracy: 0.8615 - val_loss: 0.5058 - val_accuracy: 0.9504
Epoch 5/10
W0804 20:27:38.677954 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 67s - loss: 0.5645 - accuracy: 0.8622 - val_loss: 0.5139 - val_accuracy: 0.9509
Epoch 6/10
W0804 20:28:34.189206 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 55s - loss: 0.5542 - accuracy: 0.8645 - val_loss: 0.5474 - val_accuracy: 0.9517
Epoch 7/10
W0804 20:29:28.300311 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 54s - loss: 0.5419 - accuracy: 0.8652 - val_loss: 0.5432 - val_accuracy: 0.9517
Epoch 8/10
W0804 20:30:23.016782 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 55s - loss: 0.5280 - accuracy: 0.8680 - val_loss: 0.5235 - val_accuracy: 0.9517
Epoch 9/10
W0804 20:31:20.244823 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 57s - loss: 0.5184 - accuracy: 0.8680 - val_loss: 0.5358 - val_accuracy: 0.9513
Epoch 10/10
W0804 20:32:22.545533 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 62s - loss: 0.5123 - accuracy: 0.8700 - val_loss: 0.5312 - val_accuracy: 0.9526
</pre>
<div class="highlight">
<pre><span></span>model.fit(train_batches, 
          epochs=epochs, 
          validation_data=validation_batches, 
          verbose=2, 
          callbacks=[checkpoint])
</pre></div>
<pre class="example" id="orgfc5eb8a">
Epoch 1/10
W0804 21:21:53.728024 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 55s - loss: 0.5080 - accuracy: 0.8709 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00
Epoch 2/10
W0804 21:22:51.354294 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 58s - loss: 0.5037 - accuracy: 0.8726 - val_loss: 0.5471 - val_accuracy: 0.9522
Epoch 3/10
W0804 21:23:49.173404 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 58s - loss: 0.4991 - accuracy: 0.8744 - val_loss: 0.5406 - val_accuracy: 0.9530
Epoch 4/10
W0804 21:24:43.631767 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 54s - loss: 0.4928 - accuracy: 0.8748 - val_loss: 0.5449 - val_accuracy: 0.9522
Epoch 5/10
W0804 21:25:44.675879 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 61s - loss: 0.4900 - accuracy: 0.8764 - val_loss: 0.5528 - val_accuracy: 0.9517
Epoch 6/10
W0804 21:26:56.251078 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 72s - loss: 0.4834 - accuracy: 0.8774 - val_loss: 0.5698 - val_accuracy: 0.9496
Epoch 7/10
W0804 21:28:04.352257 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 68s - loss: 0.4778 - accuracy: 0.8792 - val_loss: 0.5532 - val_accuracy: 0.9491
Epoch 8/10
W0804 21:29:14.626469 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 70s - loss: 0.4751 - accuracy: 0.8803 - val_loss: 0.5537 - val_accuracy: 0.9500
Epoch 9/10
W0804 21:30:28.570089 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 74s - loss: 0.4721 - accuracy: 0.8796 - val_loss: 0.5479 - val_accuracy: 0.9496
Epoch 10/10
W0804 21:31:40.674842 140458756540224 callbacks.py:986] Can save best model only with val_acc available, skipping.
582/582 - 72s - loss: 0.4718 - accuracy: 0.8799 - val_loss: 0.5544 - val_accuracy: 0.9496
</pre>
<div class="highlight">
<pre><span></span>data = pandas.DataFrame(model.history.history)
print(data.val_accuracy.max())
</pre></div>
<pre class="example">
0.9530172348022461
</pre>
<p>So it looks like we max-out at around 96% - not much better than our five-layer model, but we reached it much faster.</p>
<div class="highlight">
<pre><span></span>plot = data.hvplot().opts(
    title="Transfer Learning Performance",
    height=800,
    width=1000
)
Embed(plot=plot, file_name="performance_1")()
</pre></div>
<object data="performance_1.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object></div>
</div>
</div>
<div class="outline-2" id="outline-container-orgc4e5ac6">
<h2 id="orgc4e5ac6">End</h2>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/cnn/index.html" rel="tag">cnn</a></li>
<li><a class="tag p-category" href="../../../categories/keras/index.html" rel="tag">keras</a></li>
<li><a class="tag p-category" href="../../../categories/tensorflow/index.html" rel="tag">tensorflow</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../dogs-vs-cats-with-transfer-learning/index.html" rel="prev" title="Dogs Vs Cats With Transfer Learning">Previous post</a></li>
<li class="next"><a href="../horse-or-human-using-tensorflow-20/index.html" rel="next" title="Horse Or Human Using TensorFlow 2.0">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Scribbles by <a href="mailto:cloisteredmonkey.jmark@slmail.me">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>
<div id="license" xmlns:cc="http://creativecommons.org/ns#">This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" rel="license noopener noreferrer" style="display:inline-block;" target="_blank">CC BY 4.0 <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></div>
</footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
