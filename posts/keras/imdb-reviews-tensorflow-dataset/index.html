<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Using the Tensorflow IMDB Reviews data-set to train a Single-Layer LSTM Model." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>IMDB Reviews Tensorflow Dataset | In Too Deep</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<script async src="../../../assets/javascript/bokeh-1.3.4.min.js" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="/posts/keras/bbc-news-classification/" rel="prev" title="BBC News Classification" type="text/html">
<link href="/posts/keras/multi-layer-lstm/" rel="next" title="Multi-Layer LSTM" type="text/html">
<meta content="In Too Deep" property="og:site_name">
<meta content="IMDB Reviews Tensorflow Dataset" property="og:title">
<meta content="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/" property="og:url">
<meta content="Using the Tensorflow IMDB Reviews data-set to train a Single-Layer LSTM Model." property="og:description">
<meta content="article" property="og:type">
<meta content="2019-09-09T16:24:46-07:00" property="article:published_time">
<meta content="nlp" property="article:tag">
<meta content="sentiment" property="article:tag">
<meta content="tensorflow" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/In-Too-Deep/"><span id="blog-title">In Too Deep</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/In-Too-Deep/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="/posts/keras/imdb-reviews-tensorflow-dataset/index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="/posts/keras/imdb-reviews-tensorflow-dataset/">IMDB Reviews Tensorflow Dataset</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/keras/imdb-reviews-tensorflow-dataset/" rel="bookmark"><time class="published dt-published" datetime="2019-09-09T16:24:46-07:00" itemprop="datePublished" title="2019-09-09 16:24">2019-09-09 16:24</time></a></p>
<p class="sourceline"><a class="sourcelink" href="/posts/keras/imdb-reviews-tensorflow-dataset/index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org8fbfa99">Beginning</a>
<ul>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org57b4c0c">Imports</a>
<ul>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org5031863">Python</a></li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org7112ec7">PyPi</a></li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org6043e04">Graeae</a></li>
</ul>
</li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org1c3a4cc">Set Up</a>
<ul>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org32ac284">Plotting</a></li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org9ddfee5">Timer</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org46583a7">Middle</a>
<ul>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#orgdd5f87d">Get the Dataset</a>
<ul>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org8fa174d">Load It</a></li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org7f6f438">Split It</a></li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org808a294">The Tokenizer</a></li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#orgba55015">Set Up Data</a></li>
</ul>
</li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org0d2ed39">The Model</a>
<ul>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org99ac84a">Compile It</a></li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org3ed7a59">Train It</a></li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org8f0e54f">Plot the Performance</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org360dae3">End</a>
<ul>
<li><a href="/posts/keras/imdb-reviews-tensorflow-dataset/#org9efad09">Citation</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org8fbfa99">
<h2 id="org8fbfa99">Beginning</h2>
<div class="outline-text-2" id="text-org8fbfa99">
<p>We're going to use the <a href="https://www.tensorflow.org/datasets/catalog/imdb_reviews">IMDB Reviews Dataset</a> (used in <a href="https://www.tensorflow.org/tutorials/keras/basic_text_classification">this tutorial</a>) - a set of 50,000 movie reviews taken from the <a href="https://www.imdb.com/">Internet Movie Database</a> that have been classified as either positive or negative. It looks like the original source is from a page on Stanford University's web sight title <a href="http://ai.stanford.edu/~amaas/data/sentiment/">Large Movie Review Dataset</a>. The dataset seems to be widely available (the Stanford page and <a href="https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews">Kaggle</a> for instance) but this will serve as practice for using tensorflow datasets as well.</p>
</div>
<div class="outline-3" id="outline-container-org57b4c0c">
<h3 id="org57b4c0c">Imports</h3>
<div class="outline-text-3" id="text-org57b4c0c"></div>
<div class="outline-4" id="outline-container-org5031863">
<h4 id="org5031863">Python</h4>
<div class="outline-text-4" id="text-org5031863">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org7112ec7">
<h4 id="org7112ec7">PyPi</h4>
<div class="outline-text-4" id="text-org7112ec7">
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
<span class="kn">import</span> <span class="nn">tensorflow_datasets</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6043e04">
<h4 id="org6043e04">Graeae</h4>
<div class="outline-text-4" id="text-org6043e04">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org1c3a4cc">
<h3 id="org1c3a4cc">Set Up</h3>
<div class="outline-text-3" id="text-org1c3a4cc"></div>
<div class="outline-4" id="outline-container-org32ac284">
<h4 id="org32ac284">Plotting</h4>
<div class="outline-text-4" id="text-org32ac284">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"imdb-reviews-tensorflow-dataset"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">f</span><span class="s2">"../../files/posts/keras/{SLUG}"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org9ddfee5">
<h4 id="org9ddfee5">Timer</h4>
<div class="outline-text-4" id="text-org9ddfee5">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org46583a7">
<h2 id="org46583a7">Middle</h2>
<div class="outline-text-2" id="text-org46583a7"></div>
<div class="outline-3" id="outline-container-orgdd5f87d">
<h3 id="orgdd5f87d">Get the Dataset</h3>
<div class="outline-text-3" id="text-orgdd5f87d"></div>
<div class="outline-4" id="outline-container-org8fa174d">
<h4 id="org8fa174d">Load It</h4>
<div class="outline-text-4" id="text-org8fa174d">
<p>The <a href="https://www.tensorflow.org/datasets/api_docs/python/tfds/load">load</a> function takes quite a few parameters, in this case we're just passing in three - the name of the dataset, <code>with_info</code> which tells it to return both a <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset">Dataset</a> and a <a href="https://www.tensorflow.org/datasets/api_docs/python/tfds/core/DatasetInfo">DatasetInfo</a> object, and <code>as_supervised</code>, which tells the builder to return the <code>Dataset</code> as a series of <code>(input, label)</code> tuples.</p>
<div class="highlight">
<pre><span></span><span class="n">dataset</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">tensorflow_datasets</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'imdb_reviews/subwords8k'</span><span class="p">,</span>
                                         <span class="n">with_info</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                         <span class="n">as_supervised</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org7f6f438">
<h4 id="org7f6f438">Split It</h4>
<div class="outline-text-4" id="text-org7f6f438">
<p>The <code>dataset</code> is a dict with three keys:</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
<pre class="example">
dict_keys(['test', 'train', 'unsupervised'])
</pre>
<p>As you might guess, we don't use the <code>unsupervised</code> key.</p>
<div class="highlight">
<pre><span></span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">'train'</span><span class="p">],</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">'test'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org808a294">
<h4 id="org808a294">The Tokenizer</h4>
<div class="outline-text-4" id="text-org808a294">
<p>One of the advantages of using the tensorflow dataset version of this is that it comes with a pre-built tokenizer inside the DatasetInfo object.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
</pre></div>
<pre class="example">
FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'text': Text(shape=(None,), dtype=tf.int64, encoder=&lt;SubwordTextEncoder vocab_size=8185&gt;),
})
</pre>
<div class="highlight">
<pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span><span class="o">.</span><span class="n">encoder</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
</pre></div>
<pre class="example">
&lt;SubwordTextEncoder vocab_size=8185&gt;
</pre>
<p>The <code>tokenizer</code> is a <a href="https://www.tensorflow.org/datasets/api_docs/python/tfds/features/text/SubwordTextEncoder">SubwordTextEncoder</a> with a vocabulary size of 8,185.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgba55015">
<h4 id="orgba55015">Set Up Data</h4>
<div class="outline-text-4" id="text-orgba55015">
<p>We're going to shuffle the training data and then add padding to both sets so theyre all the same size.</p>
<div class="highlight">
<pre><span></span><span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">padded_batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">output_shapes</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">padded_batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">output_shapes</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org0d2ed39">
<h3 id="org0d2ed39">The Model</h3>
<div class="outline-text-3" id="text-org0d2ed39">
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
    <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">)),</span>
    <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
    <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
<pre class="example">
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 64)          523840    
_________________________________________________________________
bidirectional (Bidirectional (None, 128)               66048     
_________________________________________________________________
dense (Dense)                (None, 64)                8256      
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 65        
=================================================================
Total params: 598,209
Trainable params: 598,209
Non-trainable params: 0
_________________________________________________________________
</pre></div>
<div class="outline-4" id="outline-container-org99ac84a">
<h4 id="org99ac84a">Compile It</h4>
<div class="outline-text-4" id="text-org99ac84a">
<div class="highlight">
<pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3ed7a59">
<h4 id="org3ed7a59">Train It</h4>
<div class="outline-text-4" id="text-org3ed7a59">
<div class="highlight">
<pre><span></span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">SILENT</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">ONCE_PER_EPOCH</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
                        <span class="n">validation_data</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="n">ONCE_PER_EPOCH</span><span class="p">)</span>
</pre></div>
<pre class="example">
2019-09-21 15:52:50,469 graeae.timers.timer start: Started: 2019-09-21 15:52:50.469787
I0921 15:52:50.469841 140086305412928 timer.py:70] Started: 2019-09-21 15:52:50.469787
Epoch 1/10
391/391 - 80s - loss: 0.3991 - accuracy: 0.8377 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00
Epoch 2/10
391/391 - 80s - loss: 0.3689 - accuracy: 0.8571 - val_loss: 0.4595 - val_accuracy: 0.8021
Epoch 3/10
391/391 - 80s - loss: 0.3664 - accuracy: 0.8444 - val_loss: 0.5262 - val_accuracy: 0.7228
Epoch 4/10
391/391 - 80s - loss: 0.5611 - accuracy: 0.7133 - val_loss: 0.6832 - val_accuracy: 0.6762
Epoch 5/10
391/391 - 80s - loss: 0.6151 - accuracy: 0.6597 - val_loss: 0.5164 - val_accuracy: 0.7844
Epoch 6/10
391/391 - 80s - loss: 0.3842 - accuracy: 0.8340 - val_loss: 0.4970 - val_accuracy: 0.7996
Epoch 7/10
391/391 - 80s - loss: 0.2449 - accuracy: 0.9058 - val_loss: 0.3639 - val_accuracy: 0.8463
Epoch 8/10
391/391 - 80s - loss: 0.1896 - accuracy: 0.9306 - val_loss: 0.3698 - val_accuracy: 0.8614
Epoch 9/10
391/391 - 80s - loss: 0.1555 - accuracy: 0.9456 - val_loss: 0.3896 - val_accuracy: 0.8535
Epoch 10/10
391/391 - 80s - loss: 0.1195 - accuracy: 0.9606 - val_loss: 0.4878 - val_accuracy: 0.8428
2019-09-21 16:06:09,935 graeae.timers.timer end: Ended: 2019-09-21 16:06:09.935707
I0921 16:06:09.935745 140086305412928 timer.py:77] Ended: 2019-09-21 16:06:09.935707
2019-09-21 16:06:09,938 graeae.timers.timer end: Elapsed: 0:13:19.465920
I0921 16:06:09.938812 140086305412928 timer.py:78] Elapsed: 0:13:19.465920
</pre></div>
</div>
<div class="outline-4" id="outline-container-org8f0e54f">
<h4 id="org8f0e54f">Plot the Performance</h4>
<div class="outline-text-4" id="text-org8f0e54f">
<ul class="org-ul">
<li><b>Note</b>: This only works if your kernel is on the local machine, running it remotely gives an error, as it tries to save it on the remote machine.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">"loss"</span><span class="p">:</span> <span class="s2">"Training Loss"</span><span class="p">,</span>
                            <span class="s2">"accuracy"</span><span class="p">:</span> <span class="s2">"Training Accuracy"</span><span class="p">,</span>
                            <span class="s2">"val_loss"</span><span class="p">:</span> <span class="s2">"Validation Loss"</span><span class="p">,</span>
                            <span class="s2">"val_accuracy"</span><span class="p">:</span> <span class="s2">"Validation Accuracy"</span><span class="p">})</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">()</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"LSTM IMDB Performance"</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
<span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"model_performance"</span><span class="p">)()</span>
</pre></div>
<object data="/posts/keras/imdb-reviews-tensorflow-dataset/model_performance.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>It looks like I over-trained it, as the loss is getting high. (Also note that I used this notebook to troubleshoot so there was actually one extra epoch that isn't shown).</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org360dae3">
<h2 id="org360dae3">End</h2>
<div class="outline-text-2" id="text-org360dae3"></div>
<div class="outline-3" id="outline-container-org9efad09">
<h3 id="org9efad09">Citation</h3>
<div class="outline-text-3" id="text-org9efad09">
<p>This is the paper where the dataset was originally used.</p>
<ul class="org-ul">
<li>Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).</li>
</ul>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="/categories/nlp/" rel="tag">nlp</a></li>
<li><a class="tag p-category" href="/categories/sentiment/" rel="tag">sentiment</a></li>
<li><a class="tag p-category" href="/categories/tensorflow/" rel="tag">tensorflow</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="/posts/keras/bbc-news-classification/" rel="prev" title="BBC News Classification">Previous post</a></li>
<li class="next"><a href="/posts/keras/multi-layer-lstm/" rel="next" title="Multi-Layer LSTM">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents Â© 2020 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> 
</body>
</html>
