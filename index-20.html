<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Studies in Deep Learning." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Neurotic Networking (old posts, page 20) | Neurotic Networking</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/index-20.html" rel="canonical">
<link href="index-21.html" rel="prev" type="text/html">
<link href="index-19.html" rel="next" type="text/html"><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
<link href="apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="site.webmanifest" rel="manifest">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="."><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="rss.xml">RSS feed</a></li>
<li class="nav-item dropdown"><a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#">Monkey Pages</a>
<div class="dropdown-menu"><a class="dropdown-item" href="https://necromuralist.github.io/">The Cloistered Monkey</a> <a class="dropdown-item" href="https://necromuralist.github.io/Ape-Iron/">Ape Iron</a> <a class="dropdown-item" href="https://necromuralist.github.io/Bowling-For-Data/">Bowling For Data</a> <a class="dropdown-item" href="https://necromuralist.github.io/Beach-Pig-Thigh/">Beach-Pig Rump & Thigh</a> <a class="dropdown-item" href="https://necromuralist.github.io/Visions-Voices-Data/">Visions, Voices, Data</a></div>
</li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<div class="postindex">
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/neural-machine-translation-the-data/index.html">Neural Machine Translation: The Data</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/neural-machine-translation-the-data/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-02-14T14:53:32-08:00" itemprop="datePublished" title="2021-02-14 14:53">2021-02-14 14:53</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org81ef733">The Data</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#orgb6c60a4">Imports</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org0c75376">Middle</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#orgffc12c6">Loading the Data</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org5fc390b">The Training Data</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org6c6de33">The Evaluation Data</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org4aadf46">Tokenization and Formatting</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org3ab9842">Integer assigned as end-of-sentence (EOS)</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org653af60">Filter long sentences</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#orgb2bb8a5">tokenize & detokenize helper functions</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org2fd5dff">Bucketing</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#orgc761241">Bucketing to create streams of batches.</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org30b34a8">Exploring the data</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#orgbe6ee45">Bundle it Up</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#orgf878e04">Imports</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#orga56b83d">Constants</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org23ed8fb">Tokenizer/Detokenizer</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org2fa1b42">Tokenizer</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org99f4bfe">Detokenizer</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org39dec84">Data Generator</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org6deb728">Append End of Sentence</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org5e22ffc">Generator Function</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#orge3733a5">Batch Stream</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#org268365d">Try It Out</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/index.html#orgd5a80b5">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org81ef733">
<h2 id="org81ef733">The Data</h2>
<div class="outline-text-2" id="text-org81ef733">
<p>This is the first post in a series that will look at creating a Long-Short-Term-Memory (LSTM) model with attention for Machine Learning. The <a href="posts/nlp/neural-machine-translation/">previous post</a> was an overview that holds the links to all the posts in the series.</p>
</div>
<div class="outline-3" id="outline-container-orgb6c60a4">
<h3 id="orgb6c60a4">Imports</h3>
<div class="outline-text-3" id="text-orgb6c60a4">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">termcolor</span> <span class="kn">import</span> <span class="n">colored</span>

<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org0c75376">
<h2 id="org0c75376">Middle</h2>
<div class="outline-text-2" id="text-org0c75376"></div>
<div class="outline-3" id="outline-container-orgffc12c6">
<h3 id="orgffc12c6">Loading the Data</h3>
<div class="outline-text-3" id="text-orgffc12c6">
<p>Next, we will import the dataset we will use to train the model. If you are running out of space, you can just use a small dataset from <a href="http://opus.nlpl.eu/">Opus</a>, a growing collection of translated texts from the web. Particularly, we will get an English to German translation subset specified as <code>opus/medical</code> which has medical related texts. If storage is not an issue, you can opt to get a larger corpus such as the English to German translation dataset from <a href="https://paracrawl.eu/">ParaCrawl</a>, a large multi-lingual translation dataset created by the European Union. Both of these datasets are available via <a href="https://www.tensorflow.org/datasets">Tensorflow Datasets (TFDS)</a> and you can browse through the other available datasets <a href="https://www.tensorflow.org/datasets/catalog/overview">here</a>. As you'll see below, you can easily access this dataset from TFDS with <code>trax.data.TFDS</code>. The result is a python generator function yielding tuples. Use the <code>keys</code> argument to select what appears at which position in the tuple. For example, <code>keys=('en', 'de')</code> below will return pairs as (English sentence, German sentence).</p>
<p>The <a href="https://www.tensorflow.org/datasets/catalog/para_crawl#para_crawlende"><code>para_crawl/ende</code></a> dataset is 4.04 GiB while the <a href="https://www.tensorflow.org/datasets/catalog/opus#opusmedical_default_config"><code>opus/medical</code></a> dataset is 188.85 MiB.</p>
<p><b>Note:</b> Trying to download the ParaCrawl dataset using trax creates an out of resource error. You can try downloading the source from:</p>
<p><a href="https://s3.amazonaws.com/web-language-models/paracrawl/release4/en-de.bicleaner07.txt.gz">https://s3.amazonaws.com/web-language-models/paracrawl/release4/en-de.bicleaner07.txt.gz</a></p>
<p>Although I haven't figured out how to get it into the trax data yet so I'm sticking with the smaller data set.</p>
</div>
<div class="outline-4" id="outline-container-org5fc390b">
<h4 id="org5fc390b">The Training Data</h4>
<div class="outline-text-4" id="text-org5fc390b">
<p>The first time you run this it will download the dataset, after that it will just load it from the file.</p>
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/data/tensorflow/translation/"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>

<span class="n">data_set</span> <span class="o">=</span> <span class="s2">"opus/medical"</span>
<span class="c1"># data_set = "para_crawl/ende"</span>

<span class="n">train_stream_fn</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFDS</span><span class="p">(</span><span class="n">data_set</span><span class="p">,</span>
                                 <span class="n">data_dir</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
                                 <span class="n">keys</span><span class="o">=</span><span class="p">(</span><span class="s1">'en'</span><span class="p">,</span> <span class="s1">'de'</span><span class="p">),</span>
                                 <span class="n">eval_holdout_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                                 <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org90932e1">
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-6-fb62d04026f5&gt; in &lt;module&gt;
      4 # data_set = "para_crawl/ende"
      5 
----&gt; 6 train_stream_fn = trax.data.TFDS(data_set,
      7                                  data_dir=path,
      8                                  keys=('en', 'de'),

/usr/local/lib/python3.8/dist-packages/gin/config.py in gin_wrapper(*args, **kwargs)
   1067       scope_info = " in scope '{}'".format(scope_str) if scope_str else ''
   1068       err_str = err_str.format(name, fn_or_cls, scope_info)
-&gt; 1069       utils.augment_exception_message_and_reraise(e, err_str)
   1070 
   1071   return gin_wrapper

/usr/local/lib/python3.8/dist-packages/gin/utils.py in augment_exception_message_and_reraise(exception, message)
     39   proxy = ExceptionProxy()
     40   ExceptionProxy.__qualname__ = type(exception).__qualname__
---&gt; 41   raise proxy.with_traceback(exception.__traceback__) from None
     42 
     43 

/usr/local/lib/python3.8/dist-packages/gin/config.py in gin_wrapper(*args, **kwargs)
   1044 
   1045     try:
-&gt; 1046       return fn(*new_args, **new_kwargs)
   1047     except Exception as e:  # pylint: disable=broad-except
   1048       err_str = ''

/usr/local/lib/python3.8/dist-packages/gin/config.py in gin_wrapper(*args, **kwargs)
   1067       scope_info = " in scope '{}'".format(scope_str) if scope_str else ''
   1068       err_str = err_str.format(name, fn_or_cls, scope_info)
-&gt; 1069       utils.augment_exception_message_and_reraise(e, err_str)
   1070 
   1071   return gin_wrapper

/usr/local/lib/python3.8/dist-packages/gin/utils.py in augment_exception_message_and_reraise(exception, message)
     39   proxy = ExceptionProxy()
     40   ExceptionProxy.__qualname__ = type(exception).__qualname__
---&gt; 41   raise proxy.with_traceback(exception.__traceback__) from None
     42 
     43 

/usr/local/lib/python3.8/dist-packages/gin/config.py in gin_wrapper(*args, **kwargs)
   1044 
   1045     try:
-&gt; 1046       return fn(*new_args, **new_kwargs)
   1047     except Exception as e:  # pylint: disable=broad-except
   1048       err_str = ''

~/trax/trax/data/tf_inputs.py in TFDS(dataset_name, data_dir, tfds_preprocess_fn, keys, train, shuffle_train, host_id, n_hosts, eval_holdout_size)
    279   else:
    280     subsplit = None
--&gt; 281   (train_data, eval_data, _) = _train_and_eval_dataset(
    282       dataset_name, data_dir, eval_holdout_size,
    283       train_shuffle_files=shuffle_train, subsplit=subsplit)

~/trax/trax/data/tf_inputs.py in _train_and_eval_dataset(dataset_name, data_dir, eval_holdout_size, train_shuffle_files, eval_shuffle_files, subsplit)
    224   if eval_holdout_examples &gt; 0 or subsplit is not None:
    225     n_train = train_examples - eval_holdout_examples
--&gt; 226     train_start = int(n_train * subsplit[0])
    227     train_end = int(n_train * subsplit[1])
    228     if train_end - train_start &lt; 1:

TypeError: 'NoneType' object is not subscriptable
  In call to configurable 'TFDS' (&lt;function TFDS at 0x7f960c527280&gt;)
  In call to configurable 'TFDS' (&lt;function TFDS at 0x7f960c526f70&gt;)
</pre></div>
</div>
<div class="outline-4" id="outline-container-org6c6de33">
<h4 id="org6c6de33">The Evaluation Data</h4>
<div class="outline-text-4" id="text-org6c6de33">
<p>Since we already downloaded the data in the previous code-block, this will just load the evaluation set from the downloaded data.</p>
<div class="highlight">
<pre><span></span><span class="n">eval_stream_fn</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFDS</span><span class="p">(</span><span class="s1">'opus/medical'</span><span class="p">,</span>
                                <span class="n">data_dir</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
                                <span class="n">keys</span><span class="o">=</span><span class="p">(</span><span class="s1">'en'</span><span class="p">,</span> <span class="s1">'de'</span><span class="p">),</span>
                                <span class="n">eval_holdout_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                                <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p>Notice that TFDS returns a generator <b>function</b>, not a generator. This is because in Python, you cannot reset generators so you cannot go back to a previously yielded value. During deep learning training, you use Stochastic Gradient Descent and don't actually need to go back – but it is sometimes good to be able to do that, and that's where the functions come in. Let's print a a sample pair from our train and eval data. Notice that the raw output is represented in bytes (denoted by the <code>b'</code> prefix) and these will be converted to strings internally in the next steps.</p>
<div class="highlight">
<pre><span></span><span class="n">train_stream</span> <span class="o">=</span> <span class="n">train_stream_fn</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'train data (en, de) tuple:'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="nb">next</span><span class="p">(</span><span class="n">train_stream</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
<pre class="example">
[31mtrain data (en, de) tuple:[0m (b'Tel: +421 2 57 103 777\n', b'Tel: +421 2 57 103 777\n')

</pre>
<div class="highlight">
<pre><span></span><span class="n">eval_stream</span> <span class="o">=</span> <span class="n">eval_stream_fn</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'eval data (en, de) tuple:'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="nb">next</span><span class="p">(</span><span class="n">eval_stream</span><span class="p">))</span>
</pre></div>
<pre class="example">
[31meval data (en, de) tuple:[0m (b'Lutropin alfa Subcutaneous use.\n', b'Pulver zur Injektion Lutropin alfa Subkutane Anwendung\n')
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org4aadf46">
<h3 id="org4aadf46">Tokenization and Formatting</h3>
<div class="outline-text-3" id="text-org4aadf46">
<p>Now that we have imported our corpus, we will be preprocessing the sentences into a format that our model can accept. This will be composed of several steps:</p>
<p><b>Tokenizing the sentences using subword representations:</b> We want to represent each sentence as an array of integers instead of strings. For our application, we will use <b>subword</b> representations to tokenize our sentences. This is a common technique to avoid out-of-vocabulary words by allowing parts of words to be represented separately. For example, instead of having separate entries in your vocabulary for –"fear", "fearless", "fearsome", "some", and "less"–, you can simply store –"fear", "some", and "less"– then allow your tokenizer to combine these subwords when needed. This allows it to be more flexible so you won't have to save uncommon words explicitly in your vocabulary (e.g. <b>stylebender</b>, <b>nonce</b>, etc). Tokenizing is done with the `trax.data.Tokenize()` command and we have provided you the combined subword vocabulary for English and German (i.e. `ende_32k.subword`) retrieved from <a href="https://storage.googleapis.com/trax-ml/vocabs/ende_32k.subword">https://storage.googleapis.com/trax-ml/vocabs/ende_32k.subword</a> (I'm using the web-interface, but you could also just download it and put it in a directory).</p>
<div class="highlight">
<pre><span></span><span class="n">VOCAB_FILE</span> <span class="o">=</span> <span class="s1">'ende_32k.subword'</span>
<span class="n">VOCAB_DIR</span> <span class="o">=</span> <span class="s2">"gs://trax-ml/vocabs/"</span> <span class="c1"># google storage</span>

<span class="c1"># Tokenize the dataset.</span>
<span class="n">tokenized_train_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Tokenize</span><span class="p">(</span><span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">)(</span><span class="n">train_stream</span><span class="p">)</span>
<span class="n">tokenized_eval_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Tokenize</span><span class="p">(</span><span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">)(</span><span class="n">eval_stream</span><span class="p">)</span>
</pre></div>
<p><b>Append an end-of-sentence token to each sentence:</b> We will assign a token (i.e. in this case <code>1</code>) to mark the end of a sentence. This will be useful in inference/prediction so we'll know that the model has completed the translation.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org3ab9842">
<h3 id="org3ab9842">Integer assigned as end-of-sentence (EOS)</h3>
<div class="outline-text-3" id="text-org3ab9842">
<div class="highlight">
<pre><span></span><span class="n">EOS</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">append_eos</span><span class="p">(</span><span class="n">stream</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""helper to add end of sentence token to sentences in the stream</span>

<span class="sd">    Yields:</span>
<span class="sd">     next tuple of numpy arrays with EOS token added (inputs, targets)</span>
<span class="sd">    """</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="n">stream</span><span class="p">:</span>
        <span class="n">inputs_with_eos</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">EOS</span><span class="p">]</span>
        <span class="n">targets_with_eos</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">EOS</span><span class="p">]</span>
        <span class="k">yield</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs_with_eos</span><span class="p">),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">targets_with_eos</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">tokenized_train_stream</span> <span class="o">=</span> <span class="n">append_eos</span><span class="p">(</span><span class="n">tokenized_train_stream</span><span class="p">)</span>
<span class="n">tokenized_eval_stream</span> <span class="o">=</span> <span class="n">append_eos</span><span class="p">(</span><span class="n">tokenized_eval_stream</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org653af60">
<h4 id="org653af60">Filter long sentences</h4>
<div class="outline-text-4" id="text-org653af60">
<p>We will place a limit on the number of tokens per sentence to ensure we won't run out of memory. This is done with the <code>trax.data.FilterByLength()</code> method and you can see its syntax below.</p>
<p>Filter too long sentences to not run out of memory. length_keys=[0, 1] means we filter both English and German sentences, so both must not be longer that 256 tokens for training and 512 tokens for evaluation.</p>
<div class="highlight">
<pre><span></span><span class="n">filtered_train_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">FilterByLength</span><span class="p">(</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">length_keys</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])(</span><span class="n">tokenized_train_stream</span><span class="p">)</span>
<span class="n">filtered_eval_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">FilterByLength</span><span class="p">(</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">length_keys</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])(</span><span class="n">tokenized_eval_stream</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">filtered_train_stream</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Single tokenized example input:'</span><span class="p">,</span> <span class="s1">'red'</span> <span class="p">),</span> <span class="n">train_input</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Single tokenized example target:'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">train_target</span><span class="p">)</span>
</pre></div>
<pre class="example">
[31mSingle tokenized example input:[0m [ 2538  2248    30 12114 23184 16889     5     2 20852  6456 20592  5812
  3932    96  5178  3851    30  7891  3550 30650  4729   992     1]
[31mSingle tokenized example target:[0m [ 1872    11  3544    39  7019 17877 30432    23  6845    10 14222    47
  4004    18 21674     5 27467  9513   920   188 10630    18  3550 30650
  4729   992     1]
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb2bb8a5">
<h3 id="orgb2bb8a5">tokenize & detokenize helper functions</h3>
<div class="outline-text-3" id="text-orgb2bb8a5">
<p>Given any data set, you have to be able to map words to their indices, and indices to their words. The inputs and outputs to your trax models are usually tensors of numbers where each number corresponds to a word. If you were to process your data manually, you would have to make use of the following:</p>
<ul class="org-ul">
<li>word2Ind: a dictionary mapping the word to its index.</li>
<li>ind2Word: a dictionary mapping the index to its word.</li>
<li>word2Count: a dictionary mapping the word to the number of times it appears.</li>
<li>num_words: total number of words that have appeared.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">input_str</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
             <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">EOS</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">EOS</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Encodes a string to an array of integers</span>

<span class="sd">    Args:</span>
<span class="sd">       input_str: human-readable string to encode</span>
<span class="sd">       vocab_file: filename of the vocabulary text file</span>
<span class="sd">       vocab_dir: path to the vocabulary file</span>

<span class="sd">    Returns:</span>
<span class="sd">       tokenized version of the input string</span>
<span class="sd">    """</span>
    <span class="c1"># Use the trax.data.tokenize method. It takes streams and returns streams,</span>
    <span class="c1"># we get around it by making a 1-element stream with `iter`.</span>
    <span class="n">inputs</span> <span class="o">=</span>  <span class="nb">next</span><span class="p">(</span><span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="nb">iter</span><span class="p">([</span><span class="n">input_str</span><span class="p">]),</span>
                                      <span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">,</span>
                                      <span class="n">vocab_dir</span><span class="o">=</span><span class="n">vocab_dir</span><span class="p">))</span>

    <span class="c1"># Mark the end of the sentence with EOS</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">EOS</span><span class="p">]</span>

    <span class="c1"># Adding the batch dimension to the front of the shape</span>
    <span class="n">batch_inputs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">batch_inputs</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">detokenize</span><span class="p">(</span><span class="n">integers</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
               <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">vocab_dir</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">EOS</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">EOS</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Decodes an array of integers to a human readable string</span>

<span class="sd">    Args:</span>
<span class="sd">       integers: array of integers to decode</span>
<span class="sd">       vocab_file: filename of the vocabulary text file</span>
<span class="sd">       vocab_dir: path to the vocabulary file</span>

<span class="sd">    Returns:</span>
<span class="sd">       str: the decoded sentence.</span>
<span class="sd">    """</span>
    <span class="c1"># Remove the dimensions of size 1</span>
    <span class="n">integers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">integers</span><span class="p">))</span>

    <span class="c1"># Remove the EOS to decode only the original tokens</span>
    <span class="k">if</span> <span class="n">EOS</span> <span class="ow">in</span> <span class="n">integers</span><span class="p">:</span>
        <span class="n">integers</span> <span class="o">=</span> <span class="n">integers</span><span class="p">[:</span><span class="n">integers</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">EOS</span><span class="p">)]</span> 

    <span class="k">return</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">detokenize</span><span class="p">(</span><span class="n">integers</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">vocab_dir</span><span class="p">)</span>
</pre></div>
<p>Let's see how we might use these functions:</p>
<p>Detokenize an input-target pair of tokenized sentences</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Single detokenized example input:'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Single detokenized example target:'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">train_target</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
<pre class="example">
[31mSingle detokenized example input:[0m During treatment with olanzapine, adolescents gained significantly more weight compared with adults.

[31mSingle detokenized example target:[0m Während der Behandlung mit Olanzapin nahmen die Jugendlichen im Vergleich zu Erwachsenen signifikant mehr Gewicht zu.

</pre>
<p>Tokenize and detokenize a word that is not explicitly saved in the vocabulary file. See how it combines the subwords – 'hell' and 'o'– to form the word 'hello'.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s2">"tokenize('hello'): "</span><span class="p">,</span> <span class="s1">'green'</span><span class="p">),</span> <span class="n">tokenize</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s2">"detokenize([17332, 140, 1]): "</span><span class="p">,</span> <span class="s1">'green'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">([</span><span class="mi">17332</span><span class="p">,</span> <span class="mi">140</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">))</span>
</pre></div>
<pre class="example">
[32mtokenize('hello'): [0m [[17332   140     1]]
[32mdetokenize([17332, 140, 1]): [0m hello
</pre></div>
</div>
<div class="outline-3" id="outline-container-org2fd5dff">
<h3 id="org2fd5dff">Bucketing</h3>
<div class="outline-text-3" id="text-org2fd5dff">
<p>Bucketing the tokenized sentences is an important technique used to speed up training in NLP. Here is a <a href="https://medium.com/@rashmi.margani/how-to-speed-up-the-training-of-the-sequence-model-using-bucketing-techniques-9e302b0fd976">nice article describing it in detail</a> but the gist is very simple. Our inputs have variable lengths and you want to make these the same when batching groups of sentences together. One way to do that is to pad each sentence to the length of the longest sentence in the dataset. This might lead to some wasted computation though. For example, if there are multiple short sentences with just two tokens, do we want to pad these when the longest sentence is composed of a 100 tokens? Instead of padding with 0s to the maximum length of a sentence each time, we can group our tokenized sentences by length and bucket.</p>
<p>We batch the sentences with similar length together and only add minimal padding to make them have equal length (usually up to the nearest power of two). This allows us to waste less computation when processing padded sequences.</p>
<p>In Trax, it is implemented in the <a href="https://github.com/google/trax/blob/5fb8aa8c5cb86dabb2338938c745996d5d87d996/trax/supervised/inputs.py#L378">bucket_by_length</a> function.</p>
</div>
<div class="outline-4" id="outline-container-orgc761241">
<h4 id="orgc761241">Bucketing to create streams of batches.</h4>
<div class="outline-text-4" id="text-orgc761241">
<p>Buckets are defined in terms of boundaries and batch sizes. Batch_sizes[i] determines the batch size for items with length &lt; boundaries[i]. So below, we'll take a batch of 256 sentences of length &lt; 8, 128 if length is between 8 and 16, and so on – and only 2 if length is over 512. We'll do the bucketing using <a href="https://trax-ml.readthedocs.io/en/latest/trax.data.html?highlight=bucket_by_length#trax.data.inputs.bucket_by_length">bucket_by_length</a>.</p>
<div class="highlight">
<pre><span></span><span class="n">boundaries</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">power_of_two</span> <span class="k">for</span> <span class="n">power_of_two</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="n">batch_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">power_of_two</span> <span class="k">for</span> <span class="n">power_of_two</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
</pre></div>
<p>Create the generators.</p>
<div class="highlight">
<pre><span></span><span class="n">train_batch_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">BucketByLength</span><span class="p">(</span>
    <span class="n">boundaries</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span>
    <span class="n">length_keys</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># As before: count inputs and targets to length.</span>
<span class="p">)(</span><span class="n">filtered_train_stream</span><span class="p">)</span>

<span class="n">eval_batch_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">BucketByLength</span><span class="p">(</span>
    <span class="n">boundaries</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span>
    <span class="n">length_keys</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">)(</span><span class="n">filtered_eval_stream</span><span class="p">)</span>
</pre></div>
<p>Add masking for the padding (0s) using <a href="https://trax-ml.readthedocs.io/en/latest/trax.data.html">add_loss_weights</a> (we're using <code>AddLossWeights</code> but the documentation for that just says "see add_loss_weights"). I can't find any documentation for it, but I think the 0's are what BucketByLength uses for padding.</p>
<div class="highlight">
<pre><span></span><span class="n">train_batch_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AddLossWeights</span><span class="p">(</span><span class="n">id_to_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">train_batch_stream</span><span class="p">)</span>
<span class="n">eval_batch_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AddLossWeights</span><span class="p">(</span><span class="n">id_to_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">eval_batch_stream</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org30b34a8">
<h3 id="org30b34a8">Exploring the data</h3>
<div class="outline-text-3" id="text-org30b34a8">
<p>We will now be displaying some of our data. You will see that the functions defined above (i.e. <code>tokenize()</code> and <code>detokenize()</code>) do the same things you have been doing again and again throughout the specialization. We gave these so you can focus more on building the model from scratch. Let us first get the data generator and get one batch of the data.</p>
<div class="highlight">
<pre><span></span><span class="n">input_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">mask_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">train_batch_stream</span><span class="p">)</span>
</pre></div>
<p>Let's see the data type of a batch.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"input_batch data type: "</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">input_batch</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"target_batch data type: "</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">target_batch</span><span class="p">))</span>
</pre></div>
<pre class="example">
input_batch data type:  &lt;class 'numpy.ndarray'&gt;
target_batch data type:  &lt;class 'numpy.ndarray'&gt;
</pre>
<p>Let's see the shape of this particular batch (batch length, sentence length).</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"input_batch shape: "</span><span class="p">,</span> <span class="n">input_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"target_batch shape: "</span><span class="p">,</span> <span class="n">target_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
<pre class="example">
input_batch shape:  (32, 64)
target_batch shape:  (32, 64)
</pre>
<p>The <code>input_batch</code> and <code>target_batch</code> are Numpy arrays consisting of tokenized English sentences and German sentences respectively. These tokens will later be used to produce embedding vectors for each word in the sentence (so the embedding for a sentence will be a matrix). The number of sentences in each batch is usually a power of 2 for optimal computer memory usage.</p>
<p>We can now visually inspect some of the data. You can run the cell below several times to shuffle through the sentences. Just to note, while this is a standard data set that is used widely, it does have some known wrong translations. With that, let's pick a random sentence and print its tokenized representation.</p>
<p>Pick a random index less than the batch size.</p>
<div class="highlight">
<pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_batch</span><span class="p">))</span>
</pre></div>
<p>Use the index to grab an entry from the input and target batch.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE ENGLISH SENTENCE: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">input_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE TOKENIZED VERSION OF THE ENGLISH SENTENCE: </span><span class="se">\n</span><span class="s1"> '</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">input_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE GERMAN TRANSLATION: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">target_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE TOKENIZED VERSION OF THE GERMAN TRANSLATION: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">target_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgbf19d4f">
[31mTHIS IS THE ENGLISH SENTENCE: 
[0m Kidneys and urinary tract (no effects were found to be common); uncommon: blood in the urine, proteins in the urine, sugar in the urine; rare: urge to pass urine, kidney pain, passing urine frequently.
 

[31mTHIS IS THE TOKENIZED VERSION OF THE ENGLISH SENTENCE: 
 [0m [ 5381 17607  3093     8  8670  6086   105 19166     5    50   154  1743
   152  1103     9    32   568  8076 19124  6847    64  6196     6     4
  8670   510     2 13355   823     6     4  8670   510     2  4968     6
     4  8670   510   115  7227    64  7628     9  2685  8670   510     2
 12220  5509 12095     2 19632  8670   510  7326  3550 30650  4729   992
     1     0     0     0] 

[31mTHIS IS THE GERMAN TRANSLATION: 
[0m Harndrang, Nierenschmerzen, häufiges Wasserlassen.
 

[31mTHIS IS THE TOKENIZED VERSION OF THE GERMAN TRANSLATION: 
[0m [ 5135 14970  2920     2  6262  4594 27552    28     2 20052    33  3736
   530  3550 30650  4729   992     1     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0] 
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orgbe6ee45">
<h2 id="orgbe6ee45">Bundle it Up</h2>
<div class="outline-text-2" id="text-orgbe6ee45"></div>
<div class="outline-3" id="outline-container-orgf878e04">
<h3 id="orgf878e04">Imports</h3>
<div class="outline-text-3" id="text-orgf878e04">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orga56b83d">
<h3 id="orga56b83d">Constants</h3>
<div class="outline-text-3" id="text-orga56b83d">
<div class="highlight">
<pre><span></span><span class="n">DataDefaults</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"DataDefaults"</span><span class="p">,</span>
                          <span class="p">[</span><span class="s2">"path"</span><span class="p">,</span>
                           <span class="s2">"dataset"</span><span class="p">,</span>
                           <span class="s2">"keys"</span><span class="p">,</span>
                           <span class="s2">"evaluation_size"</span><span class="p">,</span>
                           <span class="s2">"end_of_sentence"</span><span class="p">,</span>
                           <span class="s2">"vocabulary_file"</span><span class="p">,</span>
                           <span class="s2">"vocabulary_path"</span><span class="p">,</span>
                           <span class="s2">"length_keys"</span><span class="p">,</span>
                           <span class="s2">"boundaries"</span><span class="p">,</span>
                           <span class="s2">"batch_sizes"</span><span class="p">,</span>
                           <span class="s2">"padding_token"</span><span class="p">])</span>

<span class="n">DEFAULTS</span> <span class="o">=</span> <span class="n">DataDefaults</span><span class="p">(</span>
    <span class="n">path</span><span class="o">=</span><span class="n">Path</span><span class="p">(</span><span class="s2">"~/data/tensorflow/translation/"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(),</span>
    <span class="n">dataset</span><span class="o">=</span><span class="s2">"opus/medical"</span><span class="p">,</span>
    <span class="n">keys</span><span class="o">=</span><span class="p">(</span><span class="s2">"en"</span><span class="p">,</span> <span class="s2">"de"</span><span class="p">),</span>
    <span class="n">evaluation_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">end_of_sentence</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vocabulary_file</span><span class="o">=</span><span class="s2">"ende_32k.subword"</span><span class="p">,</span>
    <span class="n">vocabulary_path</span><span class="o">=</span><span class="s2">"gs://trax-ml/vocabs/"</span><span class="p">,</span>
    <span class="n">length_keys</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">boundaries</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">power_of_two</span> <span class="k">for</span> <span class="n">power_of_two</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)],</span>
    <span class="n">batch_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">power_of_two</span> <span class="k">for</span> <span class="n">power_of_two</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)],</span>
    <span class="n">padding_token</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">MaxLength</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"MaxLength"</span><span class="p">,</span> <span class="s2">"train evaluate"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="n">MaxLength</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
<span class="n">END_OF_SENTENCE</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org23ed8fb">
<h3 id="org23ed8fb">Tokenizer/Detokenizer</h3>
<div class="outline-text-3" id="text-org23ed8fb"></div>
<div class="outline-4" id="outline-container-org2fa1b42">
<h4 id="org2fa1b42">Tokenizer</h4>
<div class="outline-text-4" id="text-org2fa1b42">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">input_str</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
             <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">end_of_sentence</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">end_of_sentence</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Encodes a string to an array of integers</span>

<span class="sd">    Args:</span>
<span class="sd">       input_str: human-readable string to encode</span>
<span class="sd">       vocab_file: filename of the vocabulary text file</span>
<span class="sd">       vocab_dir: path to the vocabulary file</span>
<span class="sd">       end_of_sentence: token for the end of sentence</span>
<span class="sd">    Returns:</span>
<span class="sd">       tokenized version of the input string</span>
<span class="sd">    """</span>
    <span class="c1"># The trax.data.tokenize method takes streams and returns streams,</span>
    <span class="c1"># we get around it by making a 1-element stream with `iter`.</span>
    <span class="n">inputs</span> <span class="o">=</span>  <span class="nb">next</span><span class="p">(</span><span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="nb">iter</span><span class="p">([</span><span class="n">input_str</span><span class="p">]),</span>
                                      <span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">,</span>
                                      <span class="n">vocab_dir</span><span class="o">=</span><span class="n">vocab_dir</span><span class="p">))</span>

    <span class="c1"># Mark the end of the sentence with EOS</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">end_of_sentence</span><span class="p">]</span>

    <span class="c1"># Adding the batch dimension to the front of the shape</span>
    <span class="n">batch_inputs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch_inputs</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org99f4bfe">
<h4 id="org99f4bfe">Detokenizer</h4>
<div class="outline-text-4" id="text-org99f4bfe">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">detokenize</span><span class="p">(</span><span class="n">integers</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
               <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">vocab_dir</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">end_of_sentence</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">end_of_sentence</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Decodes an array of integers to a human readable string</span>

<span class="sd">    Args:</span>
<span class="sd">       integers: array of integers to decode</span>
<span class="sd">       vocab_file: filename of the vocabulary text file</span>
<span class="sd">       vocab_dir: path to the vocabulary file</span>
<span class="sd">       end_of_sentence: token to mark the end of a sentence</span>
<span class="sd">    Returns:</span>
<span class="sd">       str: the decoded sentence.</span>
<span class="sd">    """</span>
    <span class="c1"># Remove the dimensions of size 1</span>
    <span class="n">integers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">integers</span><span class="p">))</span>

    <span class="c1"># Remove the EOS to decode only the original tokens</span>
    <span class="k">if</span> <span class="n">end_of_sentence</span> <span class="ow">in</span> <span class="n">integers</span><span class="p">:</span>
        <span class="n">integers</span> <span class="o">=</span> <span class="n">integers</span><span class="p">[:</span><span class="n">integers</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">end_of_sentence</span><span class="p">)]</span> 

    <span class="k">return</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">detokenize</span><span class="p">(</span><span class="n">integers</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">vocab_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org39dec84">
<h3 id="org39dec84">Data Generator</h3>
<div class="outline-text-3" id="text-org39dec84">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DataGenerator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Generates the streams of data</span>

<span class="sd">    Args:</span>
<span class="sd">     training: whether this generates training data or not</span>
<span class="sd">     path: path to the data set</span>
<span class="sd">     data_set: name of the data set (from tensorflow datasets)</span>
<span class="sd">     keys: the names of the data</span>
<span class="sd">     max_length: longest allowed set of tokens</span>
<span class="sd">     evaluation_fraction: how much of the data is saved for evaluation</span>
<span class="sd">     length_keys: keys (indexes) to use when setting length</span>
<span class="sd">     boundaries: upper limits for batch sizes</span>
<span class="sd">     batch_sizes: batch_size for each boundary</span>
<span class="sd">     padding_token: which token is used for padding</span>
<span class="sd">     vocabulary_file: name of the sub-words vocabulary file</span>
<span class="sd">     vocabulary_path: where to find the vocabulary file</span>
<span class="sd">     end_of_sentence: token to indicate the end of a sentence</span>
<span class="sd">    """</span>
    <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">path</span>
    <span class="n">data_set</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">dataset</span>
    <span class="n">keys</span><span class="p">:</span> <span class="nb">tuple</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">keys</span>
    <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="o">.</span><span class="n">train</span>
    <span class="n">length_keys</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">length_keys</span>
    <span class="n">boundaries</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">boundaries</span>
    <span class="n">batch_sizes</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">batch_sizes</span>
    <span class="n">evaluation_fraction</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">evaluation_size</span>
    <span class="n">vocabulary_file</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">vocabulary_file</span>
    <span class="n">vocabulary_path</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">vocabulary_path</span>
    <span class="n">padding_token</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">padding_token</span>
    <span class="n">end_of_sentence</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">end_of_sentence</span>
    <span class="n">_generator_function</span><span class="p">:</span> <span class="nb">type</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_batch_generator</span><span class="p">:</span> <span class="nb">type</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org6deb728">
<h4 id="org6deb728">Append End of Sentence</h4>
<div class="outline-text-4" id="text-org6deb728">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">end_of_sentence_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Generator that adds end of sentence tokens</span>

<span class="sd">    Args:</span>
<span class="sd">     original: generator to add the end of sentence tokens to</span>

<span class="sd">    Yields:</span>
<span class="sd">     next tuple of arrays with EOS token added</span>
<span class="sd">    """</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">original</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">end_of_sentence</span><span class="p">]</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">end_of_sentence</span><span class="p">]</span>
        <span class="k">yield</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
    <span class="k">return</span> 
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5e22ffc">
<h4 id="org5e22ffc">Generator Function</h4>
<div class="outline-text-4" id="text-org5e22ffc">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">generator_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Function to create the data generator"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_generator_function</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFDS</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_set</span><span class="p">,</span>
                                                  <span class="n">data_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">,</span>
                                                  <span class="n">keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">,</span>
                                                  <span class="n">eval_holdout_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">evaluation_fraction</span><span class="p">,</span>
                                                  <span class="n">train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator_function</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge3733a5">
<h4 id="orge3733a5">Batch Stream</h4>
<div class="outline-text-4" id="text-orge3733a5">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">batch_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""batch data generator"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_generator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator_function</span><span class="p">()</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Tokenize</span><span class="p">(</span>
            <span class="n">vocab_file</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_file</span><span class="p">,</span>
            <span class="n">vocab_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_path</span><span class="p">)(</span><span class="n">generator</span><span class="p">)</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_of_sentence_generator</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">FilterByLength</span><span class="p">(</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">length_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">length_keys</span><span class="p">)(</span><span class="n">generator</span><span class="p">)</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">BucketByLength</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">boundaries</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_sizes</span><span class="p">,</span>
            <span class="n">length_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">length_keys</span>
        <span class="p">)(</span><span class="n">generator</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_generator</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AddLossWeights</span><span class="p">(</span>
            <span class="n">id_to_mask</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_token</span><span class="p">)(</span><span class="n">generator</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_generator</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org268365d">
<h3 id="org268365d">Try It Out</h3>
<div class="outline-text-3" id="text-org268365d">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.machine_translation</span> <span class="kn">import</span> <span class="n">DataGenerator</span><span class="p">,</span> <span class="n">detokenize</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">()</span><span class="o">.</span><span class="n">batch_generator</span>
<span class="n">input_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">mask_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>


<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE ENGLISH SENTENCE: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">input_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE TOKENIZED VERSION OF THE ENGLISH SENTENCE: </span><span class="se">\n</span><span class="s1"> '</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">input_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE GERMAN TRANSLATION: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">target_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE TOKENIZED VERSION OF THE GERMAN TRANSLATION: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">target_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgbe84cbd">
[31mTHIS IS THE ENGLISH SENTENCE: 
[0m Signs of hypersensitivity reactions include hives, generalised urticaria, tightness of the chest, wheezing, hypotension and anaphylaxis.
 

[31mTHIS IS THE TOKENIZED VERSION OF THE ENGLISH SENTENCE: 
 [0m [10495    14     7 10224 19366 10991  1020  3481  2486     2  9547  7417
   103  4572 11927  9371     2 13197  1496     7     4 24489    62     2
 16402 24010   211     2  4814 23010 12122    22     8  4867 19606  6457
  5175    14  3550 30650  4729   992     1     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0] 

[31mTHIS IS THE GERMAN TRANSLATION: 
[0m Überempfindlichkeitsreaktionen können sich durch Anzeichen wie Nesselausschlag, generalisierte Urtikaria, Engegefühl im Brustkorb, Pfeifatmung, Blutdruckabfall und Anaphylaxie äußern.
 

[31mTHIS IS THE TOKENIZED VERSION OF THE GERMAN TRANSLATION: 
[0m [ 3916 29551 13504  5020  4094 13522   119    51   121  8602    93 31508
  6050 30327  6978     2  9547  7417  2446  5618  4581  5530  1384     2
 26006  7831 13651     5    47  8584  4076  5262   868     2 25389  8898
 28268     2  9208 29697 17944    83    12  9925 19606  6457 16384     5
 11790  3550 30650  4729   992     1     0     0     0     0     0     0
     0     0     0     0] 
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orgd5a80b5">
<h2 id="orgd5a80b5">End</h2>
<div class="outline-text-2" id="text-orgd5a80b5">
<p>Now that we have our data prepared it's time to move on to <a href="posts/nlp/neural-machine-translation-the-attention-model/">defining the Attention Model</a>.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/neural-machine-translation/index.html">Neural Machine Translation</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/neural-machine-translation/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-02-11T19:56:46-08:00" itemprop="datePublished" title="2021-02-11 19:56">2021-02-11 19:56</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/neural-machine-translation/index.html#orgb56754f">Neural Machine Translations</a></li>
<li><a href="posts/nlp/neural-machine-translation/index.html#orgfb9984f">The Posts</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgb56754f">
<h2 id="orgb56754f">Neural Machine Translations</h2>
<div class="outline-text-2" id="text-orgb56754f">
<p>Here, we will build an English-to-German neural machine translation (NMT) model using Long Short-Term Memory (LSTM) networks with attention. Machine translation is an important task in natural language processing and could be useful not only for translating one language to another but also for word sense disambiguation (e.g. determining whether the word "bank" refers to the financial bank, or the land alongside a river). Implementing this using just a Recurrent Neural Network (RNN) with LSTMs can work for short to medium length sentences but can result in vanishing gradients for very long sequences. To solve this, we will be adding an attention mechanism to allow the decoder to access all relevant parts of the input sentence regardless of its length. By completing this assignment, we will:</p>
<ul class="org-ul">
<li>learn how to preprocess your training and evaluation data</li>
<li>implement an encoder-decoder system with attention</li>
<li>understand how attention works</li>
<li>build the NMT model from scratch using Trax</li>
<li>generate translations using greedy and Minimum Bayes Risk (MBR) decoding</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgfb9984f">
<h2 id="orgfb9984f">The Posts</h2>
<div class="outline-text-2" id="text-orgfb9984f">
<p>This will be broken up into the following posts.</p>
<ul class="org-ul">
<li><a href="posts/nlp/neural-machine-translation-the-data/">The Data</a></li>
<li><a href="posts/nlp/neural-machine-translation-helper-functions/">Helper Functions</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-attention-model/">The Attention Model</a></li>
<li><a href="posts/nlp/neural-machine-translation-training-the-model/">Training the Model</a></li>
<li><a href="posts/nlp/neural-machine-translation-testing-the-model/">Testing the Model</a></li>
</ul>
<p>First - a <a href="posts/nlp/neural-machine-translation-the-data/">look at the data</a>.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/stack-semantics/index.html">Stack Semantics</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/stack-semantics/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-02-11T19:53:36-08:00" itemprop="datePublished" title="2021-02-11 19:53">2021-02-11 19:53</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/stack-semantics/index.html#org528ef6a">Stack Semantics in Trax</a>
<ul>
<li><a href="posts/nlp/stack-semantics/index.html#org72ddde5">Imports</a></li>
</ul>
</li>
<li><a href="posts/nlp/stack-semantics/index.html#org9a898e2">Middle</a>
<ul>
<li><a href="posts/nlp/stack-semantics/index.html#org3712f2e">The Serial Combinator is Stack Oriented.</a>
<ul>
<li><a href="posts/nlp/stack-semantics/index.html#org50bda6d">Defining addition</a></li>
<li><a href="posts/nlp/stack-semantics/index.html#org5d6b6a0">Defining multiplication</a></li>
<li><a href="posts/nlp/stack-semantics/index.html#orgfd9f4bc">Implementing the computations using the Serial combinator</a></li>
</ul>
</li>
<li><a href="posts/nlp/stack-semantics/index.html#org83af332">The tl.Select combinator in the context of the Serial combinator</a>
<ul>
<li><a href="posts/nlp/stack-semantics/index.html#orgc8d8306">First example of tl.Select</a></li>
<li><a href="posts/nlp/stack-semantics/index.html#org53e842f">Select Makes It More Like a Collection</a></li>
</ul>
</li>
<li><a href="posts/nlp/stack-semantics/index.html#orgcc2bf25">Another example of tl.Select</a></li>
<li><a href="posts/nlp/stack-semantics/index.html#orgd0da5a1">The tl.Residual combinator in the context of the Serial combinator</a>
<ul>
<li><a href="posts/nlp/stack-semantics/index.html#orgb0ff4a3">tl.Residual</a></li>
<li><a href="posts/nlp/stack-semantics/index.html#org9da1475">Modifying the network</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org528ef6a">
<h2 id="org528ef6a">Stack Semantics in Trax</h2>
<div class="outline-text-2" id="text-org528ef6a">
<p>This will help in understanding how to use layers like <code>Select</code> and <code>Residual</code> which operate on elements in the stack. If you've taken a computer science class before, you will recall that a stack is a data structure that follows the Last In, First Out (LIFO) principle. That is, whatever is the latest element that is pushed into the stack will also be the first one to be popped out. If you're not yet familiar with stacks, then you may find this <a href="https://www.tutorialspoint.com/python_data_structure/python_stack.htm">short tutorial</a> useful. In a nutshell, all you really need to remember is it puts elements one on top of the other. You should be aware of what is on top of the stack to know which element you will be popping.</p>
</div>
<div class="outline-3" id="outline-container-org72ddde5">
<h3 id="org72ddde5">Imports</h3>
<div class="outline-text-3" id="text-org72ddde5">
<div class="highlight">
<pre><span></span><span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">fastmath</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">shapes</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org9a898e2">
<h2 id="org9a898e2">Middle</h2>
<div class="outline-text-2" id="text-org9a898e2"></div>
<div class="outline-3" id="outline-container-org3712f2e">
<h3 id="org3712f2e">The Serial Combinator is Stack Oriented.</h3>
<div class="outline-text-3" id="text-org3712f2e">
<p>To understand how stack-orientation works in <a href="https://trax-ml.readthedocs.io/en/latest/">Trax</a>, most times one will be using the <code>Serial</code> layer. We will define two simple <a href="https://trax-ml.readthedocs.io/en/latest/notebooks/layers_intro.html?highlight=fn#With-the-Fn-layer-creating-function.">Function layers</a>:</p>
<ol class="org-ol">
<li>Addition</li>
<li>Multiplication</li>
</ol>
<p>Suppose we want to make the simple calculation \((3 + 4) \times 15 + 3\). We'll use <code>Serial</code> to perform the calculations in the following order <code>3</code> <code>4</code> <code>add</code> <code>15</code> <code>mul</code> <code>3</code> <code>add</code>. The steps of the calculation are shown in the table below.</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Stack Operations</th>
<th class="org-right" scope="col">Stack</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Push(4)</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">Push(3)</td>
<td class="org-right">4 3</td>
</tr>
<tr>
<td class="org-left">Push(Add Pop() Pop())</td>
<td class="org-right">7</td>
</tr>
<tr>
<td class="org-left">Push(15)</td>
<td class="org-right">7 15</td>
</tr>
<tr>
<td class="org-left">Push(Mul Pop() Pop())</td>
<td class="org-right">105</td>
</tr>
<tr>
<td class="org-left">Push(3)</td>
<td class="org-right">105 3</td>
</tr>
<tr>
<td class="org-left">Push(Add() Pop() Pop())</td>
<td class="org-right">108</td>
</tr>
</tbody>
</table>
<p>The first column shows the operations made on the stack and the second column is what's on the stack. Moreover, the rightmost element in the second column represents the top of the stack (e.g. in the second row, <code>Push(3)</code> pushes <code>3 = on top of the stack and =4</code> is now under it).</p>
<p>After finishing the steps the stack contains 108 which is the answer to our simple computation.</p>
<p>From this, the following can be concluded: a stack-based layer has only one way to handle data, by taking one piece of data from atop the stack, called <i>popping</i>, and putting data back atop the stack, called <i>pushing</i>. Any expression that can be written conventionally, can be written this way and thus will be amenable to being interpreted by a stack-oriented layer like <code>Serial</code>.</p>
</div>
<div class="outline-4" id="outline-container-org50bda6d">
<h4 id="org50bda6d">Defining addition</h4>
<div class="outline-text-4" id="text-org50bda6d">
<p>We're going to define a trax <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html?highlight=Fn#trax.layers.base.Fn">function (FN)</a> for addition.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">Addition</span><span class="p">():</span>
    <span class="n">layer_name</span> <span class="o">=</span> <span class="s2">"Addition"</span> 

    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>

    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="n">layer_name</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span>
</pre></div>
<p>Test it out.</p>
<div class="highlight">
<pre><span></span><span class="n">add</span> <span class="o">=</span> <span class="n">Addition</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">add</span><span class="p">))</span>
</pre></div>
<pre class="example">
&lt;class 'trax.layers.base.PureLayer'&gt;
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">add</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">add</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">add</span><span class="o">.</span><span class="n">n_out</span><span class="p">)</span>
</pre></div>
<pre class="example">
name : Addition
expected inputs : 2
promised outputs : 1
</pre>
<div class="highlight">
<pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">y</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">add</span><span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">))</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
[3] + [4] = [7]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org5d6b6a0">
<h4 id="org5d6b6a0">Defining multiplication</h4>
<div class="outline-text-4" id="text-org5d6b6a0">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">Multiplication</span><span class="p">():</span>
    <span class="n">layer_name</span> <span class="o">=</span> <span class="s2">"Multiplication"</span>

    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>

    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="n">layer_name</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span>
</pre></div>
<p>Test it out.</p>
<div class="highlight">
<pre><span></span><span class="n">mul</span> <span class="o">=</span> <span class="n">Multiplication</span><span class="p">()</span>
</pre></div>
<p>The properties.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">mul</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">mul</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">mul</span><span class="o">.</span><span class="n">n_out</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
name : Multiplication
expected inputs : 2
promised outputs : 1 

</pre>
<p>Some Inputs.</p>
<div class="highlight">
<pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">15</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"x :"</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"y :"</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
<pre class="example">
x : [7]
y : [15]
</pre>
<p>The Output</p>
<div class="highlight">
<pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">mul</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2"> * </span><span class="si">{</span><span class="n">y</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">mul</span><span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">))</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
[7] * [15] = [105]
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgfd9f4bc">
<h4 id="orgfd9f4bc">Implementing the computations using the Serial combinator</h4>
<div class="outline-text-4" id="text-orgfd9f4bc">
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">Addition</span><span class="p">(),</span> <span class="n">Multiplication</span><span class="p">(),</span> <span class="n">Addition</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">15</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">]))</span>

<span class="n">serial</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">shapes</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">serial</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"sublayers :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">sublayers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_out</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org07dedac">
Serial_in4[
  Addition_in2
  Multiplication_in2
  Addition_in2
] 

name : Serial
sublayers : [Addition_in2, Multiplication_in2, Addition_in2]
expected inputs : 4
promised outputs : 1 
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">inputs</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
(array([3]), array([4]), array([15]), array([3])) -&gt; [108]
</pre>
<p>The example with the two simple adition and multiplication functions that where coded together with the serial combinator show how stack semantics work in <code>Trax</code>.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org83af332">
<h3 id="org83af332">The tl.Select combinator in the context of the Serial combinator</h3>
<div class="outline-text-3" id="text-org83af332">
<p>Having understood how stack semantics work in <code>Trax</code>, we will demonstrate how the <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html?highlight=select#trax.layers.combinators.Select">tl.Select</a> combinator works.</p>
</div>
<div class="outline-4" id="outline-container-orgc8d8306">
<h4 id="orgc8d8306">First example of tl.Select</h4>
<div class="outline-text-4" id="text-orgc8d8306">
<p>Suppose we want to make the simple calculation \((3 + 4) \times 3 + 4\). We can use <code>Select</code> to perform the calculations in the following manner:</p>
<ol class="org-ol">
<li>input <code>3</code> <code>4</code></li>
<li><code>tl.Select([0, 1, 0, 1])</code></li>
<li><code>add</code></li>
<li><code>mul</code></li>
<li><code>add</code>.</li>
</ol>
<p>The <code>tl.Select</code> requires a list or tuple of 0-based indices to select elements relative to the top of the stack. For our example, the top of the stack is <code>3</code> (which is at index 0) then <code>4</code> (index 1) and we us Select to copy the top two elements of the stack and then push all four elements back onto the stack which after the command executes will now contain <code>3</code> <code>4</code> <code>3</code> <code>4</code>. The steps of the calculation for our example are shown in the table below. As in the previous table each column shows the contents of the stack and the outputs after the operations are carried out.</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Stack Operations</th>
<th class="org-left" scope="col">Stack</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Push(4)</td>
<td class="org-left">4</td>
</tr>
<tr>
<td class="org-left">Push(3)</td>
<td class="org-left">4 3</td>
</tr>
<tr>
<td class="org-left">Push(Select([0, 1, 0, 1]))</td>
<td class="org-left">4 3 4 3</td>
</tr>
<tr>
<td class="org-left">Push(Add Pop() Pop())</td>
<td class="org-left">4 3 7</td>
</tr>
<tr>
<td class="org-left">Push(Mul Pop() Pop())</td>
<td class="org-left">4 21</td>
</tr>
<tr>
<td class="org-left">Push(Add Pop() Pop())</td>
<td class="org-left">25</td>
</tr>
</tbody>
</table>
<p>After processing all the inputs the stack contains 25 which is the result of the calculations.</p>
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="n">Addition</span><span class="p">(),</span>
    <span class="n">Multiplication</span><span class="p">(),</span>
    <span class="n">Addition</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
<p>Now we'll create the input.</p>
<div class="highlight">
<pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">]))</span>
<span class="n">serial</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">shapes</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">serial</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"sublayers :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">sublayers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_out</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org44f75cf">
Serial_in2[
  Select[0,1,0,1]_in2_out4
  Addition_in2
  Multiplication_in2
  Addition_in2
] 

name : Serial
sublayers : [Select[0,1,0,1]_in2_out4, Addition_in2, Multiplication_in2, Addition_in2]
expected inputs : 2
promised outputs : 1 
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
(array([3]), array([4])) -&gt; [25]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org53e842f">
<h4 id="org53e842f">Select Makes It More Like a Collection</h4>
<div class="outline-text-4" id="text-org53e842f">
<p>Note that since you are passing in indices to Select, you aren't really using it like a stack, even if behind the scenes it's using push and pop.</p>
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
    <span class="n">Addition</span><span class="p">(),</span>
    <span class="n">Multiplication</span><span class="p">(),</span>
    <span class="n">Addition</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">]))</span>
<span class="n">serial</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">shapes</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
(array([3]), array([4]), array([5])) -&gt; [41]
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">((</span><span class="mi">5</span> <span class="o">+</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
<pre class="example">
41
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgcc2bf25">
<h3 id="orgcc2bf25">Another example of tl.Select</h3>
<div class="outline-text-3" id="text-orgcc2bf25">
<p>Suppose we want to make the simple calculation \((3 + 4) \times 4\). We can use <code>Select</code> to perform the calculations in the following manner:</p>
<ol class="org-ol">
<li><code>4</code></li>
<li><code>3</code></li>
<li><code>tl.Select([0,1,0,1])</code></li>
<li><code>add</code></li>
<li><code>tl.Select([0], n_in=2)</code></li>
<li><code>mul</code></li>
</ol>
<p>The example is a bit contrived but it demonstrates the flexibility of the command. The second <code>tl.Select</code> pops two elements (specified in n_in) from the stack starting from index 0 (i.e. top of the stack). This means that <code>7</code> and <code>3 = will be popped out because ~n_in = 2~) but only =7</code> is placed back on top because it only selects <code>[0]</code>. As in the previous table each column shows the contents of the stack and the outputs after the operations are carried out.</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Stack Operations</th>
<th class="org-left" scope="col">Outputs</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Push(4)</td>
<td class="org-left">4</td>
</tr>
<tr>
<td class="org-left">Push(3)</td>
<td class="org-left">4 3</td>
</tr>
<tr>
<td class="org-left">Push(select([0, 1, 0, 1]))</td>
<td class="org-left">4 3 4 3</td>
</tr>
<tr>
<td class="org-left">Push(Add Pop() Pop())</td>
<td class="org-left">4 3 7</td>
</tr>
<tr>
<td class="org-left">Push(select([0], n_in=2))</td>
<td class="org-left">7</td>
</tr>
<tr>
<td class="org-left">Push(Mul Pop() Pop())</td>
<td class="org-left">28</td>
</tr>
</tbody>
</table>
<p>After processing all the inputs the stack contains 28 which is the answer we get above.</p>
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="n">Addition</span><span class="p">(),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_in</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">Multiplication</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">]))</span>
<span class="n">serial</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">shapes</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">serial</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"sublayers :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">sublayers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_out</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org2c046e5">
Serial_in2[
  Select[0,1,0,1]_in2_out4
  Addition_in2
  Select[0]_in2
  Multiplication_in2
] 

name : Serial
sublayers : [Select[0,1,0,1]_in2_out4, Addition_in2, Select[0]_in2, Multiplication_in2]
expected inputs : 2
promised outputs : 1
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">inputs</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
(array([3]), array([4])) -&gt; [28]
</pre>
<p>In summary, what Select does in this example is make a copy of the inputs in order to be used further along in the stack of operations.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgd0da5a1">
<h3 id="orgd0da5a1">The tl.Residual combinator in the context of the Serial combinator</h3>
<div class="outline-text-3" id="text-orgd0da5a1"></div>
<div class="outline-4" id="outline-container-orgb0ff4a3">
<h4 id="orgb0ff4a3">tl.Residual</h4>
<div class="outline-text-4" id="text-orgb0ff4a3">
<p><a href="https://arxiv.org/pdf/1512.03385.pdf">Residual networks</a> (that link is to a research paper, this is <a href="https://en.wikipedia.org/wiki/Residual_neural_network">wikipedia</a>)are frequently used to make deep models easier to train. Trax already has a built in layer for this. The <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html?highlight=residual#trax.layers.combinators.Residual">Residual layer</a> computes the element-wise <b>sum</b> of the <b>stack-top</b> input with the output of the layer series. Let's first see how it is used in the code below:</p>
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Residual</span><span class="p">(</span><span class="n">Addition</span><span class="p">())</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">serial</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_out</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org3d62d03">
Serial_in2_out3[
  Select[0,1,0,1]_in2_out4
  Serial_in2[
    Branch_in2_out2[
      None
      Addition_in2
    ]
    Add_in2
  ]
] 

name : Serial
expected inputs : 2
promised outputs : 3
</pre>
<p>Here, we use the Serial combinator to define our model. The inputs first goes through a <code>Select</code> layer, followed by a <code>Residual</code> layer which passes the <code>Fn: Addition()</code> layer as an argument. What this means is the <code>Residual</code> layer will take the stack top input at that point and add it to the output of the <code>Fn: Addition()</code> layer. You can picture it like the diagram the below, where <code>x1</code> and <code>x2</code> are the inputs to the model:</p>
<p>Now, let's try running our model with some sample inputs and see the result:</p>
<div class="highlight">
<pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x1</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">x2</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">x2</span><span class="p">))</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
[3] + [4] -&gt; (array([10]), array([3]), array([4]))
</pre>
<p>As you can see, the <code>Residual</code> layer remembers the stack top input (i.e. <code>3</code>) and adds it to the result of the <code>Fn: Addition()</code> layer (i.e. <code>3 + 4 = 7</code>). The output of <code>Residual(Addition()</code> is then <code>3 + 7 = 10</code> and is pushed onto the stack.</p>
<p>On a different note, you'll notice that the <code>Select</code> layer has 4 outputs but the <code>Fn: Addition()</code> layer only pops 2 inputs from the stack. This means the duplicate inputs (i.e. the 2 rightmost arrows of the <code>Select</code> outputs in the figure above) remain in the stack. This is why you still see it in the output of our simple serial network (i.e. <code>array([3]), array([4])</code>). This is useful if you want to use these duplicate inputs in another layer further down the network.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org9da1475">
<h4 id="org9da1475">Modifying the network</h4>
<div class="outline-text-4" id="text-org9da1475">
<p>To strengthen your understanding, you can modify the network above and examine the outputs you get. For example, you can pass the <code>Fn: Multiplication()</code> layer instead in the <code>Residual</code> block:</p>
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> 
    <span class="n">layers</span><span class="o">.</span><span class="n">Residual</span><span class="p">(</span><span class="n">Multiplication</span><span class="p">())</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">serial</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_out</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org6a885ed">
Serial_in2_out3[
  Select[0,1,0,1]_in2_out4
  Serial_in2[
    Branch_in2_out2[
      None
      Multiplication_in2
    ]
    Add_in2
  ]
] 

name : Serial
expected inputs : 2
promised outputs : 3
</pre>
<p>This means you'll have a different output that will be added to the stack top input saved by the Residual block. The diagram becomes like this:</p>
<p>And you'll get <code>3 + (3 * 4) = 15</code> as output of the <code>Residual</code> block:</p>
<div class="highlight">
<pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">serial</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x1</span><span class="si">}</span><span class="s2"> * </span><span class="si">{</span><span class="n">x2</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">x2</span><span class="p">))</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
[3] * [4] -&gt; (array([15]), array([3]), array([4]))
</pre></div>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/bleu-score/index.html">Bleu Score</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/bleu-score/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-02-11T19:51:55-08:00" itemprop="datePublished" title="2021-02-11 19:51">2021-02-11 19:51</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/bleu-score/index.html#org5202ce2">Calculating the Bilingual Evaluation Understudy (BLEU) score</a>
<ul>
<li><a href="posts/nlp/bleu-score/index.html#org89c4e51">Imports</a></li>
<li><a href="posts/nlp/bleu-score/index.html#orgc969119">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/bleu-score/index.html#orgf0dfc4c">Middle</a>
<ul>
<li><a href="posts/nlp/bleu-score/index.html#orge702137">Part 1: BLEU Score</a>
<ul>
<li><a href="posts/nlp/bleu-score/index.html#org3a46363">Defining the BLEU Score</a></li>
<li><a href="posts/nlp/bleu-score/index.html#org85b8b10">Explaining the BLEU score</a></li>
<li><a href="posts/nlp/bleu-score/index.html#org02ff5ae">N-Gram Precision (example)</a></li>
<li><a href="posts/nlp/bleu-score/index.html#org5681c1c">N-gram BLEU score (example):</a></li>
<li><a href="posts/nlp/bleu-score/index.html#org918e153">Example Calculations of the BLEU score</a></li>
</ul>
</li>
<li><a href="posts/nlp/bleu-score/index.html#org905d8cc">Part 2: BLEU computation on a corpus</a>
<ul>
<li><a href="posts/nlp/bleu-score/index.html#org96ad6b6">Loading Data Sets for Evaluation Using the BLEU Score</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org5202ce2">
<h2 id="org5202ce2">Calculating the Bilingual Evaluation Understudy (BLEU) score</h2>
<div class="outline-text-2" id="text-org5202ce2">
<p>We will be implementing a popular metric for evaluating the quality of machine-translated text: the <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> score proposed by Kishore Papineni, et al. In their 2002 paper <a href="https://www.aclweb.org/anthology/P02-1040.pdf">"BLEU: a Method for Automatic Evaluation of Machine Translation"</a>, the BLEU score works by comparing "candidate" text to one or more "reference" translations. The result is better the closer the score is to 1. Let's see how to get this value in the following sections.</p>
</div>
<div class="outline-3" id="outline-container-org89c4e51">
<h3 id="org89c4e51">Imports</h3>
<div class="outline-text-3" id="text-org89c4e51">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">nltk.util</span> <span class="kn">import</span> <span class="n">ngrams</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">sacrebleu</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># my stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc969119">
<h3 id="orgc969119">Set Up</h3>
<div class="outline-text-3" id="text-orgc969119">
<div class="highlight">
<pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">'punkt'</span><span class="p">)</span>
<span class="n">slug</span> <span class="o">=</span> <span class="s2">"bleu-score"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">slug</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span> <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">])</span>
<span class="n">PLOT</span> <span class="o">=</span> <span class="n">Plot</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
 <span class="p">)</span>

<span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgf0dfc4c">
<h2 id="orgf0dfc4c">Middle</h2>
<div class="outline-text-2" id="text-orgf0dfc4c"></div>
<div class="outline-3" id="outline-container-orge702137">
<h3 id="orge702137">Part 1: BLEU Score</h3>
<div class="outline-text-3" id="text-orge702137">
<p>We will implement our own version of the BLEU Score using Numpy. To verify that our implementation is correct, we will compare our results with those generated by the <a href="https://github.com/mjpost/sacrebleu">SacreBLEU library</a>. This package provides hassle-free computation of shareable, comparable, and reproducible BLEU scores. It also knows all the standard test sets and handles downloading, processing, and tokenization.</p>
</div>
<div class="outline-4" id="outline-container-org3a46363">
<h4 id="org3a46363">Defining the BLEU Score</h4>
<div class="outline-text-4" id="text-org3a46363">
<p>We can express the BLEU score as:</p>
<p>\[ BLEU = BP\left(\prod_{i=1}^{4}precision_i\right)^{(1/4)} \]</p>
<p>with the <i>Brevity Penalty</i> and <i>precision</i> defined as:</p>
<p>\[ BP = min\left(1, e^{(1-(\textit{reference}/\textit{candidate}))}\right) \]</p>
<p>\[ precision_i = \frac {\sum_{snt \in{cand}}\sum_{i\in{snt}}min\Bigl(m^{i}_{cand}, m^{i}_{ref}\Bigr)}{w^{i}_{t}} \]</p>
<p>where:</p>
<ul class="org-ul">
<li>\(m^{i}_{cand}\), is the count of i-gram in candidate matching the reference translation.</li>
<li>\(m^{i}_{ref}\), is the count of i-gram in the reference translation.</li>
<li>\(w^{i}_{t}\), is the total number of i-grams in candidate translation.</li>
</ul>
</div>
</div>
<div class="outline-4" id="outline-container-org85b8b10">
<h4 id="org85b8b10">Explaining the BLEU score</h4>
<div class="outline-text-4" id="text-org85b8b10"></div>
<ul class="org-ul">
<li><a id="orgb2f325a"></a>Brevity Penalty (example)<br>
<div class="outline-text-5" id="text-orgb2f325a">
<div class="highlight">
<pre><span></span><span class="n">ref_length</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">can_length</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ref_length</span> <span class="o">/</span> <span class="n">can_length</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">x</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">brevity_penalty</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s2">"Reference Length/Candidate Length"</span><span class="p">:</span> <span class="n">x</span>
                                    <span class="p">,</span> <span class="s2">"Brevity Penalty"</span><span class="p">:</span> <span class="n">brevity_penalty</span><span class="p">})</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Reference Length/Candidate Length"</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="s2">"Brevity Penalty"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Brevity Penalty"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">fontscale</span>    
<span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"brevity_penalty"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/bleu-score/brevity_penalty.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>The <i>brevity penalty</i> penalizes generated translations that are too short compared to the closest reference length with an exponential decay. The brevity penalty compensates for the fact that the BLEU score has no recall term.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org02ff5ae">
<h4 id="org02ff5ae">N-Gram Precision (example)</h4>
<div class="outline-text-4" id="text-org02ff5ae">
<p>And now for a meaningless plot.</p>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s2">"1-gram"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">],</span>
                                   <span class="s2">"2-gram"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.7</span><span class="p">],</span>
                                   <span class="s2">"3-gram"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">],</span>
                                   <span class="s2">"4-gram"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]})</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"N-Gram Precision"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">fontscale</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"n_gram_precision"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/bleu-score/n_gram_precision.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>The n-gram precision counts how many unigrams, bigrams, trigrams, and four-grams (i=1,…,4) match their n-gram counterpart in the reference translations. This term acts as a precision metric. Unigrams account for adequacy while longer n-grams account for fluency of the translation. To avoid overcounting, the n-gram counts are clipped to the maximal n-gram count occurring in the reference (\(m_{n}^{ref}\)). Typically precision shows exponential decay with the with the degree of the n-gram.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org5681c1c">
<h4 id="org5681c1c">N-gram BLEU score (example):</h4>
<div class="outline-text-4" id="text-org5681c1c">
<p>Another meaningless plot.</p>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s2">"1-gram"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">],</span>
                                   <span class="s2">"2-gram"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.77</span><span class="p">],</span>
                                   <span class="s2">"3-gram"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.74</span><span class="p">],</span>
                                   <span class="s2">"4-gram"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.71</span><span class="p">]})</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Modified N-Gram Precision"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">fontscale</span>
<span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"modified_n_gram_precision"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/bleu-score/modified_n_gram_precision.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>When the n-gram precision is multiplied by the BP, then the exponential decay of n-grams is almost fully compensated. The BLEU score corresponds to a geometric average of this modified n-gram precision.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org918e153">
<h4 id="org918e153">Example Calculations of the BLEU score</h4>
<div class="outline-text-4" id="text-org918e153">
<p>In this example we will have a reference translation and 2 candidates translations. We will tokenize all sentences using the NLTK.</p>
</div>
<ul class="org-ul">
<li><a id="org9f16d64"></a>Step 1: Computing the Brevity Penalty<br>
<div class="outline-text-5" id="text-org9f16d64">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">brevity_penalty</span><span class="p">(</span><span class="n">candidate</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">reference</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Calculates the brevity penalty"""</span>
    <span class="n">reference_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">reference</span><span class="p">)</span>
    <span class="n">candidate_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidate</span><span class="p">)</span>

    <span class="c1"># Brevity Penalty</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">reference_length</span> <span class="o">&lt;</span> <span class="n">candidate_length</span> <span class="k">else</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">reference_length</span> <span class="o">/</span> <span class="n">candidate_length</span><span class="p">))</span>
</pre></div>
</div>
</li>
<li><a id="orgf3bdfa5"></a>Step 2: Computing the Precision<br>
<div class="outline-text-5" id="text-orgf3bdfa5">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">clipped_precision</span><span class="p">(</span><span class="n">candidate</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">reference</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Clipped precision function given a original and a machine translated sentences</span>
<span class="sd">    """</span>
    <span class="n">clipped_precision_score</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
        <span class="n">ref_n_gram</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">ngrams</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span><span class="n">i</span><span class="p">))</span>
        <span class="n">cand_n_gram</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">ngrams</span><span class="p">(</span><span class="n">candidate</span><span class="p">,</span><span class="n">i</span><span class="p">))</span>

        <span class="n">c</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">cand_n_gram</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">cand_n_gram</span><span class="p">:</span> <span class="c1"># for every n-gram up to 4 in candidate text</span>
            <span class="k">if</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">ref_n_gram</span><span class="p">:</span> <span class="c1"># check if it is in the reference n-gram</span>
                <span class="k">if</span> <span class="n">cand_n_gram</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">ref_n_gram</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span> <span class="c1"># if the count of the candidate n-gram is bigger</span>
                                                   <span class="c1"># than the corresponding count in the reference n-gram,</span>
                    <span class="n">cand_n_gram</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">ref_n_gram</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="c1"># then set the count of the candidate n-gram to be equal</span>
                                                   <span class="c1"># to the reference n-gram</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cand_n_gram</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># else set the candidate n-gram equal to zero</span>

        <span class="n">clipped_precision_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">cand_n_gram</span><span class="o">.</span><span class="n">values</span><span class="p">())</span><span class="o">/</span><span class="n">c</span><span class="p">)</span>

    <span class="n">weights</span> <span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span>

    <span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="n">w_i</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_i</span><span class="p">)</span> <span class="k">for</span> <span class="n">w_i</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">clipped_precision_score</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">fsum</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">s</span>
</pre></div>
</div>
</li>
<li><a id="orge37964a"></a>Step 3: Computing the BLEU score<br>
<div class="outline-text-5" id="text-orge37964a">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">bleu_score</span><span class="p">(</span><span class="n">candidate</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">reference</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="n">BP</span> <span class="o">=</span> <span class="n">brevity_penalty</span><span class="p">(</span><span class="n">candidate</span><span class="p">,</span> <span class="n">reference</span><span class="p">)</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">clipped_precision</span><span class="p">(</span><span class="n">candidate</span><span class="p">,</span> <span class="n">reference</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">BP</span> <span class="o">*</span> <span class="n">precision</span>
</pre></div>
</div>
</li>
<li><a id="org466a248"></a>Step 4: Testing with our Example Reference and Candidates Sentences<br>
<div class="outline-text-5" id="text-org466a248">
<div class="highlight">
<pre><span></span><span class="n">reference</span> <span class="o">=</span> <span class="s2">"The NASA Opportunity rover is battling a massive dust storm on planet Mars."</span>
<span class="n">candidate_1</span> <span class="o">=</span> <span class="s2">"The Opportunity rover is combating a big sandstorm on planet Mars."</span>
<span class="n">candidate_2</span> <span class="o">=</span> <span class="s2">"A NASA rover is fighting a massive storm on planet Mars."</span>

<span class="n">tokenized_ref</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">reference</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
<span class="n">tokenized_cand_1</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">candidate_1</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
<span class="n">tokenized_cand_2</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">candidate_2</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">"Results reference versus candidate 1 our own code BLEU: "</span><span class="p">,</span>
    <span class="nb">round</span><span class="p">(</span><span class="n">bleu_score</span><span class="p">(</span><span class="n">tokenized_cand_1</span><span class="p">,</span> <span class="n">tokenized_ref</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
<pre class="example">
Results reference versus candidate 1 our own code BLEU:  27.6
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">"Results reference versus candidate 2 our own code BLEU: "</span><span class="p">,</span>
    <span class="nb">round</span><span class="p">(</span><span class="n">bleu_score</span><span class="p">(</span><span class="n">tokenized_cand_2</span><span class="p">,</span> <span class="n">tokenized_ref</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
<pre class="example">
Results reference versus candidate 2 our own code BLEU:  35.3
</pre></div>
</li>
<li><a id="org0c96098"></a>Step 5: Comparing the Results from our Code with the SacreBLEU Library<br>
<div class="outline-text-5" id="text-org0c96098">
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">"Results reference versus candidate 1 sacrebleu library BLEU: "</span><span class="p">,</span>
    <span class="nb">round</span><span class="p">(</span><span class="n">sacrebleu</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">(</span><span class="n">candidate_1</span><span class="p">,</span> <span class="n">reference</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
<pre class="example">
Results reference versus candidate 1 sacrebleu library BLEU:  27.6
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">"Results reference versus candidate 2 sacrebleu library BLEU: "</span><span class="p">,</span>
    <span class="nb">round</span><span class="p">(</span><span class="n">sacrebleu</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">(</span><span class="n">candidate_2</span><span class="p">,</span> <span class="n">reference</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
<pre class="example">
Results reference versus candidate 2 sacrebleu library BLEU:  35.3
</pre></div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org905d8cc">
<h3 id="org905d8cc">Part 2: BLEU computation on a corpus</h3>
<div class="outline-text-3" id="text-org905d8cc"></div>
<div class="outline-4" id="outline-container-org96ad6b6">
<h4 id="org96ad6b6">Loading Data Sets for Evaluation Using the BLEU Score</h4>
<div class="outline-text-4" id="text-org96ad6b6">
<p>In this section, we will show a simple pipeline for evaluating machine translated text. Due to storage and speed constraints, we will not be using our own model in this lab. Instead, we will be using <a href="https://translate.google.com">Google Translate</a> to generate English to German translations and we will evaluate it against a known evaluation set. There are three files we will need:</p>
<ol class="org-ol">
<li>A source text in English. In this lab, we will use the first 1671 words of the <a href="http://statmt.org/wmt19/translation-task.html">wmt19</a> evaluation dataset downloaded via SacreBLEU. We just grabbed a subset because of limitations in the number of words that can be translated using Google Translate.</li>
<li>A reference translation to German of the corresponding first 1671 words from the original English text. This is also provided by SacreBLEU.</li>
<li>A candidate machine translation to German from the same 1671 words. This is generated by feeding the source text to a machine translation model. As mentioned above, we will use Google Translate to generate the translations in this file.</li>
</ol>
<p>With that, we can now compare the reference an candidate translation to get the BLEU Score.</p>
<p>Load the raw data.</p>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"WMT19_SOURCE"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">wmt19_src_1</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="k">with</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"WMT19_REFERENCE"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">wmt19_ref_1</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="k">with</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"WMT19_CANDIDATE"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">wmt19_can_1</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">tokenized_corpus_src</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">wmt19_src_1</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
<span class="n">tokenized_corpus_ref</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">wmt19_ref_1</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
<span class="n">tokenized_corpus_cand</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">wmt19_can_1</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>    
</pre></div>
<p>Inspecting the first sentence of the data.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"English source text:</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">wmt19_src_1</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">170</span><span class="p">]</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">tokenized_corpus_src</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">30</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"German reference translation:</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">wmt19_ref_1</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">219</span><span class="p">]</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">tokenized_corpus_ref</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">35</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"German machine translation:</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">wmt19_can_1</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">199</span><span class="p">]</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">tokenized_corpus_cand</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">29</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org7635138">
English source text:

﻿Welsh AMs worried about 'looking like muppets'
There is consternation among some AMs at a suggestion their title should change to MWPs (Member of the Welsh Parliament).
 -&gt; ['\ufeffwelsh', 'ams', 'worried', 'about', "'looking", 'like', "muppets'", 'there', 'is', 'consternation', 'among', 'some', 'ams', 'at', 'a', 'suggestion', 'their', 'title', 'should', 'change', 'to', 'mwps', '(', 'member', 'of', 'the', 'welsh', 'parliament', ')', '.']

German reference translation:

﻿Walisische Ageordnete sorgen sich "wie Dödel auszusehen"
Es herrscht Bestürzung unter einigen Mitgliedern der Versammlung über einen Vorschlag, der ihren Titel zu MWPs (Mitglied der walisischen Parlament) ändern soll.
 -&gt; ['\ufeffwalisische', 'ageordnete', 'sorgen', 'sich', '``', 'wie', 'dödel', 'auszusehen', "''", 'es', 'herrscht', 'bestürzung', 'unter', 'einigen', 'mitgliedern', 'der', 'versammlung', 'über', 'einen', 'vorschlag', ',', 'der', 'ihren', 'titel', 'zu', 'mwps', '(', 'mitglied', 'der', 'walisischen', 'parlament', ')', 'ändern', 'soll', '.']

German machine translation:

Walisische AMs machten sich Sorgen, dass sie wie Muppets aussehen könnten
Einige AMs sind bestürzt über den Vorschlag, ihren Titel in MWPs (Mitglied des walisischen Parlaments) zu ändern.
Es ist aufg -&gt; ['walisische', 'ams', 'machten', 'sich', 'sorgen', ',', 'dass', 'sie', 'wie', 'muppets', 'aussehen', 'könnten', 'einige', 'ams', 'sind', 'bestürzt', 'über', 'den', 'vorschlag', ',', 'ihren', 'titel', 'in', 'mwps', '(', 'mitglied', 'des', 'walisischen', 'parlaments']
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">"Results reference versus candidate 1 our own BLEU implementation: "</span><span class="p">,</span>
    <span class="nb">round</span><span class="p">(</span><span class="n">bleu_score</span><span class="p">(</span><span class="n">tokenized_corpus_cand</span><span class="p">,</span> <span class="n">tokenized_corpus_ref</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
<pre class="example">
Results reference versus candidate 1 our own BLEU implementation:  43.6
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">"Results reference versus candidate 1 sacrebleu library BLEU: "</span><span class="p">,</span>
    <span class="nb">round</span><span class="p">(</span><span class="n">sacrebleu</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">(</span><span class="n">wmt19_can_1</span><span class="p">,</span> <span class="n">wmt19_ref_1</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
<pre class="example">
Results reference versus candidate 1 sacrebleu library BLEU:  43.2
</pre>
<p><b>BLEU Score Interpretation on a Corpus</b></p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Score</th>
<th class="org-left" scope="col">Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&lt; 10</td>
<td class="org-left">Almost useless</td>
</tr>
<tr>
<td class="org-left">10 - 19</td>
<td class="org-left">Hard to get the gist</td>
</tr>
<tr>
<td class="org-left">20 - 29</td>
<td class="org-left">The gist is clear, but has significant grammatical errors</td>
</tr>
<tr>
<td class="org-left">30 - 40</td>
<td class="org-left">Understandable to good translations</td>
</tr>
<tr>
<td class="org-left">40 - 50</td>
<td class="org-left">High quality translations</td>
</tr>
<tr>
<td class="org-left">50 - 60</td>
<td class="org-left">Very high quality, adequate, and fluent translations</td>
</tr>
<tr>
<td class="org-left">&gt; 60</td>
<td class="org-left">Quality often better than human</td>
</tr>
</tbody>
</table>
<p>From the table above (taken from <a href="https://cloud.google.com/translate/automl/docs/evaluate">here</a>), we can see the translation is high quality (<b>if you see "Hard to get the gist", please open your workspace, delete `wmt19_can.txt` and get the latest version via the Lab Help button</b>). Moreover, the results of our coded BLEU score are almost identical to those of the SacreBLEU package.</p>
</div>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-new-questions/index.html">Siamese Networks: New Questions</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-new-questions/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:40:55-08:00" itemprop="datePublished" title="2021-01-25 19:40">2021-01-25 19:40</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/siamese-networks-new-questions/index.html#orgb4f7ac9">Trying New Questions</a>
<ul>
<li><a href="posts/nlp/siamese-networks-new-questions/index.html#org8c8d429">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-new-questions/index.html#orgcb02583">Set Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-new-questions/index.html#orgabcbd89">The Data</a></li>
<li><a href="posts/nlp/siamese-networks-new-questions/index.html#org66eb7eb">The Model</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-new-questions/index.html#org8f916cf">Implementing It</a>
<ul>
<li><a href="posts/nlp/siamese-networks-new-questions/index.html#orgd841410">Some Trials</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgb4f7ac9">
<h2 id="orgb4f7ac9">Trying New Questions</h2>
<div class="outline-text-2" id="text-orgb4f7ac9"></div>
<div class="outline-3" id="outline-container-org8c8d429">
<h3 id="org8c8d429">Imports</h3>
<div class="outline-text-3" id="text-org8c8d429">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">trax</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DataGenerator</span><span class="p">,</span>
    <span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">SiameseModel</span><span class="p">,</span>
    <span class="n">TOKENS</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgcb02583">
<h3 id="orgcb02583">Set Up</h3>
<div class="outline-text-3" id="text-orgcb02583"></div>
<div class="outline-4" id="outline-container-orgabcbd89">
<h4 id="orgabcbd89">The Data</h4>
<div class="outline-text-4" id="text-orgabcbd89">
<div class="highlight">
<pre><span></span><span class="n">data_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>
<span class="n">vocabulary</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org66eb7eb">
<h4 id="org66eb7eb">The Model</h4>
<div class="outline-text-4" id="text-org66eb7eb">
<div class="highlight">
<pre><span></span><span class="n">siamese</span> <span class="o">=</span> <span class="n">SiameseModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">))</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/siamese_networks/model.pkl.gz"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">siamese</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">init_from_file</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">siamese</span><span class="o">.</span><span class="n">model</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org8f916cf">
<h2 id="org8f916cf">Implementing It</h2>
<div class="outline-text-2" id="text-org8f916cf">
<p>Write a function =predict=that takes in two questions, the model, and the vocabulary and returns whether the questions are duplicates (<i>1</i>) or not duplicates (<i>0</i>) given a similarity threshold.</p>
<p><b>Instructions:</b></p>
<ul class="org-ul">
<li>Tokenize your question using `nltk.word_tokenize`</li>
<li>Create Q1,Q2 by encoding your questions as a list of numbers using vocab</li>
<li>pad Q1,Q2 with next(data_generator([Q1], [Q2],1,vocab['&lt;PAD&gt;']))</li>
<li>use model() to create v1, v2</li>
<li>compute the cosine similarity (dot product) of v1, v2</li>
<li>compute res by comparing d to the threshold</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">question1</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">question2</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">vocab</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="n">vocabulary</span><span class="p">,</span> <span class="n">data_generator</span><span class="p">:</span> <span class="nb">type</span><span class="o">=</span><span class="n">data_generator</span><span class="p">,</span>
            <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Function for predicting if two questions are duplicates.</span>

<span class="sd">    Args:</span>
<span class="sd">       question1 (str): First question.</span>
<span class="sd">       question2 (str): Second question.</span>
<span class="sd">       threshold (float): Desired threshold.</span>
<span class="sd">       model (trax.layers.combinators.Parallel): The Siamese model.</span>
<span class="sd">       vocab (collections.defaultdict): The vocabulary used.</span>
<span class="sd">       data_generator (function): Data generator function. Defaults to data_generator.</span>
<span class="sd">       verbose (bool, optional): If the results should be printed out. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">       bool: True if the questions are duplicates, False otherwise.</span>
<span class="sd">    """</span>
    <span class="n">question_one</span> <span class="o">=</span> <span class="p">[[</span><span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">question1</span><span class="p">)]]</span>
    <span class="n">question_two</span> <span class="o">=</span> <span class="p">[[</span><span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">question2</span><span class="p">)]]</span>

    <span class="n">questions</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_generator</span><span class="p">(</span><span class="n">question_one</span><span class="p">,</span>
                                    <span class="n">question_two</span><span class="p">,</span>
                                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">vector_1</span><span class="p">,</span> <span class="n">vector_2</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vector_1</span><span class="p">,</span> <span class="n">vector_2</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
    <span class="n">same_question</span> <span class="o">=</span> <span class="n">similarity</span> <span class="o">&gt;</span> <span class="n">threshold</span>

    <span class="k">if</span><span class="p">(</span><span class="n">verbose</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q1  = </span><span class="si">{</span><span class="n">questions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q2 = </span><span class="si">{</span><span class="n">questions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Similarity : </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">similarity</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"They are the same question: </span><span class="si">{</span><span class="n">same_question</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">same_question</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgd841410">
<h3 id="orgd841410">Some Trials</h3>
<div class="outline-text-3" id="text-orgd841410">
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tokens(unknown=0, padding=1, padding_token='&lt;PAD&gt;')
</pre>
<p>So if we see a 0 in the tokens then we know the word wasn't in the vocabulary.</p>
<div class="highlight">
<pre><span></span><span class="n">question1</span> <span class="o">=</span> <span class="s2">"When will I see you?"</span>
<span class="n">question2</span> <span class="o">=</span> <span class="s2">"When can I see you again?"</span>
<span class="c1"># 1 means it is duplicated, 0 otherwise</span>
<span class="n">predict</span><span class="p">(</span><span class="n">question1</span> <span class="p">,</span> <span class="n">question2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[581  64  20  44  49  16   1   1]]
Q2 = [[ 581   39   20   44   49 7280   16    1]]
Similarity : 0.95
They are the same question: True
</pre>
<div class="highlight">
<pre><span></span><span class="n">question1</span> <span class="o">=</span> <span class="s2">"Do they enjoy eating the dessert?"</span>
<span class="n">question2</span> <span class="o">=</span> <span class="s2">"Do they like hiking in the desert?"</span>

<span class="n">predict</span><span class="p">(</span><span class="n">question1</span> <span class="p">,</span> <span class="n">question2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[  446  1138  3159  1169    70 29016    16     1]]
Q2 = [[  446  1138    57 15302    24    70  7430    16]]
Similarity : 0.60
They are the same question: False
</pre>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Do cows have butts?"</span><span class="p">,</span> <span class="s2">"Do dogs have bones?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[  446  5757   216 25442    16     1     1     1]]
Q2 = [[  446   788   216 11192    16     1     1     1]]
Similarity : 0.25
They are the same question: False
</pre>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Do cows from Lancashire have butts?"</span><span class="p">,</span> <span class="s2">"Do dogs have bones as big as whales?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[  446  5757   125     0   216 25442    16     1     1     1     1     1
      1     1     1     1]]
Q2 = [[  446   788   216 11192   249  1124   249 30836    16     1     1     1
      1     1     1     1]]
Similarity : 0.13
They are the same question: False
</pre>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Can pigs fly?"</span><span class="p">,</span> <span class="s2">"Are you my mother?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[  221 14137  5750    16     1     1     1     1]]
Q2 = [[ 517   49   41 1585   16    1    1    1]]
Similarity : 0.01
They are the same question: False
</pre>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Shall we dance?"</span><span class="p">,</span> <span class="s2">"Shall I fart?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[19382   138  4201    16]]
Q2 = [[19382    20 18288    16]]
Similarity : 0.71
They are the same question: True
</pre>
<p>Hm… surprising that "fart" was in the data set, and it's the same as dancing.</p>
<div class="highlight">
<pre><span></span><span class="n">farts</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">training_data</span><span class="p">[</span><span class="n">loader</span><span class="o">.</span><span class="n">training_data</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">"fart[^a-z]"</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">farts</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">farts</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
<pre class="example">
16
19820                                    Can penguins fart?
60745       How do I control a fart when I'm about to fart?
83124           What word square starts with the word fart?
96707         Which part of human body is called fart pump?
120727    Why do people fart more when they wake up in t...
Name: question2, dtype: object
</pre>
<p>Maybe I shouldn't have been surprised.</p>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Am I man or gorilla?"</span><span class="p">,</span> <span class="s2">"Am I able to eat the pasta?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[4311   20 1215   75 7438   16    1    1]]
Q2 = [[ 4311    20   461    37   922    70 14552    16]]
Similarity : 0.20
They are the same question: False
</pre>
<p>It looks like the model only looks at the first words… at least when the sentences are short.</p>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Will we return to Mars or go instead to Venus?"</span><span class="p">,</span> <span class="s2">"Will we eat rice with plums and cherry topping?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[  168   141  8303    34  6861    72  1315  4536    34 15555    16     1
      1     1     1     1]]
Q2 = [[  168   141   927  7612   121     0     9 19275     0    16     1     1
      1     1     1     1]]
Similarity : 0.67
They are the same question: False
</pre>
<p>Siamese networks are important and useful. Many times there are several questions that are already asked in quora, or other platforms and you can use Siamese networks to avoid question duplicates.</p>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-evaluating-the-model/index.html">Siamese Networks: Evaluating the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-evaluating-the-model/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:39:59-08:00" itemprop="datePublished" title="2021-01-25 19:39">2021-01-25 19:39</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/index.html#orga92baa6">Evaluating the Siamese Network</a>
<ul>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/index.html#orgc91700a">Force CPU Use</a></li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/index.html#org20ddb51">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/index.html#org647faa0">Set Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/index.html#org8ce3c48">The Data</a></li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/index.html#org6c8da3d">The Timer</a></li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/index.html#org93a8ef1">The Model</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/index.html#orgab32130">Classify</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orga92baa6">
<h2 id="orga92baa6">Evaluating the Siamese Network</h2>
<div class="outline-text-2" id="text-orga92baa6"></div>
<div class="outline-3" id="outline-container-orgc91700a">
<h3 id="orgc91700a">Force CPU Use</h3>
<div class="outline-text-3" id="text-orgc91700a">
<p>For some reason the model eats up more and more memory on the GPU until it runs out. Seems like a memory leak. Anyway, for reasons that I don't know, the way that tensorflow tells you to disable using the GPU doesn't work (it's in the second code block) so to get this to work I have to essentially break the CUDA settings.</p>
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">""</span>
</pre></div>
<p>This is the way they tell you to do it.</p>
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span>
<span class="n">tensorflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_visible_devices</span><span class="p">([],</span> <span class="s2">"GPU"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org20ddb51">
<h3 id="org20ddb51">Imports</h3>
<div class="outline-text-3" id="text-org20ddb51">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DataGenerator</span><span class="p">,</span>
    <span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">SiameseModel</span><span class="p">,</span>
 <span class="p">)</span>

<span class="c1"># other</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org647faa0">
<h3 id="org647faa0">Set Up</h3>
<div class="outline-text-3" id="text-org647faa0"></div>
<div class="outline-4" id="outline-container-org8ce3c48">
<h4 id="org8ce3c48">The Data</h4>
<div class="outline-text-4" id="text-org8ce3c48">
<div class="highlight">
<pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>

<span class="n">vocabulary_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span>
<span class="n">testing</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">test</span>

<span class="k">del</span><span class="p">(</span><span class="n">loader</span><span class="p">)</span>
<span class="k">del</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6c8da3d">
<h4 id="org6c8da3d">The Timer</h4>
<div class="outline-text-4" id="text-org6c8da3d">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org93a8ef1">
<h4 id="org93a8ef1">The Model</h4>
<div class="outline-text-4" id="text-org93a8ef1">
<div class="highlight">
<pre><span></span><span class="n">siamese</span> <span class="o">=</span> <span class="n">SiameseModel</span><span class="p">(</span><span class="n">vocabulary_length</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/siamese_networks/model.pkl.gz"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">siamese</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">init_from_file</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgab32130">
<h2 id="orgab32130">Classify</h2>
<div class="outline-text-2" id="text-orgab32130">
<p>To determine the accuracy of the model, we will utilize the test set that was configured earlier. While in training we used only positive examples, the test data, Q1_test, Q2_test and y_test, is setup as pairs of questions, some of which are duplicates some are not.</p>
<p>This routine will run all the test question pairs through the model, compute the cosine simlarity of each pair, threshold it and compare the result to y_test - the correct response from the data set. The results are accumulated to produce an accuracy.</p>
<p><b>Instructions</b></p>
<ul class="org-ul">
<li>Loop through the incoming data in batch_size chunks</li>
<li>Use the data generator to load q1, q2 a batch at a time. <b>Don't forget to set shuffle=False!</b></li>
<li>copy a batch_size chunk of y into y_test</li>
<li>compute v1, v2 using the model</li>
<li>for each element of the batch
<ul class="org-ul">
<li>compute the cos similarity of each pair of entries, v1[j],v2[j]</li>
<li>determine if d &gt; threshold</li>
<li>increment accuracy if that result matches the expected results (y_test[j])</li>
</ul>
</li>
<li>compute the final accuracy and return</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">Outcome</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Outcome"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"accuracy"</span><span class="p">,</span> <span class="s2">"true_positive"</span><span class="p">,</span>
                                 <span class="s2">"true_negative"</span><span class="p">,</span> <span class="s2">"false_positive"</span><span class="p">,</span>
                                 <span class="s2">"false_negative"</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">data_generator</span><span class="p">:</span> <span class="nb">iter</span><span class="p">,</span>
             <span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
             <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
             <span class="n">model</span><span class="p">:</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Function to test the accuracy of the model.</span>

<span class="sd">    Args:</span>
<span class="sd">      data_generator: batch generator,</span>
<span class="sd">      y: Array of actual target.</span>
<span class="sd">      threshold: minimum distance to be considered the same</span>
<span class="sd">      model: The Siamese model.</span>
<span class="sd">    Returns:</span>
<span class="sd">       float: Accuracy of the model.</span>
<span class="sd">    """</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">true_positive</span> <span class="o">=</span> <span class="n">false_positive</span> <span class="o">=</span> <span class="n">true_negative</span> <span class="o">=</span> <span class="n">false_negative</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">batch_start</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">batch_one</span><span class="p">,</span> <span class="n">batch_two</span> <span class="ow">in</span> <span class="n">data_generator</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_one</span><span class="p">)</span>
        <span class="n">batch_stop</span> <span class="o">=</span> <span class="n">batch_start</span> <span class="o">+</span> <span class="n">batch_size</span>

        <span class="k">if</span> <span class="n">batch_stop</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="k">break</span>
        <span class="n">batch_labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">batch_start</span><span class="p">:</span> <span class="n">batch_stop</span><span class="p">]</span>
        <span class="n">vector_one</span><span class="p">,</span> <span class="n">vector_two</span> <span class="o">=</span> <span class="n">model</span><span class="p">((</span><span class="n">batch_one</span><span class="p">,</span> <span class="n">batch_two</span><span class="p">))</span>
        <span class="n">batch_start</span> <span class="o">=</span> <span class="n">batch_stop</span>

        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vector_one</span><span class="p">[</span><span class="n">row</span><span class="p">],</span> <span class="n">vector_two</span><span class="p">[</span><span class="n">row</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">same_question</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">similarity</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">=</span> <span class="n">same_question</span> <span class="o">==</span> <span class="n">batch_labels</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">same_question</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">correct</span><span class="p">:</span>
                    <span class="n">true_positive</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">false_positive</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">correct</span><span class="p">:</span>
                    <span class="n">true_negative</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">false_negative</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">accuracy</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Outcome</span><span class="p">(</span><span class="n">accuracy</span><span class="o">=</span><span class="n">accuracy</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span>
                   <span class="n">true_positive</span> <span class="o">=</span> <span class="n">true_positive</span><span class="p">,</span>
                   <span class="n">true_negative</span> <span class="o">=</span> <span class="n">true_negative</span><span class="p">,</span>
                   <span class="n">false_positive</span> <span class="o">=</span> <span class="n">false_positive</span><span class="p">,</span>
                   <span class="n">false_negative</span> <span class="o">=</span> <span class="n">false_negative</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">data_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">testing</span><span class="o">.</span><span class="n">question_one</span><span class="p">,</span> <span class="n">testing</span><span class="o">.</span><span class="n">question_two</span><span class="p">,</span>
                               <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                               <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">outcome</span> <span class="o">=</span> <span class="n">classify</span><span class="p">(</span>
        <span class="n">data_generator</span><span class="o">=</span><span class="n">data_generator</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
        <span class="n">threshold</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
        <span class="n">model</span><span class="o">=</span><span class="n">siamese</span><span class="o">.</span><span class="n">model</span>
    <span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Outcome: </span><span class="si">{</span><span class="n">outcome</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2021-02-10 21:42:27.320674
Ended: 2021-02-10 21:47:57.411380
Elapsed: 0:05:30.090706
Outcome: Outcome(accuracy=0.6546453536874203, true_positive=16439, true_negative=51832, false_positive=14425, false_negative=21240)
</pre>
<p>So, is that good or not? It might be more useful to look at the rates.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy: </span><span class="si">{</span><span class="n">outcome</span><span class="o">.</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">true_positive</span> <span class="o">=</span> <span class="n">outcome</span><span class="o">.</span><span class="n">true_positive</span>
<span class="n">false_negative</span> <span class="o">=</span> <span class="n">outcome</span><span class="o">.</span><span class="n">false_negative</span>
<span class="n">true_negative</span> <span class="o">=</span> <span class="n">outcome</span><span class="o">.</span><span class="n">true_negative</span>
<span class="n">false_positive</span> <span class="o">=</span> <span class="n">outcome</span><span class="o">.</span><span class="n">false_positive</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"True Positive Rate: </span><span class="si">{</span><span class="n">true_positive</span><span class="o">/</span><span class="p">(</span><span class="n">true_positive</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">false_negative</span><span class="p">)</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"True Negative Rate: </span><span class="si">{</span><span class="n">true_negative</span><span class="o">/</span><span class="p">(</span><span class="n">true_negative</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">false_positive</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Precision: </span><span class="si">{</span><span class="n">outcome</span><span class="o">.</span><span class="n">true_positive</span><span class="o">/</span><span class="p">(</span><span class="n">true_positive</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">false_positive</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"False Negative Rate: </span><span class="si">{</span><span class="n">false_negative</span><span class="o">/</span><span class="p">(</span><span class="n">false_negative</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">true_positive</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"False Positive Rate: </span><span class="si">{</span><span class="n">false_positive</span><span class="o">/</span><span class="p">(</span><span class="n">false_positive</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">true_negative</span><span class="p">)</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Accuracy: 0.65
True Positive Rate:  0.44
True Negative Rate: 0.78
Precision: 0.53
False Negative Rate: 0.56
False Positive Rate:  0.22
</pre>
<p>So, it was better at recognizing questions that were different. We could probably fiddle with the threshold to make it more one way or the other, if we needed to.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-training-the-model/index.html">Siamese Networks: Training the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-training-the-model/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:38:08-08:00" itemprop="datePublished" title="2021-01-25 19:38">2021-01-25 19:38</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html#org5ab3e96">Beginning</a>
<ul>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html#orgc967e2b">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html#org11da41e">Set Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html#org03dfef2">The Timer And Plotting</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html#org4889c6b">The Data</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html#org3786f64">The Data generator</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html#orga460b20">Middle</a>
<ul>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html#orge6c53f0">Training the Model</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html#org281efb8">Training</a>
<ul>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html#orgcbe71c1">Trial Two</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/index.html#org86e8226">Trial Three</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org5ab3e96">
<h2 id="org5ab3e96">Beginning</h2>
<div class="outline-text-2" id="text-org5ab3e96">
<p>Now we are going to train the Siamese Network Model model. As usual, we have to define the cost function and the optimizer. We also have to feed in the built model. Before, going into the training, we will use a special data set up. We will define the inputs using the data generator we built above. The lambda function acts as a seed to remember the last batch that was given. Run the cell below to get the question pairs inputs.</p>
</div>
<div class="outline-3" id="outline-container-orgc967e2b">
<h3 id="orgc967e2b">Imports</h3>
<div class="outline-text-3" id="text-orgc967e2b">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">tempfile</span> <span class="kn">import</span> <span class="n">TemporaryFile</span>

<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">holoviews</span> <span class="kn">import</span> <span class="n">opts</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">trax</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DataGenerator</span><span class="p">,</span>
    <span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">SiameseModel</span><span class="p">,</span>
    <span class="n">TOKENS</span><span class="p">,</span>
    <span class="n">triplet_loss_layer</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">Timer</span><span class="p">,</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org11da41e">
<h3 id="org11da41e">Set Up</h3>
<div class="outline-text-3" id="text-org11da41e"></div>
<div class="outline-4" id="outline-container-org03dfef2">
<h4 id="org03dfef2">The Timer And Plotting</h4>
<div class="outline-text-4" id="text-org03dfef2">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">slug</span> <span class="o">=</span> <span class="s2">"siamese-networks-training-the-model"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">slug</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span> <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">])</span>
<span class="n">PLOT</span> <span class="o">=</span> <span class="n">Plot</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4889c6b">
<h4 id="org4889c6b">The Data</h4>
<div class="outline-text-4" id="text-org4889c6b">
<div class="highlight">
<pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3786f64">
<h4 id="org3786f64">The Data generator</h4>
<div class="outline-text-4" id="text-org3786f64">
<div class="highlight">
<pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">train_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_two</span><span class="p">,</span>
                                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">validation_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">validate</span><span class="o">.</span><span class="n">question_one</span><span class="p">,</span>
                                     <span class="n">data</span><span class="o">.</span><span class="n">validate</span><span class="o">.</span><span class="n">question_two</span><span class="p">,</span>
                                     <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"training question 1 rows: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"validation question 1 rows: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">validate</span><span class="o">.</span><span class="n">question_one</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
training question 1 rows: 89,179
validation question 1 rows: 22,295
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orga460b20">
<h2 id="orga460b20">Middle</h2>
<div class="outline-text-2" id="text-orga460b20"></div>
<div class="outline-3" id="outline-container-orge6c53f0">
<h3 id="orge6c53f0">Training the Model</h3>
<div class="outline-text-3" id="text-orge6c53f0">
<p>We will now write a function that takes in the model and trains it. To train the model we have to decide how many times to iterate over the entire data set; each iteration is defined as an <code>epoch</code>. For each epoch, you have to go over all the data, using the training iterator.</p>
<ul class="org-ul">
<li>Create <code>TrainTask</code> and <code>EvalTask</code></li>
<li>Create the training loop <code>trax.supervised.training.Loop</code></li>
<li>Pass in the following depending on the context (train_task or eval_task):
<ul class="org-ul">
<li><code>labeled_data=generator</code></li>
<li><code>metrics</code>[TripletLoss()]=,</li>
<li><code>loss_layer=TripletLoss()</code></li>
<li><code>optimizer=trax.optimizers.Adam</code> with learning rate of 0.01</li>
<li><code>lr_schedule=lr_schedule</code>,</li>
<li><code>output_dir=output_dir</code></li>
</ul>
</li>
</ul>
<p>We will be using the triplet loss function with Adam optimizer. Please read the <a href="https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html?highlight=adam#trax.optimizers.adam.Adam">trax Adam</a> documentation to get a full understanding.</p>
<p>This function should return a <code>training.Loop</code> object. To read more about this check the <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html?highlight=loop#trax.supervised.training.Loop">training.Loop</a> documentation.</p>
<div class="highlight">
<pre><span></span><span class="n">lr_schedule</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">warmup_and_rsqrt_decay</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">Siamese</span><span class="p">,</span> <span class="n">TripletLoss</span><span class="p">,</span> <span class="n">lr_schedule</span><span class="p">,</span> <span class="n">train_generator</span><span class="o">=</span><span class="n">train_generator</span><span class="p">,</span> <span class="n">val_generator</span><span class="o">=</span><span class="n">validation_generator</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="s2">"~/models/siamese_networks/"</span><span class="p">,</span>
                <span class="n">steps_per_checkpoint</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Training the Siamese Model</span>

<span class="sd">    Args:</span>
<span class="sd">       Siamese (function): Function that returns the Siamese model.</span>
<span class="sd">       TripletLoss (function): Function that defines the TripletLoss loss function.</span>
<span class="sd">       lr_schedule (function): Trax multifactor schedule function.</span>
<span class="sd">       train_generator (generator, optional): Training generator. Defaults to train_generator.</span>
<span class="sd">       val_generator (generator, optional): Validation generator. Defaults to val_generator.</span>
<span class="sd">       output_dir (str, optional): Path to save model to. Defaults to 'model/'.</span>

<span class="sd">    Returns:</span>
<span class="sd">       trax.supervised.training.Loop: Training loop for the model.</span>
<span class="sd">    """</span>
    <span class="n">output_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>

    <span class="c1">### START CODE HERE (Replace instances of 'None' with your code) ###</span>

    <span class="n">train_task</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">supervised</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">TrainTask</span><span class="p">(</span>
        <span class="n">labeled_data</span><span class="o">=</span><span class="n">train_generator</span><span class="p">,</span>       <span class="c1"># Use generator (train)</span>
        <span class="n">loss_layer</span><span class="o">=</span><span class="n">TripletLoss</span><span class="p">(),</span>         <span class="c1"># Use triplet loss. Don't forget to instantiate this object</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">trax</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span>          <span class="c1"># Don't forget to add the learning rate parameter</span>
        <span class="n">lr_schedule</span><span class="o">=</span><span class="n">lr_schedule</span><span class="p">,</span> <span class="c1"># Use Trax multifactor schedule function</span>
        <span class="n">n_steps_per_checkpoint</span><span class="o">=</span><span class="n">steps_per_checkpoint</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">eval_task</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">supervised</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">EvalTask</span><span class="p">(</span>
        <span class="n">labeled_data</span><span class="o">=</span><span class="n">val_generator</span><span class="p">,</span>       <span class="c1"># Use generator (val)</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">TripletLoss</span><span class="p">()],</span>          <span class="c1"># Use triplet loss. Don't forget to instantiate this object</span>
    <span class="p">)</span>

    <span class="c1">### END CODE HERE ###</span>

    <span class="n">training_loop</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">supervised</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">Loop</span><span class="p">(</span><span class="n">Siamese</span><span class="p">,</span>
                                                  <span class="p">[</span><span class="n">train_task</span><span class="p">],</span>
                                                  <span class="n">eval_tasks</span><span class="o">=</span><span class="p">[</span><span class="n">eval_task</span><span class="p">],</span>
                                                  <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">training_loop</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org281efb8">
<h3 id="org281efb8">Training</h3>
<div class="outline-text-3" id="text-org281efb8"></div>
<div class="outline-4" id="outline-container-orgcbe71c1">
<h4 id="orgcbe71c1">Trial Two</h4>
<div class="outline-text-4" id="text-orgcbe71c1">
<p><b>Note:</b> I re-ran this next code block so it's actually the second run.</p>
<div class="highlight">
<pre><span></span><span class="n">train_steps</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">siamese</span> <span class="o">=</span> <span class="n">SiameseModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">))</span>
<span class="n">training_loop</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">siamese</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">triplet_loss_layer</span><span class="p">,</span> <span class="n">lr_schedule</span><span class="p">,</span> <span class="n">steps_per_checkpoint</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">real_stdout</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span>

<span class="n">TIMER</span><span class="o">.</span><span class="n">emit</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">TIMER</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TemporaryFile</span><span class="p">(</span><span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">temp_file</span><span class="p">:</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">temp_file</span>
    <span class="n">training_loop</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_steps</span><span class="p">)</span>
<span class="n">TIMER</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">real_stdout</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">TIMER</span><span class="o">.</span><span class="n">ended</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">TIMER</span><span class="o">.</span><span class="n">started</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0:19:46.056057
</pre>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">mode</span> <span class="ow">in</span> <span class="n">training_loop</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">modes</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">training_loop</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">metrics_for_mode</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span>
</pre></div>
<pre class="example">
eval
['metrics/TripletLoss']
train
['metrics/TripletLoss', 'training/gradients_l2', 'training/learning_rate', 'training/loss', 'training/steps per second', 'training/weights_l2']
</pre></div>
<ul class="org-ul">
<li><a id="org73a764c"></a>Plotting the Metrics<br>
<div class="outline-text-5" id="text-org73a764c">
<p><b>Note:</b> As of February 2021, the version of trax on pypi doesn't have a <i>history</i> attribute - to get it you have to install the code from the github repository.</p>
<div class="highlight">
<pre><span></span><span class="n">frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">training_loop</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eval"</span><span class="p">,</span> <span class="s2">"metrics/TripletLoss"</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="s2">"Batch TripletLoss"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

<span class="n">minimum</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">TripletLoss</span><span class="o">.</span><span class="n">idxmin</span><span class="p">()]</span>
<span class="n">vline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">Batch</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">hline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">TripletLoss</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Batch"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"TripletLoss"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">Curve</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">))</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">hline</span> <span class="o">*</span> <span class="n">vline</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Evaluation Batch Triplet Loss"</span><span class="p">,</span>
                                   <span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"evaluation_triplet_loss"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/siamese-networks-training-the-model/evaluation_triplet_loss.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>It looks the loss is stabilizing. If it doesn't perform well I'll re-train it.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org86e8226">
<h4 id="org86e8226">Trial Three</h4>
<div class="outline-text-4" id="text-org86e8226">
<p>Let's see if the continues going down.</p>
<div class="highlight">
<pre><span></span><span class="n">train_steps</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">siamese</span> <span class="o">=</span> <span class="n">SiameseModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">))</span>
<span class="n">training_loop</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">siamese</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">triplet_loss_layer</span><span class="p">,</span> <span class="n">lr_schedule</span><span class="p">,</span> <span class="n">steps_per_checkpoint</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">real_stdout</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span>

<span class="n">TIMER</span><span class="o">.</span><span class="n">emit</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">TIMER</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TemporaryFile</span><span class="p">(</span><span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">temp_file</span><span class="p">:</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">temp_file</span>
    <span class="n">training_loop</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_steps</span><span class="p">)</span>
<span class="n">TIMER</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">real_stdout</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">TIMER</span><span class="o">.</span><span class="n">ended</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">TIMER</span><span class="o">.</span><span class="n">started</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0:17:41.167719
</pre></div>
<ul class="org-ul">
<li><a id="orgf76fc90"></a>Plotting the Metrics<br>
<div class="outline-text-5" id="text-orgf76fc90">
<div class="highlight">
<pre><span></span><span class="n">frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">training_loop</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eval"</span><span class="p">,</span> <span class="s2">"metrics/TripletLoss"</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="s2">"Batch TripletLoss"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

<span class="n">minimum</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">TripletLoss</span><span class="o">.</span><span class="n">idxmin</span><span class="p">()]</span>
<span class="n">vline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">Batch</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">hline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">TripletLoss</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Batch"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"TripletLoss"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">Curve</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">))</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">hline</span> <span class="o">*</span> <span class="n">vline</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Evaluation Batch Triplet Loss (Third Run)"</span><span class="p">,</span>
                                   <span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"evaluation_triplet_loss_third"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/siamese-networks-training-the-model/evaluation_triplet_loss.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>It looks like it stopped improving. Probably time to stop.</p>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-hard-negative-mining/index.html">Siamese Networks: Hard Negative Mining</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:37:28-08:00" itemprop="datePublished" title="2021-01-25 19:37">2021-01-25 19:37</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#orgfcfabfe">Hard Negative Mining</a>
<ul>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#org61ea768">Imports</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#org9611eed">Implementation</a>
<ul>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#org1acd421">More Detailed Instructions</a>
<ul>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#org13a4fc2">Cosine Similarity</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#org1981aa3">Closest Negative</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#orgbbe660a">Mean Negative</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#org791e64c">Bundle It Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#org9f95925">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#org694c721">Triplet Loss</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#org3e9e964">Triplet Loss Layer</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/index.html#orge64cb9c">Check It Out</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgfcfabfe">
<h2 id="orgfcfabfe">Hard Negative Mining</h2>
<div class="outline-text-2" id="text-orgfcfabfe">
<p>Now we will now implement the <code>TripletLoss</code>. Loss is composed of two terms. One term utilizes the mean of all the non duplicates, the second utilizes the <b>closest negative</b>. Our loss expression is then:</p>
\begin{align} \mathcal{Loss_1(A,P,N)} &amp;=\max \left( -cos(A,P) + mean_{neg} +\alpha, 0\right) \\ \mathcal{Loss_2(A,P,N)} &amp;=\max \left( -cos(A,P) + closest_{neg} +\alpha, 0\right) \\ \mathcal{Loss(A,P,N)} &amp;= mean(Loss_1 + Loss_2) \\ \end{align}
<p>Here is a list of things we have to do:</p>
<ul class="org-ul">
<li>As this will be run inside trax, use <code>fastnp.xyz</code> when using any <code>xyz</code> numpy function</li>
<li>Use <code>fastnp.dot</code> to calculate the similarity matrix \(v_1v_2^T\) of dimension <code>batch_size</code> x <code>batch_size</code></li>
<li>Take the score of the duplicates on the diagonal <code>fastnp.diagonal</code></li>
<li>Use the <code>trax</code> functions <code>fastnp.eye</code> and <code>fastnp.maximum</code> for the identity matrix and the maximum.</li>
</ul>
</div>
<div class="outline-3" id="outline-container-org61ea768">
<h3 id="org61ea768">Imports</h3>
<div class="outline-text-3" id="text-org61ea768">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">trax.fastmath</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">fastnp</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org9611eed">
<h2 id="org9611eed">Implementation</h2>
<div class="outline-text-2" id="text-org9611eed"></div>
<div class="outline-3" id="outline-container-org1acd421">
<h3 id="org1acd421">More Detailed Instructions</h3>
<div class="outline-text-3" id="text-org1acd421">
<p>We'll describe the algorithm using a detailed example. Below, V1, V2 are the output of the normalization blocks in our model. Here we will use a batch_size of 4 and a d_model of 3. The inputs, Q1, Q2 are arranged so that corresponding inputs are duplicates while non-corresponding entries are not. The outputs will have the same pattern.</p>
<p>This testcase arranges the outputs, v1,v2, to highlight different scenarios. Here, the first two outputs V1[0], V2[0] match exactly - so the model is generating the same vector for Q1[0] and Q2[0] inputs. The second outputs differ, circled in orange, we set, V2[1] is set to match V2[**2**], simulating a model which is generating very poor results. V1[3] and V2[3] match exactly again while V1[4] and V2[4] are set to be exactly wrong - 180 degrees from each other, circled in blue.</p>
</div>
<div class="outline-4" id="outline-container-org13a4fc2">
<h4 id="org13a4fc2">Cosine Similarity</h4>
<div class="outline-text-4" id="text-org13a4fc2">
<p>The first step is to compute the cosine similarity matrix or <code>score</code> in the code. This is \(V_1 V_2^T\) which is generated with <code>fastnp.dot</code>.</p>
<p>The clever arrangement of inputs creates the data needed for positive <b>and</b> negative examples without having to run all pair-wise combinations. Because Q1[n] is a duplicate of only Q2[n], other combinations are explicitly created negative examples or <b>Hard Negative</b> examples. The matrix multiplication efficiently produces the cosine similarity of all positive/negative combinations as shown above on the left side of the diagram. 'Positive' are the results of duplicate examples and 'negative' are the results of explicitly created negative examples. The results for our test case are as expected, V1[0]V2[0] match producing '1' while our other 'positive' cases (in green) don't match well, as was arranged. The V2[2] was set to match V1[3] producing a poor match at <code>score[2,2]</code> and an undesired 'negative' case of a '1' shown in grey.</p>
<p>With the similarity matrix (<code>score</code>) we can begin to implement the loss equations. First, we can extract \(\cos(A,P)\) by utilizing <code>fastnp.diagonal</code>. The goal is to grab all the green entries in the diagram above. This is <code>positive</code> in the code.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org1981aa3">
<h4 id="org1981aa3">Closest Negative</h4>
<div class="outline-text-4" id="text-org1981aa3">
<p>Next, we will create the <b>closest_negative</b>. This is the nonduplicate entry in V2 that is closest (has largest cosine similarity) to an entry in V1. Each row, n, of <code>score</code> represents all comparisons of the results of Q1[n] vs Q2[x] within a batch. A specific example in our testcase is row <code>score[2,:]</code>. It has the cosine similarity of V1[2] and V2[x]. The <b>closest_negative</b>, as was arranged, is V2[2] which has a score of 1. This is the maximum value of the 'negative' entries (blue entries in the diagram).</p>
<p>To implement this, we need to pick the maximum entry on a row of <code>score</code>, ignoring the 'positive'/green entries. To avoid selecting the 'positive'/green entries, we can make them larger negative numbers. Multiply <code>fastnp.eye(batch_size)</code> with 2.0 and subtract it out of <code>scores</code>. The result is <code>negative_without_positive</code>. Now we can use <code>fastnp.max</code>, row by row (axis=1), to select the maximum which is <code>closest_negative</code>.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgbbe660a">
<h4 id="orgbbe660a">Mean Negative</h4>
<div class="outline-text-4" id="text-orgbbe660a">
<p>Next, we'll create <b>mean_negative</b>. As the name suggests, this is the mean of all the 'negative'/blue values in <code>score</code> on a row by row basis. We can use <code>fastnp.eye(batch_size)</code> and a constant, this time to create a mask with zeros on the diagonal. Element-wise multiply this with <code>score</code> to get just the 'negative values. This is <code>negative_zero_on_duplicate</code> in the code. Compute the mean by using <code>fastnp.sum</code> on <code>negative_zero_on_duplicate</code> for <code>axis=1</code> and divide it by <code>(batch_size - 1)</code> . This is <code>mean_negative</code>.</p>
<p>Now, we can compute loss using the two equations above and <code>fastnp.maximum</code>. This will form <code>triplet_loss1</code> and <code>triplet_loss2</code>.</p>
<p><code>triple_loss</code> is the <code>fastnp.mean</code> of the sum of the two individual losses.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">TripletLossFn</span><span class="p">(</span><span class="n">v1</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">v2</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                  <span class="n">margin</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jax</span><span class="o">.</span><span class="n">interpreters</span><span class="o">.</span><span class="n">xla</span><span class="o">.</span><span class="n">DeviceArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Custom Loss function.</span>

<span class="sd">    Args:</span>
<span class="sd">       v1 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q1.</span>
<span class="sd">       v2 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q2.</span>
<span class="sd">       margin (float, optional): Desired margin. Defaults to 0.25.</span>

<span class="sd">    Returns:</span>
<span class="sd">       jax.interpreters.xla.DeviceArray: Triplet Loss.</span>
<span class="sd">    """</span>
    <span class="c1"># use fastnp to take the dot product of the two batches (don't forget to transpose the second argument)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="c1"># calculate new batch size</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="c1"># use fastnp to grab all postive =diagonal= entries in =scores=</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>  <span class="c1"># the positive ones (duplicates)</span>
    <span class="c1"># multiply =fastnp.eye(batch_size)= with 2.0 and subtract it out of =scores=</span>
    <span class="n">negative_without_positive</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">-</span> <span class="p">(</span><span class="n">fastnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">2.0</span><span class="p">)</span>
    <span class="c1"># take the row by row =max= of =negative_without_positive=. </span>
    <span class="c1"># Hint: negative_without_positive.max(axis = [?])  </span>
    <span class="n">closest_negative</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">negative_without_positive</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># subtract =fastnp.eye(batch_size)= out of 1.0 and do element-wise multiplication with =scores=</span>
    <span class="n">negative_zero_on_duplicate</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">batch_size</span><span class="p">))</span> <span class="o">*</span> <span class="n">scores</span>
    <span class="c1"># use =fastnp.sum= on =negative_zero_on_duplicate= for =axis=1= and divide it by =(batch_size - 1)= </span>
    <span class="n">mean_negative</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">negative_zero_on_duplicate</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># compute =fastnp.maximum= among 0.0 and =A=</span>
    <span class="c1"># A = subtract =positive= from =margin= and add =closest_negative= </span>
    <span class="n">triplet_loss1</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">margin</span> <span class="o">-</span> <span class="n">positive</span> <span class="o">+</span> <span class="n">closest_negative</span><span class="p">)</span>
    <span class="c1"># compute =fastnp.maximum= among 0.0 and =B=</span>
    <span class="c1"># B = subtract =positive= from =margin= and add =mean_negative=</span>
    <span class="n">triplet_loss2</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">margin</span> <span class="o">-</span> <span class="n">positive</span><span class="p">)</span> <span class="o">+</span> <span class="n">mean_negative</span><span class="p">)</span>
    <span class="c1"># add the two losses together and take the =fastnp.mean= of it</span>
    <span class="n">triplet_loss</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">triplet_loss1</span> <span class="o">+</span> <span class="n">triplet_loss2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">triplet_loss</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">v1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.26726124</span><span class="p">,</span> <span class="mf">0.53452248</span><span class="p">,</span> <span class="mf">0.80178373</span><span class="p">],[</span><span class="mf">0.5178918</span> <span class="p">,</span> <span class="mf">0.57543534</span><span class="p">,</span> <span class="mf">0.63297887</span><span class="p">]])</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">0.26726124</span><span class="p">,</span>  <span class="mf">0.53452248</span><span class="p">,</span>  <span class="mf">0.80178373</span><span class="p">],[</span><span class="o">-</span><span class="mf">0.5178918</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.57543534</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.63297887</span><span class="p">]])</span>
<span class="n">triplet_loss</span> <span class="o">=</span> <span class="n">TripletLossFn</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="n">v1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Triplet Loss: </span><span class="si">{</span><span class="n">triplet_loss</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">triplet_loss</span> <span class="o">==</span> <span class="mf">0.5</span>
</pre></div>
<pre class="example">
Triplet Loss: 0.5
</pre>
<p>To make a layer out of a function with no trainable variables, use <code>tl.Fn</code>.</p>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="k">def</span> <span class="nf">TripletLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="mf">0.25</span><span class="p">):</span>
    <span class="n">triplet_loss_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">TripletLossFn</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="n">margin</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s1">'TripletLoss'</span><span class="p">,</span> <span class="n">triplet_loss_fn</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org791e64c">
<h2 id="org791e64c">Bundle It Up</h2>
<div class="outline-text-2" id="text-org791e64c">
<p>Unfortunately trax does some kind of weirdness where it counts the arguments of the things you use as layers, so class-based stuff won't work (because it counts the <code>self</code> argument, giving it too many to expect). There might be a way to work around this, but it doesn't appear to be documented so this has to be done with only functions. That's not bad, it's just unexpected (and not well documented).</p>
</div>
<div class="outline-3" id="outline-container-org9f95925">
<h3 id="org9f95925">Imports</h3>
<div class="outline-text-3" id="text-org9f95925">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">trax.fastmath</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">fastmath_numpy</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org694c721">
<h3 id="org694c721">Triplet Loss</h3>
<div class="outline-text-3" id="text-org694c721">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">triplet_loss</span><span class="p">(</span><span class="n">v1</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
             <span class="n">v2</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">margin</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">jax</span><span class="o">.</span><span class="n">interpreters</span><span class="o">.</span><span class="n">xla</span><span class="o">.</span><span class="n">DeviceArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Calculates the triplet loss</span>

<span class="sd">    Args:</span>
<span class="sd">     v1: normalized batch for question 1</span>
<span class="sd">     v2: normalized batch for question 2</span>

<span class="sd">    Returns:</span>
<span class="sd">     triplet loss</span>
<span class="sd">    """</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="n">negative_without_positive</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">-</span> <span class="p">(</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">2.0</span><span class="p">)</span>
    <span class="n">closest_negative</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">negative_without_positive</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">negative_zero_on_duplicate</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">batch_size</span><span class="p">))</span> <span class="o">*</span> <span class="n">scores</span>
    <span class="n">mean_negative</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">negative_zero_on_duplicate</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">triplet_loss1</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">margin</span> <span class="o">-</span> <span class="n">positive</span> <span class="o">+</span> <span class="n">closest_negative</span><span class="p">)</span>
    <span class="n">triplet_loss2</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">margin</span> <span class="o">-</span> <span class="n">positive</span><span class="p">)</span> <span class="o">+</span> <span class="n">mean_negative</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">triplet_loss1</span> <span class="o">+</span> <span class="n">triplet_loss2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org3e9e964">
<h3 id="org3e9e964">Triplet Loss Layer</h3>
<div class="outline-text-3" id="text-org3e9e964">
<p>Another not well documented limitation is that the function you create the layer from isn't allowed to take have default values, so if we want to allow the <code>margin</code> to have a default, we have to use <code>partial</code> to set the value before creating the layer…</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">triplet_loss_layer</span><span class="p">(</span><span class="n">margin</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Converts the triplet_loss function to a trax layer"""</span>
    <span class="n">with_margin</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">triplet_loss</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="n">margin</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s2">"TripletLoss"</span><span class="p">,</span> <span class="n">with_margin</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orge64cb9c">
<h3 id="orge64cb9c">Check It Out</h3>
<div class="outline-text-3" id="text-orge64cb9c">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">triplet_loss_layer</span>

<span class="n">layer</span> <span class="o">=</span> <span class="n">triplet_loss_layer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">layer</span><span class="p">))</span>
</pre></div>
<pre class="example">
&lt;class 'trax.layers.base.PureLayer'&gt;
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-defining-the-model/index.html">Siamese Networks: Defining the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-defining-the-model/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:36:23-08:00" itemprop="datePublished" title="2021-01-25 19:36">2021-01-25 19:36</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#org69393e5">Understanding the Siamese Network</a>
<ul>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#orgb6e03d9">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#org1df97c9">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#org2535411">Implementation</a>
<ul>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#orge9b96ec">Check the Model</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#orgb4f4e9b">Bundle It Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#orgef4ebb8">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#org4b99819">Constants</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#org9d869e8">Normalize</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#org152a700">The Siamese Model</a>
<ul>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#org3edecbd">The Processor</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#org06e6069">The Model</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/index.html#org5960d87">Check It Out</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org69393e5">
<h2 id="org69393e5">Understanding the Siamese Network</h2>
<div class="outline-text-2" id="text-org69393e5">
<p>A Siamese network is a neural network which uses the same weights while working in tandem on two different input vectors to compute comparable output vectors.</p>
<p>You get the question embedding, run it through an LSTM layer, normalize \(v_1\) and \(v_2\), and finally use a triplet loss (explained below) to get the corresponding cosine similarity for each pair of questions. As usual, you will start by importing the data set. The triplet loss makes use of a baseline (anchor) input that is compared to a positive (truthy) input and a negative (falsy) input. The distance from the baseline (anchor) input to the positive (truthy) input is minimized, and the distance from the baseline (anchor) input to the negative (falsy) input is maximized. In math equations, you are trying to maximize the following.</p>
<p>\[ \mathcal{L}(A, P, N)=\max \left(\|\mathrm{f}(A)-\mathrm{f}(P)\|^{2}-\|\mathrm{f}(A)-\mathrm{f}(N)\|^{2}+\alpha, 0\right) \]</p>
<p><i>A</i> is the anchor input, for example \(q1_1\), \(P\) the duplicate input, for example, \(q2_1\), and \(N\) the negative input (the non duplicate question), for example \(q2_2\). \(\alpha\) is a margin; you can think about it as a safety net, or by how much you want to push the duplicates from the non duplicates.</p>
</div>
<div class="outline-3" id="outline-container-orgb6e03d9">
<h3 id="orgb6e03d9">Imports</h3>
<div class="outline-text-3" id="text-orgb6e03d9">
<div class="highlight">
<pre><span></span><span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">trax.fastmath.numpy</span> <span class="k">as</span> <span class="nn">fastnp</span>
<span class="kn">import</span> <span class="nn">trax.layers</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="c1"># This Project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TOKENS</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1df97c9">
<h3 id="org1df97c9">Set Up</h3>
<div class="outline-text-3" id="text-org1df97c9">
<div class="highlight">
<pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org2535411">
<h2 id="org2535411">Implementation</h2>
<div class="outline-text-2" id="text-org2535411">
<p>To implement this model, you will be using `trax`. Concretely, you will be using the following functions.</p>
<ul class="org-ul">
<li><code>tl.Serial</code>: Combinator that applies layers serially (by function composition) allows you set up the overall structure of the feedforward. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/combinators.py#L26">source code</a>
<ul class="org-ul">
<li>You can pass in the layers as arguments to <code>Serial</code>, separated by commas.</li>
<li>For example: <code>tl.Serial(tl.Embeddings(...), tl.Mean(...), tl.Dense(...), tl.LogSoftmax(...))</code></li>
</ul>
</li>
<li><code>tl.Embedding</code>: Maps discrete tokens to vectors. It will have shape (vocabulary length X dimension of output vectors). The dimension of output vectors (also called d_feature) is the number of elements in the word embedding. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L113">source code</a>
<ul class="org-ul">
<li><code>tl.Embedding(vocab_size, d_feature)</code>.</li>
<li><code>vocab_size</code> is the number of unique words in the given vocabulary.</li>
<li><code>d_feature</code> is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example).</li>
</ul>
</li>
<li><code>tl.LSTM</code> The LSTM layer. It leverages another Trax layer called <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTMCell"><code>LSTMCell</code></a>. The number of units should be specified and should match the number of elements in the word embedding. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTM">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/rnn.py#L87">source code</a>
<ul class="org-ul">
<li><code>tl.LSTM(n_units)</code> Builds an LSTM layer of n_units.</li>
</ul>
</li>
<li><code>tl.Mean</code>: Computes the mean across a desired axis. Mean uses one tensor axis to form groups of values and replaces each group with the mean value of that group. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Mean">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L276">source code</a>
<ul class="org-ul">
<li><code>tl.Mean(axis=1)</code> mean over columns.</li>
</ul>
</li>
<li><code>tl.Fn</code> Layer with no weights that applies the function f, which should be specified using a lambda syntax. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn">docs</a> / <a href="https://github.com/google/trax/blob/70f5364dcaf6ec11aabbd918e5f5e4b0f5bfb995/trax/layers/base.py#L576">source code</a>
<ul class="org-ul">
<li><i>x</i> -&gt; This is used for cosine similarity.</li>
<li><code>tl.Fn('Normalize', lambda x: normalize(x))</code> Returns a layer with no weights that applies the function <code>f</code></li>
</ul>
</li>
<li><code>tl.parallel</code>: It is a combinator layer (like <code>Serial</code>) that applies a list of layers in parallel to its inputs. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Parallel">docs</a> / <a href="https://github.com/google/trax/blob/37aba571a89a8ad86be76a569d0ec4a46bdd8642/trax/layers/combinators.py#L152">source code</a></li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">Siamese</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">),</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'train'</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Returns a Siamese model.</span>

<span class="sd">    Args:</span>
<span class="sd">       vocab_size (int, optional): Length of the vocabulary. Defaults to len(vocab).</span>
<span class="sd">       d_model (int, optional): Depth of the model. Defaults to 128.</span>
<span class="sd">       mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to 'train'.</span>

<span class="sd">    Returns:</span>
<span class="sd">       trax.layers.combinators.Parallel: A Siamese model. </span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>  <span class="c1"># normalizes the vectors to have L2 norm 1</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fastnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="n">q_processor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>  <span class="c1"># Processor will run on Q1 and Q2.</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span> <span class="c1"># Embedding layer</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">d_model</span><span class="p">),</span> <span class="c1"># LSTM layer</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># Mean over columns</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s2">"Normalize"</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span>  <span class="c1"># Apply normalize function</span>
    <span class="p">)</span>  <span class="c1"># Returns one vector of shape [batch_size, d_model].</span>

    <span class="c1"># Run on Q1 and Q2 in parallel.</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">Parallel</span><span class="p">(</span><span class="n">q_processor</span><span class="p">,</span> <span class="n">q_processor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-orge9b96ec">
<h3 id="orge9b96ec">Check the Model</h3>
<div class="outline-text-3" id="text-orge9b96ec">
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Siamese</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org8b0269a">
Parallel_in2_out2[
  Serial[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize
  ]
  Serial[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize
  ]
]
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orgb4f4e9b">
<h2 id="orgb4f4e9b">Bundle It Up</h2>
<div class="outline-text-2" id="text-orgb4f4e9b">
<div class="highlight">
<pre><span></span><span class="o">&lt;&lt;</span><span class="n">imports</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">constants</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">normalize</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">siamese</span><span class="o">-</span><span class="n">network</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">the</span><span class="o">-</span><span class="n">processor</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">the</span><span class="o">-</span><span class="n">model</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgef4ebb8">
<h3 id="orgef4ebb8">Imports</h3>
<div class="outline-text-3" id="text-orgef4ebb8">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">trax.fastmath</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">fastmath_numpy</span>

<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org4b99819">
<h3 id="org4b99819">Constants</h3>
<div class="outline-text-3" id="text-org4b99819">
<div class="highlight">
<pre><span></span><span class="n">Axis</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Axis"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"columns"</span><span class="p">,</span> <span class="s2">"last"</span><span class="p">])</span>
<span class="n">Constants</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Constants"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"model_depth"</span><span class="p">,</span> <span class="s2">"axis"</span><span class="p">])</span>

<span class="n">AXIS</span> <span class="o">=</span> <span class="n">Axis</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">CONSTANTS</span> <span class="o">=</span> <span class="n">Constants</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">AXIS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org9d869e8">
<h3 id="org9d869e8">Normalize</h3>
<div class="outline-text-3" id="text-org9d869e8">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Normalizes the vectors to have L2 norm 1</span>

<span class="sd">    Args:</span>
<span class="sd">     x: the array of vectors to normalize</span>

<span class="sd">    Returns:</span>
<span class="sd">     normalized version of x</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">/</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span>
                                                    <span class="n">axis</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">last</span><span class="p">,</span>
                                                    <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org152a700">
<h3 id="org152a700">The Siamese Model</h3>
<div class="outline-text-3" id="text-org152a700">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">SiameseModel</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""The Siamese network model</span>

<span class="sd">    Args:</span>
<span class="sd">     vocabulary_size: number of tokens in the vocabulary</span>
<span class="sd">     model_depth: depth of our embedding layer</span>
<span class="sd">     mode: train|eval|predict</span>
<span class="sd">    """</span>
    <span class="n">vocabulary_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">model_depth</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">model_depth</span>
    <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"train"</span>
    <span class="n">_processor</span><span class="p">:</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">combinators</span><span class="o">.</span><span class="n">Serial</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_model</span><span class="p">:</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">combinators</span><span class="o">.</span><span class="n">Parallel</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org3edecbd">
<h4 id="org3edecbd">The Processor</h4>
<div class="outline-text-4" id="text-org3edecbd">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">processor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""The Question Processor"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_processor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_processor</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s2">"Normalize"</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span> 
        <span class="p">)</span> 
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_processor</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org06e6069">
<h4 id="org06e6069">The Model</h4>
<div class="outline-text-4" id="text-org06e6069">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""The Siamese Model"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">processor</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s2">"Normalize"</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span> 
        <span class="p">)</span> 

        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="n">processor</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org5960d87">
<h3 id="org5960d87">Check It Out</h3>
<div class="outline-text-3" id="text-org5960d87">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">SiameseModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SiameseModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org816bac0">
Parallel_in4_out2[
  Serial_in2[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize_in2
  ]
  Serial_in2[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize_in2
  ]
]
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-the-data-generator/index.html">Siamese Networks: The Data Generator</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-the-data-generator/index.html" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:35:05-08:00" itemprop="datePublished" title="2021-01-25 19:35">2021-01-25 19:35</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#org13e6bb2">Beginning</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#orgb6804d3">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#orgb134057">Set Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#org90ed996">Our Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#org42911ca">The Idiotic Names</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#orgcd02f72">Middle</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#org682fd6b">Try It Out</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#orgedd85b8">Bundling It Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#orgf224535">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#org02641a2">The Data Generator</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#org17ba17d">The Generator Definition</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#orgb57d6f2">The Generator</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#orgfb3b215">The Iter Method</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#org143f79f">The Next Method</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/index.html#org8d00941">Check It Out</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org13e6bb2">
<h2 id="org13e6bb2">Beginning</h2>
<div class="outline-text-2" id="text-org13e6bb2">
<p>Most of the time in Natural Language Processing, and AI in general we use batches when training our data sets. If you were to use stochastic gradient descent with one example at a time, it would take you forever to build a model. In this example, we show you how you can build a data generator that takes in \(Q1\) and \(Q2\) and returns a batch of size <code>batch_size</code> in the following format \(([q1_1, q1_2, q1_3, ...]\), \([q2_1, q2_2,q2_3, ...])\). The tuple consists of two arrays and each array has <code>batch_size</code> questions. Again, \(q1_i\) and \(q2_i\) are duplicates, but they are not duplicates with any other elements in the batch.</p>
<p>The iterator that we're going to create returns a pair of arrays of questions.</p>
<p>We'll implement the data generator below. Here are some things we will need.</p>
<ul class="org-ul">
<li>While true loop.</li>
<li>if <code>index &gt;</code> len_Q1=, set the <code>idx</code> to \(0\).</li>
<li>The generator should return shuffled batches of data. To achieve this without modifying the actual question lists, a list containing the indexes of the questions is created. This list can be shuffled and used to get random batches everytime the index is reset.</li>
<li>Append elements of \(Q1\) and \(Q2\) to <code>input1</code> and <code>input2</code> respectively.</li>
<li>if <code>len(input1) =</code> batch_size=, determine <code>max_len</code> as the longest question in <code>input1</code> and <code>input2</code>. Ceil <code>max_len</code> to a power of \(2\) (for computation purposes) using the following command: <code>max_len = 2**int(np.ceil(np.log2(max_len)))</code>.</li>
<li>Pad every question by <code>vocab['&lt;PAD&gt;']</code> until you get the length <code>max_len</code>.</li>
<li>Use yield to return <code>input1, input2</code>.</li>
<li>Don't forget to reset <code>input1, input2</code> to empty arrays at the end (data generator resumes from where it last left).</li>
</ul>
</div>
<div class="outline-3" id="outline-container-orgb6804d3">
<h3 id="orgb6804d3">Imports</h3>
<div class="outline-text-3" id="text-orgb6804d3">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TOKENS</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb134057">
<h3 id="orgb134057">Set Up</h3>
<div class="outline-text-3" id="text-orgb134057"></div>
<div class="outline-4" id="outline-container-org90ed996">
<h4 id="org90ed996">Our Data</h4>
<div class="outline-text-4" id="text-org90ed996">
<div class="highlight">
<pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org42911ca">
<h4 id="org42911ca">The Idiotic Names</h4>
<div class="outline-text-4" id="text-org42911ca">
<div class="highlight">
<pre><span></span><span class="n">np</span> <span class="o">=</span> <span class="n">numpy</span>
<span class="n">rnd</span> <span class="o">=</span> <span class="n">random</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgcd02f72">
<h2 id="orgcd02f72">Middle</h2>
<div class="outline-text-2" id="text-orgcd02f72">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">data_generator</span><span class="p">(</span><span class="n">Q1</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">Q2</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                   <span class="n">pad</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Generator function that yields batches of data</span>

<span class="sd">    Args:</span>
<span class="sd">       Q1 (list): List of transformed (to tensor) questions.</span>
<span class="sd">       Q2 (list): List of transformed (to tensor) questions.</span>
<span class="sd">       batch_size (int): Number of elements per batch.</span>
<span class="sd">       pad (int, optional): Pad character from the vocab. Defaults to 1.</span>
<span class="sd">       shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.</span>

<span class="sd">    Yields:</span>
<span class="sd">       tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)</span>
<span class="sd">       NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates</span>
<span class="sd">             input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates</span>
<span class="sd">    """</span>

    <span class="n">input1</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">len_q</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Q1</span><span class="p">)</span>
    <span class="n">question_indexes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">len_q</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">rnd</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">question_indexes</span><span class="p">)</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">len_q</span><span class="p">:</span>
            <span class="c1"># if idx is greater than or equal to len_q, set idx accordingly </span>
            <span class="c1"># (Hint: look at the instructions above)</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># shuffle to get random batches if shuffle is set to True</span>
            <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
                <span class="n">rnd</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">question_indexes</span><span class="p">)</span>

        <span class="c1"># get questions at the `question_indexes[idx]` position in Q1 and Q2</span>
        <span class="n">q1</span> <span class="o">=</span> <span class="n">Q1</span><span class="p">[</span><span class="n">question_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>
        <span class="n">q2</span> <span class="o">=</span> <span class="n">Q2</span><span class="p">[</span><span class="n">question_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>

        <span class="c1"># increment idx by 1</span>
        <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># append q1</span>
        <span class="n">input1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q1</span><span class="p">)</span>
        <span class="c1"># append q2</span>
        <span class="n">input2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q2</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input1</span><span class="p">)</span> <span class="o">==</span> <span class="n">batch_size</span><span class="p">:</span>
            <span class="c1"># determine max_len as the longest question in input1 & input 2</span>
            <span class="c1"># Hint: use the `max` function. </span>
            <span class="c1"># take max of input1 & input2 and then max out of the two of them.</span>
            <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">question</span><span class="p">)</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">input1</span><span class="p">),</span>
                          <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">question</span><span class="p">)</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">input2</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">max_len</span><span class="p">)</span>
            <span class="c1"># pad to power-of-2 (Hint: look at the instructions above)</span>
            <span class="n">max_len</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">max_len</span><span class="p">)))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">max_len</span><span class="p">)</span>
            <span class="n">b1</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">b2</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">q1</span><span class="p">,</span> <span class="n">q2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">):</span>
                <span class="c1"># add [pad] to q1 until it reaches max_len</span>
                <span class="n">q1</span> <span class="o">=</span> <span class="n">q1</span> <span class="o">+</span> <span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">q1</span><span class="p">))</span> <span class="o">*</span> <span class="p">[</span><span class="n">pad</span><span class="p">])</span>
                <span class="c1"># add [pad] to q2 until it reaches max_len</span>
                <span class="n">q2</span> <span class="o">=</span> <span class="n">q2</span> <span class="o">+</span> <span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">q2</span><span class="p">))</span> <span class="o">*</span> <span class="p">[</span><span class="n">pad</span><span class="p">])</span>
                <span class="c1"># append q1</span>
                <span class="n">b1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q1</span><span class="p">)</span>
                <span class="c1"># append q2</span>
                <span class="n">b2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q2</span><span class="p">)</span>
            <span class="c1"># use b1 and b2</span>
            <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span>
            <span class="c1"># reset the batches</span>
            <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>  <span class="c1"># reset the batches</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-org682fd6b">
<h3 id="org682fd6b">Try It Out</h3>
<div class="outline-text-3" id="text-org682fd6b">
<div class="highlight">
<pre><span></span><span class="n">rnd</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">34</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_two</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">result_1</span><span class="p">,</span> <span class="n">result_2</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"First questions  : </span><span class="se">\n</span><span class="si">{</span><span class="n">result_1</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Second questions : </span><span class="se">\n</span><span class="si">{</span><span class="n">result_2</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org0d92c7b">
11
16
First questions  : 
[[  34   37   13   50  536 1303 6428   25  924  157   28    1    1    1
     1    1]
 [  34   95  573 1444 2343   28    1    1    1    1    1    1    1    1
     1    1]]

Second questions : 
[[  34   37   13  575 1303 6428   25  924  157   28    1    1    1    1
     1    1]
 [   9  151   25  573 5642   28    1    1    1    1    1    1    1    1
     1    1]]
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orgedd85b8">
<h2 id="orgedd85b8">Bundling It Up</h2>
<div class="outline-text-2" id="text-orgedd85b8"></div>
<div class="outline-3" id="outline-container-orgf224535">
<h3 id="orgf224535">Imports</h3>
<div class="outline-text-3" id="text-orgf224535">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>

<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TOKENS</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org02641a2">
<h3 id="org02641a2">The Data Generator</h3>
<div class="outline-text-3" id="text-org02641a2">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DataGenerator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Batch Generator for Quora question dataset</span>

<span class="sd">    Args:</span>
<span class="sd">     question_one: tensorized question 1</span>
<span class="sd">     question_two: tensorized question 2</span>
<span class="sd">     batch_size: size of generated batches</span>
<span class="sd">     padding: token to use to pad the lists</span>
<span class="sd">     shuffle: whether to shuffle the questions around</span>
<span class="sd">    """</span>
    <span class="n">question_one</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">question_two</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">TOKENS</span><span class="o">.</span><span class="n">padding</span>
    <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span>
    <span class="n">_batch</span><span class="p">:</span> <span class="nb">iter</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org17ba17d">
<h4 id="org17ba17d">The Generator Definition</h4>
<div class="outline-text-4" id="text-org17ba17d">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">data_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Generator function that yields batches of data</span>

<span class="sd">    Yields:</span>
<span class="sd">       tuple: (batch_question_1, batch_question_2)</span>
<span class="sd">    """</span>
    <span class="n">unpadded_1</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">unpadded_2</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">number_of_questions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">question_one</span><span class="p">)</span>
    <span class="n">question_indexes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">number_of_questions</span><span class="p">))</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">question_indexes</span><span class="p">)</span>

    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;=</span> <span class="n">number_of_questions</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
                <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">question_indexes</span><span class="p">)</span>

        <span class="n">unpadded_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">question_one</span><span class="p">[</span><span class="n">question_indexes</span><span class="p">[</span><span class="n">index</span><span class="p">]])</span>
        <span class="n">unpadded_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">question_two</span><span class="p">[</span><span class="n">question_indexes</span><span class="p">[</span><span class="n">index</span><span class="p">]])</span>

        <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unpadded_1</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">question</span><span class="p">)</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">unpadded_1</span><span class="p">),</span>
                          <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">question</span><span class="p">)</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">unpadded_2</span><span class="p">))</span>
            <span class="n">max_len</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="nb">int</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">max_len</span><span class="p">)))</span>
            <span class="n">padded_1</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">padded_2</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">question_1</span><span class="p">,</span> <span class="n">question_2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unpadded_1</span><span class="p">,</span> <span class="n">unpadded_2</span><span class="p">):</span>
                <span class="n">padded_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">question_1</span> <span class="o">+</span> <span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">question_1</span><span class="p">))</span> <span class="o">*</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">]))</span>
                <span class="n">padded_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">question_2</span> <span class="o">+</span>  <span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">question_2</span><span class="p">))</span> <span class="o">*</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">]))</span>
            <span class="k">yield</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">padded_1</span><span class="p">),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">padded_2</span><span class="p">)</span>
            <span class="n">unpadded_1</span><span class="p">,</span> <span class="n">unpadded_2</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb57d6f2">
<h4 id="orgb57d6f2">The Generator</h4>
<div class="outline-text-4" id="text-orgb57d6f2">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""The generator instance"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_generator</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgfb3b215">
<h4 id="orgfb3b215">The Iter Method</h4>
<div class="outline-text-4" id="text-orgfb3b215">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org143f79f">
<h4 id="org143f79f">The Next Method</h4>
<div class="outline-text-4" id="text-org143f79f">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org8d00941">
<h3 id="org8d00941">Check It Out</h3>
<div class="outline-text-3" id="text-org8d00941">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">DataGenerator</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_two</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">34</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">result_1</span><span class="p">,</span> <span class="n">result_2</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"First questions  : </span><span class="se">\n</span><span class="si">{</span><span class="n">result_1</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Second questions : </span><span class="se">\n</span><span class="si">{</span><span class="n">result_2</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org1a21431">
First questions  : 
[[  34   37   13   50  536 1303 6428   25  924  157   28    1    1    1
     1    1]
 [  34   95  573 1444 2343   28    1    1    1    1    1    1    1    1
     1    1]]

Second questions : 
[[  34   37   13  575 1303 6428   25  924  157   28    1    1    1    1
     1    1]
 [   9  151   25  573 5642   28    1    1    1    1    1    1    1    1
     1    1]]
</pre></div>
</div>
</div>
</div>
</article>
</div>
<ul class="pager postindexpager clearfix">
<li class="previous"><a href="index-21.html" rel="prev">Newer posts</a></li>
<li class="next"><a href="index-19.html" rel="next">Older posts</a></li>
</ul>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script><!--End of body content-->
<footer id="footer">Scribbles by <a href="mailto:cloisteredmonkey.jmark@slmail.me">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>
<div id="license" xmlns:cc="http://creativecommons.org/ns#">This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" rel="license noopener noreferrer" style="display:inline-block;" target="_blank">CC BY 4.0 <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></div>
</footer>
</div>
</div>
<script src="assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
