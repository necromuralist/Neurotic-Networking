<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Studies in Deep Learning." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Neurotic Networking (old posts, page 22) | Neurotic Networking</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/index-22.html" rel="canonical">
<link href="." rel="prev" type="text/html">
<link href="index-21.html" rel="next" type="text/html"><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
<link href="apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="site.webmanifest" rel="manifest">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="."><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<div class="postindex">
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/gans/controllable-generation/">Controllable Generation</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/gans/controllable-generation/" rel="bookmark"><time class="published dt-published" datetime="2021-05-02T16:23:09-07:00" itemprop="datePublished" title="2021-05-02 16:23">2021-05-02 16:23</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div class="outline-2" id="outline-container-org9c39edc">
<h2 id="org9c39edc">Controllable Generation</h2>
<div class="outline-text-2" id="text-org9c39edc">
<p>In this notebook, we're going to implement a GAN controllability method using gradients from a classifier. By training a classifier to recognize a relevant feature, we can use it to change the generator's inputs (z-vectors) to make it generate images with more or less of that feature.</p>
<p>We will be started we off with a pre-trained generator and classifier, so that we can focus on the controllability aspects.</p>
<p>The classifier has the same archicture as the earlier critic (remember that the discriminator/critic is simply a classifier used to classify real and fake).</p>
</div>
<div class="outline-3" id="outline-container-orgfa13176">
<h3 id="orgfa13176">CelebA</h3>
<div class="outline-text-3" id="text-orgfa13176">
<p>Instead of the MNIST dataset, we will be using <a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">CelebA</a>. CelebA is a dataset of annotated celebrity images. Since they are colored (not black-and-white), the images have three channels for red, green, and blue (RGB). We'll be using the pre-built <a href="https://pytorch.org/vision/stable/datasets.html?highlight=celeba#torchvision.datasets.CelebA">pytorch Celeba dataset</a>.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orga6d2090">
<h3 id="orga6d2090">Imports</h3>
<div class="outline-text-3" id="text-orga6d2090">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">pickle</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">CelebA</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># my stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgcb4a522">
<h3 id="orgcb4a522">Set Up</h3>
<div class="outline-text-3" id="text-orgcb4a522"></div>
<div class="outline-4" id="outline-container-orgddb0497">
<h4 id="orgddb0497">The Timer</h4>
<div class="outline-text-4" id="text-orgddb0497">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org7a6ef2b">
<h4 id="org7a6ef2b">The Random Seed</h4>
<div class="outline-text-4" id="text-org7a6ef2b">
<div class="highlight">
<pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org086a923">
<h4 id="org086a923">Plotting</h4>
<div class="outline-text-4" id="text-org086a923">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"controllable-generation"</span>
<span class="n">OUTPUT</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"files/posts/gans/</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">/"</span>

<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span> <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">])</span>
<span class="n">PLOT</span> <span class="o">=</span> <span class="n">Plot</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org25c78a4">
<h4 id="org25c78a4">Paths</h4>
<div class="outline-text-4" id="text-org25c78a4">
<div class="highlight">
<pre><span></span><span class="n">base_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/gans/celeba/"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">base_path</span><span class="o">.</span><span class="n">is_dir</span><span class="p">()</span>

<span class="n">prebuilt_models</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">celeba</span> <span class="o">=</span> <span class="n">base_path</span><span class="o">/</span><span class="s2">"pretrained_celeba.pth"</span><span class="p">,</span>
    <span class="n">classifier</span> <span class="o">=</span> <span class="n">base_path</span><span class="o">/</span><span class="s2">"pretrained_classifier.pth"</span>
<span class="p">)</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/pytorch-data/"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">data_path</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
    <span class="n">data_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">prebuilt_models</span><span class="o">.</span><span class="n">celeba</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">prebuilt_models</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga6c59cb">
<h4 id="orga6c59cb">Helpers</h4>
<div class="outline-text-4" id="text-orga6c59cb">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">save_tensor_images</span><span class="p">(</span><span class="n">image_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                       <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
                       <span class="n">title</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                       <span class="n">folder</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/gans</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">/"</span><span class="p">,</span>
                       <span class="n">num_images</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Plot an Image Tensor</span>

<span class="sd">    Args:</span>
<span class="sd">     image_tensor: tensor with the values for the image to plot</span>
<span class="sd">     filename: name to save the file under</span>
<span class="sd">     folder: path to put the file in</span>
<span class="sd">     title: title for the image</span>
<span class="sd">     num_images: how many images from the tensor to use</span>
<span class="sd">     size: the dimensions for each image</span>
<span class="sd">    """</span>
    <span class="n">image_tensor</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_tensor</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">image_unflat</span> <span class="o">=</span> <span class="n">image_tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
    <span class="n">image_grid</span> <span class="o">=</span> <span class="n">make_grid</span><span class="p">(</span><span class="n">image_unflat</span><span class="p">[:</span><span class="n">num_images</span><span class="p">],</span> <span class="n">nrow</span><span class="o">=</span><span class="n">nrow</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image_grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelbottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                       <span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelleft</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">folder</span> <span class="o">+</span> <span class="n">filename</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[[file:</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">]]"</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org73c2ee7">
<h3 id="org73c2ee7">The Generator</h3>
<div class="outline-text-3" id="text-org73c2ee7">
<p>This is mostly the same as the other Generators but the images are now color so the channels are different and the model has more initial hidden nodes (and one extra hidden block).</p>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Generator for the celeba images</span>

<span class="sd">    Args:</span>
<span class="sd">       z_dim: the dimension of the noise vector, a scalar</span>
<span class="sd">       im_chan: the number of channels in the images, fitted for the dataset used, a scalar</span>
<span class="sd">             (CelebA is rgb, so 3 is our default)</span>
<span class="sd">       hidden_dim: the inner dimension, a scalar</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">im_chan</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span> <span class="o">=</span> <span class="n">z_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gen</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">im_chan</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">final_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_gen_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                       <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                       <span class="n">final_layer</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Create a sequence of operations corresponding to a generator block of DCGAN</span>

<span class="sd">        - a transposed convolution</span>
<span class="sd">        - a batchnorm (except in the final layer)</span>
<span class="sd">        - an activation.</span>

<span class="sd">       Args:</span>
<span class="sd">           input_channels: how many channels the input feature representation has</span>
<span class="sd">           output_channels: how many channels the output feature representation should have</span>
<span class="sd">           kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)</span>
<span class="sd">           stride: the stride of the convolution</span>
<span class="sd">           final_layer: a boolean, true if it is the final layer and false otherwise </span>
<span class="sd">                     (affects activation and batchnorm)</span>
<span class="sd">       Returns:</span>
<span class="sd">        sequence of layers</span>
<span class="sd">       """</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">final_layer</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">output_channels</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Complete a forward pass of the generator</span>

<span class="sd">       Args:</span>
<span class="sd">       Parameters:</span>
<span class="sd">           noise: a noise tensor with dimensions (n_samples, z_dim)</span>

<span class="sd">       Returns:</span>
<span class="sd">        generated images.</span>

<span class="sd">       """</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">noise</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">noise</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gen</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgffe7949">
<h4 id="orgffe7949">Noise Alias</h4>
<div class="outline-text-4" id="text-orgffe7949">
<p>I still don't get thisâ€¦</p>
<div class="highlight">
<pre><span></span><span class="n">get_noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd0df5be">
<h4 id="orgd0df5be">Classifier</h4>
<div class="outline-text-4" id="text-orgd0df5be">
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""The Classifier (Discriminator)</span>

<span class="sd">    Args:</span>
<span class="sd">       im_chan: the number of channels in the images, fitted for the dataset used, a scalar</span>
<span class="sd">             (CelebA is rgb, so 3 is our default)</span>
<span class="sd">       n_classes: the total number of classes in the dataset, an integer scalar</span>
<span class="sd">       hidden_dim: the inner dimension, a scalar</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im_chan</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_classifier_block</span><span class="p">(</span><span class="n">im_chan</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_classifier_block</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_classifier_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_classifier_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">final_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_classifier_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                              <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                              <span class="n">final_layer</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Create a sequence of operations corresponding to a classifier block</span>

<span class="sd">        - a convolution</span>
<span class="sd">        - a batchnorm (except in the final layer)</span>
<span class="sd">        - an activation (except in the final layer).</span>

<span class="sd">       Args:</span>
<span class="sd">           input_channels: how many channels the input feature representation has</span>
<span class="sd">           output_channels: how many channels the output feature representation should have</span>
<span class="sd">           kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)</span>
<span class="sd">           stride: the stride of the convolution</span>
<span class="sd">           final_layer: a boolean, true if it is the final layer and false otherwise </span>
<span class="sd">                     (affects activation and batchnorm)</span>

<span class="sd">       Returns:</span>
<span class="sd">        Sequence of layers</span>
<span class="sd">       """</span>
        <span class="k">if</span> <span class="n">final_layer</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">output_channels</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Complete a forward pass of the classifier</span>

<span class="sd">       Args:</span>
<span class="sd">           image: a flattened image tensor with im_chan channels</span>

<span class="sd">       Returns:</span>
<span class="sd">        an n_classes-dimension tensor representing fake/real.</span>
<span class="sd">       """</span>
        <span class="n">class_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">class_pred</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_pred</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org2c41929">
<h2 id="org2c41929">Middle</h2>
<div class="outline-text-2" id="text-org2c41929"></div>
<div class="outline-3" id="outline-container-orge018ef7">
<h3 id="orge018ef7">Specifying Parameters</h3>
<div class="outline-text-3" id="text-orge018ef7">
<p>Before we begin training, we need to specify a few parameters:</p>
<ul class="org-ul">
<li>z<sub>dim</sub>: the dimension of the noise vector</li>
<li>batch<sub>size</sub>: the number of images per forward/backward pass</li>
<li>device: the device type</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'cuda'</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org7923ddf">
<h3 id="org7923ddf">Train a Classifier</h3>
<div class="outline-text-3" id="text-org7923ddf">
<p><b>Note:</b> the <code>Celeba</code> class will sometimes raise an exception:</p>
<pre class="example" id="orga8fc657">
Traceback (most recent call last):
  File "/home/neurotic/download_celeba.py", line 27, in &lt;module&gt;
    CelebA(data_path, split='train', download=True, transform=transform),
  File "/home/neurotic/.conda/envs/neurotic-pytorch/lib/python3.9/site-packages/torchvision/datasets/celeba.py", line 77, in __init__
    self.download()
  File "/home/neurotic/.conda/envs/neurotic-pytorch/lib/python3.9/site-packages/torchvision/datasets/celeba.py", line 131, in download
    with zipfile.ZipFile(os.path.join(self.root, self.base_folder, "img_align_celeba.zip"), "r") as f:
  File "/home/neurotic/.conda/envs/neurotic-pytorch/lib/python3.9/zipfile.py", line 1257, in __init__
    self._RealGetContents()
  File "/home/neurotic/.conda/envs/neurotic-pytorch/lib/python3.9/zipfile.py", line 1324, in _RealGetContents
    raise BadZipFile("File is not a zip file")
zipfile.BadZipFile: File is not a zip file
</pre>
<p>According to <a href="https://github.com/pytorch/vision/issues/2262">this bug report</a> the problem is that the files are stored on Google Drive which has a limit on the amount of data you can download per day and if it's been exceeded then when you try to download =img<sub>align</sub><sub>celeba.zip</sub>" instead of the zip file you get an HTML page (of the same name) with this message:</p>
<pre class="example" id="org87e6100">
Sorry, you can't view or download this file at this time.

Too many users have viewed or downloaded this file recently. Please try accessing the file again later. If the file you are trying to access is particularly large or is shared with many people, it may take up to 24 hours to be able to view or download the file. If you still can't access a file after 24 hours, contact your domain administrator.
</pre>
<p>The data is available on <a href="https://www.kaggle.com/jessicali9530/celeba-dataset?select=img_align_celeba">kaggle</a> so if you download it from them and put the file where the bad file is it should work - except of course, it doesn't. It turns out that some of the text files were also replaced with warnings that the download limit was exceeded so I needed to download those as well, but the files on kaggle are formatted as comma-separated files while the original files are space-separated, but even replacing the commas with spaces won't pass the MD5 check - maybe the line endings are different too? Anyway, the images work so I just waited a day and downloaded the text files from the google drive, which seemed to fix it.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train_classifier</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span> <span class="n">data_path</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                     <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">display_step</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                     <span class="n">classifier</span><span class="p">:</span> <span class="n">Classifier</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Trains the Classifier</span>

<span class="sd">    Args:</span>
<span class="sd">     filename: path to save the state-dict to</span>
<span class="sd">     data_path: path to the celeba data</span>

<span class="sd">    Returns:</span>
<span class="sd">     classifier losses</span>
<span class="sd">    """</span>
    <span class="n">label_indices</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">40</span><span class="p">)</span>

    <span class="n">display_step</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="n">beta_1</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">beta_2</span> <span class="o">=</span> <span class="mf">0.999</span>
    <span class="n">image_size</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">best_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)),</span>
    <span class="p">])</span>

    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">CelebA</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">data_path</span><span class="p">),</span> <span class="n">split</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">classifier</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">classifier</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span><span class="n">n_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">label_indices</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">class_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">beta_1</span><span class="p">,</span> <span class="n">beta_2</span><span class="p">))</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>

    <span class="n">cur_step</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">classifier_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># classifier_val_losses = []</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">real</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
            <span class="n">real</span> <span class="o">=</span> <span class="n">real</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:,</span> <span class="n">label_indices</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

            <span class="n">class_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">class_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>
            <span class="n">class_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">class_pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">class_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># Calculate the gradients</span>
            <span class="n">class_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># Update the weights</span>
            <span class="n">classifier_losses</span> <span class="o">+=</span> <span class="p">[</span><span class="n">class_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="c1"># Keep track of the average classifier loss</span>

            <span class="c1">## Visualization code ##</span>
            <span class="k">if</span> <span class="n">classifier_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s2">"classifier"</span><span class="p">:</span> <span class="n">classifier</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()},</span> <span class="n">filename</span><span class="p">)</span>
                <span class="n">best_loss</span> <span class="o">=</span> <span class="n">classifier_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">cur_step</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">cur_step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">class_mean</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">classifier_losses</span><span class="p">[</span><span class="o">-</span><span class="n">display_step</span><span class="p">:])</span> <span class="o">/</span> <span class="n">display_step</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Step </span><span class="si">{</span><span class="n">cur_step</span><span class="si">}</span><span class="s2">: Classifier loss: </span><span class="si">{</span><span class="n">class_mean</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="n">step_bins</span> <span class="o">=</span> <span class="mi">20</span>
            <span class="n">cur_step</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">classifier_losses</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">classifier_state_dict</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/gans/celeba/trained_classifier.pth"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">classifier_losses</span> <span class="o">=</span> <span class="n">train_classifier</span><span class="p">(</span><span class="n">classifier_state_dict</span><span class="p">,</span> <span class="n">data_path</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgfb3b415">
Started: 2021-05-10 16:52:26.506156
Step 500: Classifier loss: 0.2693843246996403
Step 1000: Classifier loss: 0.24250468423962593
Step 1500: Classifier loss: 0.2307623517513275
Step 2000: Classifier loss: 0.22525288465619087
Step 2500: Classifier loss: 0.22275795283913613
Step 3000: Classifier loss: 0.2154263758957386
Step 3500: Classifier loss: 0.21474265044927596
Step 4000: Classifier loss: 0.21102887812256813
Step 4500: Classifier loss: 0.20789319404959677
Step 5000: Classifier loss: 0.20887315857410432
Step 5500: Classifier loss: 0.20212965056300164
Step 6000: Classifier loss: 0.20280044555664062
Step 6500: Classifier loss: 0.20041452285647393
Step 7000: Classifier loss: 0.19656063199043275
Step 7500: Classifier loss: 0.19845477828383445
Step 8000: Classifier loss: 0.19205777409672736
Step 8500: Classifier loss: 0.19296112078428268
Step 9000: Classifier loss: 0.19257169529795648
Step 9500: Classifier loss: 0.18672975289821625
Step 10000: Classifier loss: 0.18999777460098266
Step 10500: Classifier loss: 0.18432555946707727
Step 11000: Classifier loss: 0.18430076670646667
Step 11500: Classifier loss: 0.18558891993761062
Step 12000: Classifier loss: 0.17852741411328316
Step 12500: Classifier loss: 0.18172698724269867
Step 13000: Classifier loss: 0.1773110607266426
Step 13500: Classifier loss: 0.17672735232114792
Step 14000: Classifier loss: 0.17991324526071548
Step 14500: Classifier loss: 0.17025035387277604
Step 15000: Classifier loss: 0.17529139894247056
Step 15500: Classifier loss: 0.17104978796839715
Step 16000: Classifier loss: 0.17034502020478248
Step 16500: Classifier loss: 0.17325083956122397
Step 17000: Classifier loss: 0.1642009498178959
Step 17500: Classifier loss: 0.16845661264657974
Step 18000: Classifier loss: 0.1664019832611084
Step 18500: Classifier loss: 0.1633680825829506
Step 19000: Classifier loss: 0.16797509816288947
Step 19500: Classifier loss: 0.15925687023997306
Step 20000: Classifier loss: 0.16292004188895226
Step 20500: Classifier loss: 0.16216046965122222
Step 21000: Classifier loss: 0.15743515598773955
Step 21500: Classifier loss: 0.16243972438573837
Step 22000: Classifier loss: 0.1545857997238636
Step 22500: Classifier loss: 0.15797922548651694
Step 23000: Classifier loss: 0.15804208835959435
Step 23500: Classifier loss: 0.15213489854335785
Step 24000: Classifier loss: 0.15730918619036674
Step 24500: Classifier loss: 0.1511693196296692
Step 25000: Classifier loss: 0.1527680770754814
Step 25500: Classifier loss: 0.15510675182938577
Step 26000: Classifier loss: 0.14683012741804122
Step 26500: Classifier loss: 0.15305917632579805
Step 27000: Classifier loss: 0.14754199008643626
Step 27500: Classifier loss: 0.14820717003941536
Step 28000: Classifier loss: 0.15238315638899802
Step 28500: Classifier loss: 0.14171919177472592
Step 29000: Classifier loss: 0.14881789454817773
Step 29500: Classifier loss: 0.1449408364146948
Step 30000: Classifier loss: 0.1441956951916218
Step 30500: Classifier loss: 0.1483478535115719
Step 31000: Classifier loss: 0.13893532317876817
Step 31500: Classifier loss: 0.1450331158787012
Step 32000: Classifier loss: 0.14139907719194889
Step 32500: Classifier loss: 0.1396861730515957
Step 33000: Classifier loss: 0.1451952086240053
Step 33500: Classifier loss: 0.1358419010192156
Step 34000: Classifier loss: 0.14111693547666074
Step 34500: Classifier loss: 0.1400791739821434
Step 35000: Classifier loss: 0.1358947957903147
Step 35500: Classifier loss: 0.14151665523648263
Step 36000: Classifier loss: 0.1336766537129879
Step 36500: Classifier loss: 0.13722201707959175
Step 37000: Classifier loss: 0.1379301232844591
Step 37500: Classifier loss: 0.13219603390991688
Step 38000: Classifier loss: 0.13811730867624283
Step 38500: Classifier loss: 0.13158722695708275
Step 39000: Classifier loss: 0.13359902986884117
Step 39500: Classifier loss: 0.1366793801188469
Step 40000: Classifier loss: 0.12849617034196853
Step 40500: Classifier loss: 0.13549049003422262
Step 41000: Classifier loss: 0.12929423077404498
Step 41500: Classifier loss: 0.13080933578312398
Step 42000: Classifier loss: 0.13500430592894555
Step 42500: Classifier loss: 0.12454062223434448
Step 43000: Classifier loss: 0.13214491476118564
Step 43500: Classifier loss: 0.1284936859458685
Step 44000: Classifier loss: 0.12763021168112754
Step 44500: Classifier loss: 0.13298917169868946
Step 45000: Classifier loss: 0.12208985219895839
Step 45500: Classifier loss: 0.129048362582922
Step 46000: Classifier loss: 0.12678204217553138
Step 46500: Classifier loss: 0.12455842156708241
Step 47000: Classifier loss: 0.1303500325381756
Step 47500: Classifier loss: 0.12025414818525314
Step 48000: Classifier loss: 0.12684993542730807
Step 48500: Classifier loss: 0.1252559674978256
Step 49000: Classifier loss: 0.12153738121688366
Step 49500: Classifier loss: 0.12777481034398078
Step 50000: Classifier loss: 0.118936713129282
Step 50500: Classifier loss: 0.12405500474572181
Ended: 2021-05-10 18:56:36.980805
Elapsed: 2:04:10.474649
</pre>
<div class="highlight">
<pre><span></span><span class="n">losses</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Loss</span><span class="o">=</span><span class="n">classifier_losses</span><span class="p">))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">"Loss"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Classifier Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">tan</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"classifier_loss"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/gans/controllable-generation/classifier_loss.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object></div>
<div class="outline-4" id="outline-container-orgd9f1099">
<h4 id="orgd9f1099">Take Two</h4>
<div class="outline-text-4" id="text-orgd9f1099">
<div class="highlight">
<pre><span></span><span class="n">n_classes</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span><span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">class_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">classifier_state_dict</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">))[</span><span class="s2">"classifier"</span><span class="p">]</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">class_dict</span><span class="p">)</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">classifier_losses</span> <span class="o">=</span> <span class="n">train_classifier</span><span class="p">(</span><span class="n">classifier_state_dict</span><span class="p">,</span> <span class="n">data_path</span><span class="p">,</span>
                                         <span class="n">epochs</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                                         <span class="n">classifier</span><span class="o">=</span><span class="n">classifier</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgd7ffb6d">
Started: 2021-05-11 16:02:16.181203
Step 500: Classifier loss: 0.1181784438341856
Step 1000: Classifier loss: 0.12448641647398472
Step 1500: Classifier loss: 0.1214247584193945
Step 2000: Classifier loss: 0.1198666417747736
Step 2500: Classifier loss: 0.1255625690817833
Step 3000: Classifier loss: 0.11589906251430511
Step 3500: Classifier loss: 0.12224359685182572
Step 4000: Classifier loss: 0.11944249965250492
Step 4500: Classifier loss: 0.1175859476029873
Step 5000: Classifier loss: 0.12318077574670315
Step 5500: Classifier loss: 0.11450052106380462
Step 6000: Classifier loss: 0.11944048409163951
Step 6500: Classifier loss: 0.11928777326643467
Step 7000: Classifier loss: 0.11463624723255635
Step 7500: Classifier loss: 0.12107200682163238
Step 8000: Classifier loss: 0.11355004295706748
Step 8500: Classifier loss: 0.11719673483073711
Step 9000: Classifier loss: 0.11821492326259612
Step 9500: Classifier loss: 0.11198448015749454
Step 10000: Classifier loss: 0.11870198084414005
Step 10500: Classifier loss: 0.11221958647668362
Step 11000: Classifier loss: 0.11476752410829068
Step 11500: Classifier loss: 0.11772396117448806
Step 12000: Classifier loss: 0.10936097744107247
Step 12500: Classifier loss: 0.11677812692523003
Step 13000: Classifier loss: 0.11107682411372662
Step 13500: Classifier loss: 0.11222303664684295
Step 14000: Classifier loss: 0.11760448211431504
Step 14500: Classifier loss: 0.10662877394258977
Step 15000: Classifier loss: 0.11471863305568696
Step 15500: Classifier loss: 0.11056565625965595
Step 16000: Classifier loss: 0.11046012189984322
Step 16500: Classifier loss: 0.1158019468486309
Step 17000: Classifier loss: 0.10568901741504669
Step 17500: Classifier loss: 0.11223984396457672
Step 18000: Classifier loss: 0.11002579489350318
Step 18500: Classifier loss: 0.10752195838093757
Step 19000: Classifier loss: 0.11419818633794784
Step 19500: Classifier loss: 0.10464896529912948
Step 20000: Classifier loss: 0.11005591739714146
Step 20500: Classifier loss: 0.10996675519645215
Step 21000: Classifier loss: 0.10543355357646943
Step 21500: Classifier loss: 0.11205300988256932
Step 22000: Classifier loss: 0.1038715885579586
Step 22500: Classifier loss: 0.10818033437430859
Step 23000: Classifier loss: 0.10912492156028747
Step 23500: Classifier loss: 0.10302072758972645
Step 24000: Classifier loss: 0.11008756360411644
Step 24500: Classifier loss: 0.10342664630711079
Step 25000: Classifier loss: 0.10618587562441825
Step 25500: Classifier loss: 0.10913233712315559
Step 26000: Classifier loss: 0.10061963592469693
Step 26500: Classifier loss: 0.10828037586808205
Step 27000: Classifier loss: 0.10266246040165425
Step 27500: Classifier loss: 0.1047897623181343
Step 28000: Classifier loss: 0.10866250747442245
Step 28500: Classifier loss: 0.09820086953043938
Step 29000: Classifier loss: 0.10674160474538803
Step 29500: Classifier loss: 0.10230921612679958
Step 30000: Classifier loss: 0.1021555609256029
Step 30500: Classifier loss: 0.10775842162966728
Step 31000: Classifier loss: 0.09722121758759021
Step 31500: Classifier loss: 0.10439497400820255
Step 32000: Classifier loss: 0.10229390095174312
Step 32500: Classifier loss: 0.10003190772235393
Step 33000: Classifier loss: 0.10617333140969276
Step 33500: Classifier loss: 0.09686395044624806
Step 34000: Classifier loss: 0.10285020883381367
Step 34500: Classifier loss: 0.10199978332221508
Step 35000: Classifier loss: 0.09819360673427582
Step 35500: Classifier loss: 0.10397693109512329
Step 36000: Classifier loss: 0.09642438031733036
Step 36500: Classifier loss: 0.10087257397174836
Step 37000: Classifier loss: 0.10197833214700222
Step 37500: Classifier loss: 0.09598418261110783
Step 38000: Classifier loss: 0.10283542364835739
Step 38500: Classifier loss: 0.09644483177363873
Step 39000: Classifier loss: 0.09908602401614189
Step 39500: Classifier loss: 0.10129908196628094
Step 40000: Classifier loss: 0.0939527989178896
Step 40500: Classifier loss: 0.1016722819507122
Step 41000: Classifier loss: 0.09578396078944207
Step 41500: Classifier loss: 0.09706279496848583
Step 42000: Classifier loss: 0.10207961940765381
Step 42500: Classifier loss: 0.09211373472213745
Step 43000: Classifier loss: 0.09958744782209396
Step 43500: Classifier loss: 0.09534277887642384
Step 44000: Classifier loss: 0.0952163600474596
Step 44500: Classifier loss: 0.10136887782812118
Step 45000: Classifier loss: 0.09021547995507717
Step 45500: Classifier loss: 0.09812712541222572
Step 46000: Classifier loss: 0.09560927426815033
Step 46500: Classifier loss: 0.09358323478698731
Step 47000: Classifier loss: 0.09991893386840821
Step 47500: Classifier loss: 0.0899157041311264
Step 48000: Classifier loss: 0.096542285323143
Step 48500: Classifier loss: 0.09535252919793129
Step 49000: Classifier loss: 0.09194727616012097
Step 49500: Classifier loss: 0.09831891848146915
Step 50000: Classifier loss: 0.0901611197590828
Step 50500: Classifier loss: 0.09490065774321556
Ended: 2021-05-11 18:06:19.399986
Elapsed: 2:04:03.218783
</pre>
<div class="highlight">
<pre><span></span><span class="n">losses</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Loss</span><span class="o">=</span><span class="n">classifier_losses</span><span class="p">))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">"Loss"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Classifier Loss Session 2"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">tan</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"classifier_loss_2"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/gans/controllable-generation/classifier_loss_2.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object></div>
</div>
<div class="outline-4" id="outline-container-orgfdd3dc6">
<h4 id="orgfdd3dc6">Take Three</h4>
<div class="outline-text-4" id="text-orgfdd3dc6">
<div class="highlight">
<pre><span></span><span class="n">n_classes</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span><span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">class_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">classifier_state_dict</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">))[</span><span class="s2">"classifier"</span><span class="p">]</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">class_dict</span><span class="p">)</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">classifier_losses</span> <span class="o">=</span> <span class="n">train_classifier</span><span class="p">(</span><span class="n">classifier_state_dict</span><span class="p">,</span> <span class="n">data_path</span><span class="p">,</span>
                                         <span class="n">epochs</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                                         <span class="n">classifier</span><span class="o">=</span><span class="n">classifier</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org8337dfb">
Started: 2021-05-11 21:11:32.420506
Step 500: Classifier loss: 0.09006546361744404
Step 1000: Classifier loss: 0.09647199404239655
Step 1500: Classifier loss: 0.092734768897295
Step 2000: Classifier loss: 0.09196118661761284
Step 2500: Classifier loss: 0.09789373110234738
Step 3000: Classifier loss: 0.08788785541057587
Step 3500: Classifier loss: 0.0945415845811367
Step 4000: Classifier loss: 0.09308994428813458
Step 4500: Classifier loss: 0.09022623193264008
Step 5000: Classifier loss: 0.09615834753215313
Step 5500: Classifier loss: 0.08742603194713593
Step 6000: Classifier loss: 0.09316775412857532
Step 6500: Classifier loss: 0.09275233449041843
Step 7000: Classifier loss: 0.08822614887356758
Step 7500: Classifier loss: 0.09528714890778064
Step 8000: Classifier loss: 0.08681275172531605
Step 8500: Classifier loss: 0.09150236696004868
Step 9000: Classifier loss: 0.09338522186875343
Step 9500: Classifier loss: 0.08638478130102158
Step 10000: Classifier loss: 0.09388372772932052
Step 10500: Classifier loss: 0.08720742921531201
Step 11000: Classifier loss: 0.09009483934938908
Step 11500: Classifier loss: 0.0929495030939579
Step 12000: Classifier loss: 0.08460890363156795
Step 12500: Classifier loss: 0.0924714410007
Step 13000: Classifier loss: 0.08704712373018265
Step 13500: Classifier loss: 0.08819058662652969
Step 14000: Classifier loss: 0.09366303083300591
Step 14500: Classifier loss: 0.08295501434803008
Step 15000: Classifier loss: 0.09084490737318993
Step 15500: Classifier loss: 0.08707242746651173
Step 16000: Classifier loss: 0.08690852355957031
Step 16500: Classifier loss: 0.09254233407974242
Step 17000: Classifier loss: 0.08242024271190167
Step 17500: Classifier loss: 0.08904271678626538
Step 18000: Classifier loss: 0.08771026766300201
Step 18500: Classifier loss: 0.08471861970424652
Step 19000: Classifier loss: 0.09134728060662746
Step 19500: Classifier loss: 0.08233513435721397
Step 20000: Classifier loss: 0.08778411850333213
Step 20500: Classifier loss: 0.08791485584527255
Step 21000: Classifier loss: 0.08345357306301594
Step 21500: Classifier loss: 0.08975999920070171
Step 22000: Classifier loss: 0.08225472408533097
Step 22500: Classifier loss: 0.08668080273270606
Step 23000: Classifier loss: 0.08786206224560737
Step 23500: Classifier loss: 0.08155409483611584
Step 24000: Classifier loss: 0.08907847443222999
Step 24500: Classifier loss: 0.08202618369460106
Step 25000: Classifier loss: 0.08517973597347736
Step 25500: Classifier loss: 0.08817093770205975
Step 26000: Classifier loss: 0.08008052316308022
Step 26500: Classifier loss: 0.08741954331099987
Step 27000: Classifier loss: 0.08247932478785515
Step 27500: Classifier loss: 0.08377225384116173
Step 28000: Classifier loss: 0.08846944206953049
Step 28500: Classifier loss: 0.07859189368784428
Step 29000: Classifier loss: 0.08617163190245629
Step 29500: Classifier loss: 0.0824531610161066
Step 30000: Classifier loss: 0.08195052224397659
Step 30500: Classifier loss: 0.08803890940546989
Step 31000: Classifier loss: 0.07793828934431075
Step 31500: Classifier loss: 0.08464510484039783
Step 32000: Classifier loss: 0.08275749842077494
Step 32500: Classifier loss: 0.0805082704871893
Step 33000: Classifier loss: 0.08703124921023846
Step 33500: Classifier loss: 0.0772736611738801
Step 34000: Classifier loss: 0.08353734220564366
Step 34500: Classifier loss: 0.08343685203790664
Step 35000: Classifier loss: 0.07905932680517436
Step 35500: Classifier loss: 0.08568261863291264
Step 36000: Classifier loss: 0.07762402860075235
Step 36500: Classifier loss: 0.08223582464456558
Step 37000: Classifier loss: 0.08341778349876404
Step 37500: Classifier loss: 0.07801838412880897
Step 38000: Classifier loss: 0.0842266542762518
Step 38500: Classifier loss: 0.07764634099602699
Step 39000: Classifier loss: 0.08104524739086628
Step 39500: Classifier loss: 0.08389902476221323
Step 40000: Classifier loss: 0.07612183248996734
Step 40500: Classifier loss: 0.08296740844845772
Step 41000: Classifier loss: 0.0781253460124135
Step 41500: Classifier loss: 0.07980525248497725
Step 42000: Classifier loss: 0.08405549557507039
Step 42500: Classifier loss: 0.0743530157059431
Step 43000: Classifier loss: 0.08219673927128315
Step 43500: Classifier loss: 0.07845095673948527
Step 44000: Classifier loss: 0.07780187250673772
Step 44500: Classifier loss: 0.08399353076517582
Step 45000: Classifier loss: 0.07365029990673065
Step 45500: Classifier loss: 0.0808380290567875
Step 46000: Classifier loss: 0.0786423703506589
Step 46500: Classifier loss: 0.07693013155460357
Step 47000: Classifier loss: 0.08244228959083558
Step 47500: Classifier loss: 0.07365631985664367
Step 48000: Classifier loss: 0.07970952866971492
Step 48500: Classifier loss: 0.07868134459108114
Step 49000: Classifier loss: 0.07539512529224157
Step 49500: Classifier loss: 0.08191524033248425
Step 50000: Classifier loss: 0.07361406400799751
Step 50500: Classifier loss: 0.07847459720075131
Ended: 2021-05-11 23:15:24.444278
Elapsed: 2:03:52.023772
</pre>
<div class="highlight">
<pre><span></span><span class="n">losses</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Loss</span><span class="o">=</span><span class="n">classifier_losses</span><span class="p">))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">"Loss"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Classifier Loss Session 3"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">tan</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"classifier_loss_3"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/gans/controllable-generation/classifier_loss_2.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0a21040">
<h3 id="org0a21040">Loading the Pretrained Models</h3>
<div class="outline-text-3" id="text-org0a21040">
<p>We will then load the pretrained generator and classifier using the following code. (If we trained our own classifier, we can load that one here instead.)</p>
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">gen_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">prebuilt_models</span><span class="o">.</span><span class="n">celeba</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">))[</span><span class="s2">"gen"</span><span class="p">]</span>
<span class="n">gen</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">gen_dict</span><span class="p">)</span>
<span class="n">gen</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span><span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">class_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">prebuilt_models</span><span class="o">.</span><span class="n">classifier</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">))[</span><span class="s2">"classifier"</span><span class="p">]</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">class_dict</span><span class="p">)</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org05839e8">
<h3 id="org05839e8">Training</h3>
<div class="outline-text-3" id="text-org05839e8">
<p>Now we can start implementing a method for controlling our GAN.</p>
</div>
<div class="outline-4" id="outline-container-orgd2e7172">
<h4 id="orgd2e7172">Update Noise</h4>
<div class="outline-text-4" id="text-orgd2e7172">
<p>For training, we need to write the code to update the noise to produce more of our desired feature. We do this by performing stochastic gradient ascent. We use stochastic gradient ascent to find the local maxima, as opposed to stochastic gradient descent which finds the local minima. Gradient ascent is gradient descent over the negative of the value being optimized. Their formulas are essentially the same, however, instead of subtracting the weighted value, stochastic gradient ascent adds it; it can be calculated by \(new = old + (âˆ‡ old * weight)\), where âˆ‡ is the gradient of <code>old</code>. We perform stochastic gradient ascent to try and maximize the amount of the feature we want. If we wanted to reduce the amount of the feature, we would perform gradient descent. However, in this assignment we are interested in maximize our feature using gradient ascent, since many features in the dataset are not present much more often than they're present and we are trying to add a feature to the images, not remove.</p>
<p>Given the noise with its gradient already calculated through the classifier, we want to return the new noise vector.</p>
<ol class="org-ol">
<li>Remember the equation for gradient ascent: \(new = old + (âˆ‡ old * weight)\).</li>
</ol>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">calculate_updated_noise</span><span class="p">(</span><span class="n">noise</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Update noise vectors with stochastic gradient ascent.</span>

<span class="sd">    Args:</span>
<span class="sd">     noise: the current noise vectors. </span>
<span class="sd">           We have already called the backwards function on the target class</span>
<span class="sd">           so we can access the gradient of the output class with respect </span>
<span class="sd">           to the noise by using noise.grad</span>
<span class="sd">     weight: the scalar amount by which we should weight the noise gradient</span>

<span class="sd">    Returns:</span>
<span class="sd">     updated noise</span>
<span class="sd">    """</span>
    <span class="n">new_noise</span> <span class="o">=</span> <span class="n">noise</span> <span class="o">+</span> <span class="p">(</span><span class="n">noise</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="n">weight</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_noise</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org8d6a59b"></a>UNIT TEST<br>
<div class="outline-text-5" id="text-org8d6a59b">
<p>Check that the basic function works.</p>
<div class="highlight">
<pre><span></span><span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
<span class="n">noise</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="n">fake_classes</span> <span class="o">=</span> <span class="p">(</span><span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">fake_classes</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">new_noise</span> <span class="o">=</span> <span class="n">calculate_updated_noise</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">new_noise</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
<span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_noise</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">new_noise</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">==</span> <span class="mf">2.0010</span>
<span class="k">assert</span> <span class="n">new_noise</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">==</span> <span class="mf">2.0010</span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">new_noise</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)</span> <span class="o">+</span> <span class="mi">20</span> <span class="o">*</span> <span class="mi">20</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
<p>Check that it works for generated images</p>
<div class="highlight">
<pre><span></span><span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">get_noise</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="n">fake</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
<span class="n">fake_classes</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">fake</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">fake_classes</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">noise</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">calculate_updated_noise</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">fake</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
<span class="n">fake_classes_new</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">fake</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">fake_classes_new</span> <span class="o">&gt;</span> <span class="n">fake_classes</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org1e3c3dd">
<h3 id="org1e3c3dd">Generation</h3>
<div class="outline-text-3" id="text-org1e3c3dd">
<p>Now, we can use the classifier along with stochastic gradient ascent to make noise that generates more of a certain feature. In the code given to us here, we can generate smiling faces. Feel free to change the target index and control some of the other features in the list! We will notice that some features are easier to detect and control than others.</p>
<p>The list we have here are the features labeled in CelebA, which we used to train our classifier. If we wanted to control another feature, we would need to get data that is labeled with that feature and train a classifier on that feature.</p>
<p>First generate a bunch of images with the generator.</p>
<div class="highlight">
<pre><span></span><span class="n">n_images</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">fake_image_history</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">grad_steps</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># Number of gradient steps to take</span>
<span class="n">skip</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># Number of gradient steps to skip in the visualization</span>

<span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"5oClockShadow"</span><span class="p">,</span> <span class="s2">"ArchedEyebrows"</span><span class="p">,</span> <span class="s2">"Attractive"</span><span class="p">,</span> <span class="s2">"BagsUnderEyes"</span><span class="p">,</span> <span class="s2">"Bald"</span><span class="p">,</span> <span class="s2">"Bangs"</span><span class="p">,</span>
<span class="s2">"BigLips"</span><span class="p">,</span> <span class="s2">"BigNose"</span><span class="p">,</span> <span class="s2">"BlackHair"</span><span class="p">,</span> <span class="s2">"BlondHair"</span><span class="p">,</span> <span class="s2">"Blurry"</span><span class="p">,</span> <span class="s2">"BrownHair"</span><span class="p">,</span> <span class="s2">"BushyEyebrows"</span><span class="p">,</span> <span class="s2">"Chubby"</span><span class="p">,</span>
<span class="s2">"DoubleChin"</span><span class="p">,</span> <span class="s2">"Eyeglasses"</span><span class="p">,</span> <span class="s2">"Goatee"</span><span class="p">,</span> <span class="s2">"GrayHair"</span><span class="p">,</span> <span class="s2">"HeavyMakeup"</span><span class="p">,</span> <span class="s2">"HighCheekbones"</span><span class="p">,</span> <span class="s2">"Male"</span><span class="p">,</span> 
<span class="s2">"MouthSlightlyOpen"</span><span class="p">,</span> <span class="s2">"Mustache"</span><span class="p">,</span> <span class="s2">"NarrowEyes"</span><span class="p">,</span> <span class="s2">"NoBeard"</span><span class="p">,</span> <span class="s2">"OvalFace"</span><span class="p">,</span> <span class="s2">"PaleSkin"</span><span class="p">,</span> <span class="s2">"PointyNose"</span><span class="p">,</span> 
<span class="s2">"RecedingHairline"</span><span class="p">,</span> <span class="s2">"RosyCheeks"</span><span class="p">,</span> <span class="s2">"Sideburn"</span><span class="p">,</span> <span class="s2">"Smiling"</span><span class="p">,</span> <span class="s2">"StraightHair"</span><span class="p">,</span> <span class="s2">"WavyHair"</span><span class="p">,</span> <span class="s2">"WearingEarrings"</span><span class="p">,</span> 
<span class="s2">"WearingHat"</span><span class="p">,</span> <span class="s2">"WearingLipstick"</span><span class="p">,</span> <span class="s2">"WearingNecklace"</span><span class="p">,</span> <span class="s2">"WearingNecktie"</span><span class="p">,</span> <span class="s2">"Weng"</span><span class="p">]</span>

<span class="c1">### Change me! ###</span>
<span class="n">target_indices</span> <span class="o">=</span> <span class="n">feature_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">"Weng"</span><span class="p">)</span> <span class="c1"># Feel free to change this value to any string from feature_names!</span>

<span class="n">noise</span> <span class="o">=</span> <span class="n">get_noise</span><span class="p">(</span><span class="n">n_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">grad_steps</span><span class="p">):</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">fake</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
    <span class="n">fake_image_history</span> <span class="o">+=</span> <span class="p">[</span><span class="n">fake</span><span class="p">]</span>
    <span class="n">fake_classes_score</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">fake</span><span class="p">)[:,</span> <span class="n">target_indices</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">fake_classes_score</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">noise</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">calculate_updated_noise</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">grad_steps</span><span class="p">)</span>

<span class="n">pyplot</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_images</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">grad_steps</span> <span class="o">*</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">save_tensor_images</span><span class="p">(</span><span class="n">image_tensor</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">fake_image_history</span><span class="p">[::</span><span class="n">skip</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> 
<span class="n">filename</span><span class="o">=</span><span class="s2">"weng.png"</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="n">OUTPUT</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Weng"</span><span class="p">,</span>
<span class="n">num_images</span><span class="o">=</span><span class="n">n_images</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="n">n_images</span><span class="p">)</span>
</pre></div>
<div class="figure" id="org24b3706">
<p><img alt="weng.png" src="posts/gans/controllable-generation/weng.png"></p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org2ee0f56">
<h3 id="org2ee0f56">Entanglement and Regularization</h3>
<div class="outline-text-3" id="text-org2ee0f56">
<p>We may also notice that sometimes more features than just the target feature change. This is because some features are entangled. To fix this, we can try to isolate the target feature more by holding the classes outside of the target class constant. One way we can implement this is by penalizing the differences from the original class with L2 regularization. This L2 regularization would apply a penalty for this difference using the L2 norm and this would just be an additional term on the loss function.</p>
<p>Here, we'll have to implement the score function: the higher, the better. The score is calculated by adding the target score and a penalty â€“ note that the penalty is meant to lower the score, so it should have a negative value.</p>
<p>For every non-target class, take the difference between the current noise and the old noise. The greater this value is, the more features outside the target have changed. We will calculate the magnitude of the change, take the mean, and negate it. Finally, add this penalty to the target score. The target score is the mean of the target class in the current noise.</p>
<ol class="org-ol">
<li>The higher the score, the better!</li>
<li>We want to calculate the loss per image, so we'll need to pass a dim argument to <a href="https://pytorch.org/docs/stable/generated/torch.norm.html"><code>torch.norm</code></a>.</li>
<li>Calculating the magnitude of the change requires we to take the norm of the difference between the classifications, not the difference of the norms.</li>
</ol>
<p><b>Note:</b> <code>torch.norm</code> is deprecated, they want you to use <a href="https://pytorch.org/docs/stable/linalg.html#torch.linalg.norm">torch.linalg.norm</a> instead.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_score</span><span class="p">(</span><span class="n">current_classifications</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
              <span class="n">original_classifications</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
              <span class="n">target_indices</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
              <span class="n">other_indices</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
              <span class="n">penalty_weight</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Score the current classifications, L2 Norm penalty</span>

<span class="sd">    Args:</span>
<span class="sd">       current_classifications: the classifications associated with the current noise</span>
<span class="sd">       original_classifications: the classifications associated with the original noise</span>
<span class="sd">       target_indices: the index of the target class</span>
<span class="sd">       other_indices: the indices of the other classes</span>
<span class="sd">       penalty_weight: the amount that the penalty should be weighted in the overall score</span>

<span class="sd">    Returns: </span>
<span class="sd">     the score of the current classification with L2 Norm penalty</span>
<span class="sd">    """</span>
    <span class="c1"># Steps: 1) Calculate the change between the original and current classifications (as a tensor)</span>
    <span class="c1">#           by indexing into the other_indices we're trying to preserve, like in x[:, features].</span>
    <span class="c1">#        2) Calculate the norm (magnitude) of changes per example.</span>
    <span class="c1">#        3) Multiply the mean of the example norms by the penalty weight. </span>
    <span class="c1">#           This will be our other_class_penalty.</span>
    <span class="c1">#           Make sure to negate the value since it's a penalty!</span>
    <span class="c1">#        4) Take the mean of the current classifications for the target feature over all the examples.</span>
    <span class="c1">#           This mean will be our target_score.</span>
    <span class="c1"># Calculate the norm (magnitude) of changes per example and multiply by penalty weight</span>
    <span class="n">other_class_penalty</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">original_classifications</span><span class="p">[:,</span> <span class="n">other_indices</span><span class="p">]</span>
                          <span class="o">-</span> <span class="n">current_classifications</span><span class="p">[:,</span> <span class="n">other_indices</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
                           <span class="o">*</span> <span class="n">penalty_weight</span><span class="p">)</span>
    <span class="c1"># Take the mean of the current classifications for the target feature</span>
    <span class="n">target_score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">current_classifications</span><span class="p">[:,</span> <span class="n">target_indices</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">target_score</span> <span class="o">+</span> <span class="n">other_class_penalty</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org635d44f">
<h4 id="org635d44f">UNIT TEST</h4>
<div class="outline-text-4" id="text-org635d44f">
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span>
    <span class="n">get_score</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="mf">0.2</span><span class="p">),</span> 
    <span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.</span><span class="p">))</span> <span class="o">*</span> <span class="mf">0.2</span>
<span class="p">)</span>
<span class="n">rows</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">current_class</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">original_class</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="c1"># Must be 3</span>
<span class="k">assert</span> <span class="n">get_score</span><span class="p">(</span><span class="n">current_class</span><span class="p">,</span> <span class="n">original_class</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="mf">0.2</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span>

<span class="n">current_class</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">original_class</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="c1"># Must be 3 - 0.2 * sqrt(10)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">get_score</span><span class="p">(</span><span class="n">current_class</span><span class="p">,</span> <span class="n">original_class</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="mf">0.2</span><span class="p">),</span> 
                     <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10.0</span><span class="p">))</span> <span class="o">*</span> <span class="mf">0.2</span> <span class="o">+</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
<p>In the following block of code, we will run the gradient ascent with this new score function. We might notice a few things after running it:</p>
<ol class="org-ol">
<li>It may fail more often at producing the target feature when compared to the original approach. This suggests that the model may not be able to generate an image that has the target feature without changing the other features. This makes sense! For example, it may not be able to generate a face that's smiling but whose mouth is NOT slightly open. This may also expose a limitation of the generator.</li>
</ol>
<p>Alternatively, even if the generator can produce an image with the intended features, it might require many intermediate changes to get there and may get stuck in a local minimum.</p>
<ol class="org-ol">
<li>This process may change features which the classifier was not trained to recognize since there is no way to penalize them with this method. Whether it's possible to train models to avoid changing unsupervised features is an open question.</li>
</ol>
<div class="highlight">
<pre><span></span><span class="n">fake_image_history</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1">### Change me! ###</span>
<span class="n">target_indices</span> <span class="o">=</span> <span class="n">feature_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">"Goatee"</span><span class="p">)</span> <span class="c1"># Feel free to change this value to any string from feature_names from earlier!</span>
<span class="n">other_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">cur_idx</span> <span class="o">!=</span> <span class="n">target_indices</span> <span class="k">for</span> <span class="n">cur_idx</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)]</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">get_noise</span><span class="p">(</span><span class="n">n_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="n">original_classifications</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">gen</span><span class="p">(</span><span class="n">noise</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">grad_steps</span><span class="p">):</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">fake</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
    <span class="n">fake_image_history</span> <span class="o">+=</span> <span class="p">[</span><span class="n">fake</span><span class="p">]</span>
    <span class="n">fake_score</span> <span class="o">=</span> <span class="n">get_score</span><span class="p">(</span>
        <span class="n">classifier</span><span class="p">(</span><span class="n">fake</span><span class="p">),</span> 
        <span class="n">original_classifications</span><span class="p">,</span>
        <span class="n">target_indices</span><span class="p">,</span>
        <span class="n">other_indices</span><span class="p">,</span>
        <span class="n">penalty_weight</span><span class="o">=</span><span class="mf">0.1</span>
    <span class="p">)</span>
    <span class="n">fake_score</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">noise</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">calculate_updated_noise</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">grad_steps</span><span class="p">)</span>

<span class="n">pyplot</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_images</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">grad_steps</span> <span class="o">*</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">save_tensor_images</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">fake_image_history</span><span class="p">[::</span><span class="n">skip</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">num_images</span><span class="o">=</span><span class="n">n_images</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="n">n_images</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">"goatee.png"</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="n">OUTPUT</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Goatee"</span><span class="p">)</span>
</pre></div>
<div class="figure" id="org17e8284">
<p><img alt="goatee.png" src="posts/gans/controllable-generation/goatee.png"></p>
</div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgb57fcd9">
<h2 id="orgb57fcd9">End</h2>
<div class="outline-text-2" id="text-orgb57fcd9"></div>
<div class="outline-3" id="outline-container-orgd441ac7">
<h3 id="orgd441ac7">Sources</h3>
<div class="outline-text-3" id="text-orgd441ac7">
<ul class="org-ul">
<li>Liu, Z, Luo, P, Wang, X, Tang, X, Deep Learning Face Attributes in the Wild. In Proceedings of International Conference on Computer Vision (ICCV) 2015 .</li>
</ul>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/gans/a-conditional-gan/">A Conditional GAN</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/gans/a-conditional-gan/" rel="bookmark"><time class="published dt-published" datetime="2021-04-24T14:34:07-07:00" itemprop="datePublished" title="2021-04-24 14:34">2021-04-24 14:34</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div class="outline-2" id="outline-container-org5c00faa">
<h2 id="org5c00faa">Build You a Conditional GAN For a Great Good</h2>
<div class="outline-text-2" id="text-org5c00faa"></div>
<div class="outline-3" id="outline-container-orgc20aff2">
<h3 id="orgc20aff2">Imports</h3>
<div class="outline-text-3" id="text-orgc20aff2">
<div class="highlight">
<pre><span></span><span class="c1"># python standard library</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">math</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="c1"># my stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org40a749e">
<h3 id="org40a749e">Set Up</h3>
<div class="outline-text-3" id="text-org40a749e"></div>
<div class="outline-4" id="outline-container-org0b99b84">
<h4 id="org0b99b84">The Timer</h4>
<div class="outline-text-4" id="text-org0b99b84">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org789bd08">
<h4 id="org789bd08">The Manual Seed</h4>
<div class="outline-text-4" id="text-org789bd08">
<div class="highlight">
<pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org629fb70">
<h4 id="org629fb70">Plotting</h4>
<div class="outline-text-4" id="text-org629fb70">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"a-conditional-gan"</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org7014585">
<h3 id="org7014585">Helpers</h3>
<div class="outline-text-3" id="text-org7014585">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">save_tensor_images</span><span class="p">(</span><span class="n">image_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                       <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
                       <span class="n">title</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                       <span class="n">folder</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/gans</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
                       <span class="n">num_images</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">"""Plot an Image Tensor</span>

<span class="sd">    Args:</span>
<span class="sd">     image_tensor: tensor with the values for the image to plot</span>
<span class="sd">     filename: name to save the file under</span>
<span class="sd">     folder: path to put the file in</span>
<span class="sd">     title: title for the image</span>
<span class="sd">     num_images: how many images from the tensor to use</span>
<span class="sd">     size: the dimensions for each image</span>
<span class="sd">    """</span>
    <span class="n">image_tensor</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_tensor</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">image_unflat</span> <span class="o">=</span> <span class="n">image_tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
    <span class="n">image_grid</span> <span class="o">=</span> <span class="n">make_grid</span><span class="p">(</span><span class="n">image_unflat</span><span class="p">[:</span><span class="n">num_images</span><span class="p">],</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image_grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelbottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                       <span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelleft</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">folder</span> <span class="o">+</span> <span class="n">filename</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[[file:</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">]]"</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orga85cbf7">
<h4 id="orga85cbf7">Noise</h4>
<div class="outline-text-4" id="text-orga85cbf7">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">make_some_noise</span><span class="p">(</span><span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Alias for torch.randn</span>

<span class="sd">    Args:</span>
<span class="sd">      n_samples: the number of samples to generate</span>
<span class="sd">      z_dim: the dimension of the noise vector</span>
<span class="sd">      device: the device type</span>

<span class="sd">    Returns:</span>
<span class="sd">     tensor with random numbers from the normal distribution.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgb45c911">
<h2 id="orgb45c911">Middle</h2>
<div class="outline-text-2" id="text-orgb45c911"></div>
<div class="outline-3" id="outline-container-orgbe165ef">
<h3 id="orgbe165ef">The Generator</h3>
<div class="outline-text-3" id="text-orgbe165ef">
<p>The Generator and Discriminator are the same ones we used before except the <code>z_dim</code> attribute has been renamed <code>input_dim</code> to reflect the fact that the data is going to be augmented with the classification information.</p>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""The DCGAN Generator</span>

<span class="sd">    Args:</span>
<span class="sd">       input_dim: the dimension of the input vector</span>
<span class="sd">       im_chan: the number of channels in the images, fitted for the dataset used</span>
<span class="sd">             (MNIST is black-and-white, so 1 channel is your default)</span>
<span class="sd">       hidden_dim: the inner dimension,</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">im_chan</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gen</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">im_chan</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">final_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_gen_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                       <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                       <span class="n">final_layer</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Creates a block for the generator (sub sequence)</span>

<span class="sd">       The parts</span>
<span class="sd">        - a transposed convolution</span>
<span class="sd">        - a batchnorm (except for in the last layer)</span>
<span class="sd">        - an activation.</span>

<span class="sd">       Args:</span>
<span class="sd">           input_channels: how many channels the input feature representation has</span>
<span class="sd">           output_channels: how many channels the output feature representation should have</span>
<span class="sd">           kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)</span>
<span class="sd">           stride: the stride of the convolution</span>
<span class="sd">           final_layer: a boolean, true if it is the final layer and false otherwise </span>
<span class="sd">                     (affects activation and batchnorm)</span>

<span class="sd">       Returns:</span>
<span class="sd">        the sub-sequence of layers</span>
<span class="sd">       """</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">final_layer</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">output_channels</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""complete a forward pass of the generator: Given a noise tensor, </span>

<span class="sd">       Args:</span>
<span class="sd">        noise: a noise tensor with dimensions (n_samples, z_dim)</span>

<span class="sd">       Returns:</span>
<span class="sd">        generated images.</span>
<span class="sd">       """</span>
        <span class="c1"># unsqueeze the noise</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">noise</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">noise</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gen</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orga409188">
<h3 id="orga409188">Discriminator</h3>
<div class="outline-text-3" id="text-orga409188">
<p>This differs a little from the DCGAN Discriminator in that the initial hidden dimension output goes up to 64 nodes from 16 in the original.</p>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""The DCGAN Discriminator</span>

<span class="sd">    Args:</span>
<span class="sd">     im_chan: the number of channels in the images, fitted for the dataset used</span>
<span class="sd">             (MNIST is black-and-white, so 1 channel is the default)</span>
<span class="sd">     hidden_dim: the inner dimension,</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im_chan</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_disc_block</span><span class="p">(</span><span class="n">im_chan</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_disc_block</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_disc_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">final_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">make_disc_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">final_layer</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Make a sub-block of layers for the discriminator</span>

<span class="sd">        - a convolution</span>
<span class="sd">        - a batchnorm (except for in the last layer)</span>
<span class="sd">        - an activation.</span>

<span class="sd">       Args:</span>
<span class="sd">         input_channels: how many channels the input feature representation has</span>
<span class="sd">         output_channels: how many channels the output feature representation should have</span>
<span class="sd">         kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)</span>
<span class="sd">         stride: the stride of the convolution</span>
<span class="sd">         final_layer: if true it is the final layer and otherwise not</span>
<span class="sd">                     (affects activation and batchnorm)</span>
<span class="sd">       """</span>        
        <span class="c1"># Build the neural block</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">final_layer</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">output_channels</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Final Layer</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Complete a forward pass of the discriminator</span>

<span class="sd">       Args:</span>
<span class="sd">         image: a flattened image tensor with dimension (im_dim)</span>

<span class="sd">       Returns:</span>
<span class="sd">        a 1-dimension tensor representing fake/real.</span>
<span class="sd">       """</span>
        <span class="n">disc_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">disc</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">disc_pred</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">disc_pred</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org6423ff4">
<h3 id="org6423ff4">The Class Input</h3>
<div class="outline-text-3" id="text-org6423ff4"></div>
<div class="outline-4" id="outline-container-orge1bb4c6">
<h4 id="orge1bb4c6">One-Hot Encoder</h4>
<div class="outline-text-4" id="text-orge1bb4c6">
<p>In conditional GANs, the input vector for the generator will also need to include the class information. The class is represented using a one-hot encoded vector where its length is the number of classes and each index represents a class. The vector is all 0's and a 1 on the chosen class. Given the labels of multiple images (e.g. from a batch) and number of classes, please create one-hot vectors for each label. There is a class within the PyTorch functional library that can help you.</p>
<ol class="org-ol">
<li>This code can be done in one line.</li>
<li>pytorch documentation for <a href="https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.one_hot">F.one<sub>hot</sub></a></li>
</ol>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_one_hot_labels</span><span class="p">(</span><span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Create one-hot vectors for the labels</span>

<span class="sd">    Args:</span>
<span class="sd">       labels: tensor of labels from the dataloader</span>
<span class="sd">       n_classes: the total number of classes in the dataset</span>

<span class="sd">    Returns:</span>
<span class="sd">     a tensor of shape (labels size, num_classes).</span>
<span class="sd">    """</span>
    <span class="c1">#### START CODE HERE ####</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
    <span class="c1">#### END CODE HERE ####</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="p">(</span>
    <span class="n">get_one_hot_labels</span><span class="p">(</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span>
        <span class="n">n_classes</span><span class="o">=</span><span class="mi">3</span>
    <span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">==</span> 
    <span class="p">[[</span>
      <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> 
      <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
      <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="p">]]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8a8e9f5">
<h4 id="org8a8e9f5">Combine Vectors</h4>
<div class="outline-text-4" id="text-org8a8e9f5">
<p>Next, you need to be able to concatenate the one-hot class vector to the noise vector before giving it to the generator. You will also need to do this when adding the class channels to the discriminator.</p>
<ol class="org-ol">
<li>This code can also be written in one line.</li>
<li>See the documentation <a href="https://pytorch.org/docs/master/generated/torch.cat.html">torch.cat</a> ( Specifically, look at what the <code>dim</code> argument of <code>torch.cat</code> does)</li>
</ol>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">combine_vectors</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Combine two vectors with shapes (n_samples, ?) and (n_samples, ?).</span>

<span class="sd">    Args:</span>
<span class="sd">      x: the first vector. </span>
<span class="sd">      y: the second vector.</span>
<span class="sd">    """</span>
    <span class="c1"># Note: Make sure this function outputs a float no matter what inputs it receives</span>
    <span class="c1">#### START CODE HERE ####</span>
    <span class="n">combined</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1">#### END CODE HERE ####</span>
    <span class="k">return</span> <span class="n">combined</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">combined</span> <span class="o">=</span> <span class="n">combine_vectors</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]));</span>
<span class="c1"># Check exact order of elements</span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">combined</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]))</span>
<span class="c1"># Tests that items are of float type</span>
<span class="k">assert</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">combined</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">==</span> <span class="nb">float</span><span class="p">)</span>
<span class="c1"># Check shapes</span>
<span class="n">combined</span> <span class="o">=</span> <span class="n">combine_vectors</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">));</span>
<span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">combined</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">combine_vectors</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">())</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org1e55c6f">
<h3 id="org1e55c6f">Training</h3>
<div class="outline-text-3" id="text-org1e55c6f">
<p>First, you will define some new parameters:</p>
<ul class="org-ul">
<li>mnist<sub>shape</sub>: the number of pixels in each MNIST image, which has dimensions 28 x 28 and one channel (because it's black-and-white) so 1 x 28 x 28</li>
<li>n<sub>classes</sub>: the number of classes in MNIST (10, since there are the digits from 0 to 9)</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">mnist_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
<p>And you also include the same parameters from before:</p>
<ul class="org-ul">
<li>criterion: the loss function</li>
<li>n<sub>epochs</sub>: the number of times you iterate through the entire dataset when training</li>
<li>z<sub>dim</sub>: the dimension of the noise vector</li>
<li>display<sub>step</sub>: how often to display/visualize the images</li>
<li>batch<sub>size</sub>: the number of images per forward/backward pass</li>
<li>lr: the learning rate</li>
<li>device: the device type</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0002</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'cuda'</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,)),</span>
<span class="p">])</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/pytorch-data/MNIST/"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">MNIST</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgae93e0e">
<h4 id="orgae93e0e">Input Dimensions</h4>
<div class="outline-text-4" id="text-orgae93e0e">
<p>Then, you can initialize your generator, discriminator, and optimizers. To do this, you will need to update the input dimensions for both models. For the generator, you will need to calculate the size of the input vector; recall that for conditional GANs, the generator's input is the noise vector concatenated with the class vector. For the discriminator, you need to add a channel for every class.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_input_dimensions</span><span class="p">(</span><span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">mnist_shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Calculates the size of the conditional input dimensions </span>

<span class="sd">    Args:</span>
<span class="sd">       z_dim: the dimension of the noise vector</span>
<span class="sd">       mnist_shape: the shape of each MNIST image as (C, W, H), which is (1, 28, 28)</span>
<span class="sd">       n_classes: the total number of classes in the dataset, an integer scalar</span>
<span class="sd">               (10 for MNIST)</span>
<span class="sd">    Returns: </span>
<span class="sd">       generator_input_dim: the input dimensionality of the conditional generator, </span>
<span class="sd">                         which takes the noise and class vectors</span>
<span class="sd">       discriminator_im_chan: the number of input channels to the discriminator</span>
<span class="sd">                           (e.g. C x 28 x 28 for MNIST)</span>
<span class="sd">    """</span>
    <span class="c1">#### START CODE HERE ####</span>
    <span class="n">generator_input_dim</span> <span class="o">=</span> <span class="n">z_dim</span> <span class="o">+</span> <span class="n">n_classes</span>
    <span class="n">discriminator_im_chan</span> <span class="o">=</span> <span class="n">n_classes</span> <span class="o">+</span> <span class="n">mnist_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1">#### END CODE HERE ####</span>
    <span class="k">return</span> <span class="n">generator_input_dim</span><span class="p">,</span> <span class="n">discriminator_im_chan</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_input_dims</span><span class="p">():</span>
    <span class="n">gen_dim</span><span class="p">,</span> <span class="n">disc_dim</span> <span class="o">=</span> <span class="n">get_input_dimensions</span><span class="p">(</span><span class="mi">23</span><span class="p">,</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">52</span><span class="p">),</span> <span class="mi">9</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">gen_dim</span> <span class="o">==</span> <span class="mi">32</span>
    <span class="k">assert</span> <span class="n">disc_dim</span> <span class="o">==</span> <span class="mi">21</span>
<span class="n">test_input_dims</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org084dcb2">
<h4 id="org084dcb2">Initialize the Objects</h4>
<div class="outline-text-4" id="text-org084dcb2">
<div class="highlight">
<pre><span></span><span class="n">generator_input_dim</span><span class="p">,</span> <span class="n">discriminator_im_chan</span> <span class="o">=</span> <span class="n">get_input_dimensions</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">mnist_shape</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>

<span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">generator_input_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">gen_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">disc</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">im_chan</span><span class="o">=</span><span class="n">discriminator_im_chan</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">disc_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">weights_init</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Initialize the weights from the normal distribution</span>

<span class="sd">    Args:</span>
<span class="sd">     m: object to initialize</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">gen</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">weights_init</span><span class="p">)</span>
<span class="n">disc</span> <span class="o">=</span> <span class="n">disc</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">weights_init</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgef69e50">
<h4 id="orgef69e50">The Training</h4>
<div class="outline-text-4" id="text-orgef69e50">
<p>Now to train, you would like both your generator and your discriminator to know what class of image should be generated.</p>
<p>For example, if you're generating a picture of the number "1", you would need to:</p>
<ol class="org-ol">
<li>Tell that to the generator, so that it knows it should be generating a "1"</li>
<li>Tell that to the discriminator, so that it knows it should be looking at a "1". If the discriminator is told it should be looking at a 1 but sees something that's clearly an 8, it can guess that it's probably fake</li>
</ol>
<div class="highlight">
<pre><span></span><span class="n">cur_step</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">generator_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">discriminator_losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">noise_and_labels</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">fake</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">fake_image_and_labels</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">real_image_and_labels</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">disc_fake_pred</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">disc_real_pred</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="c1"># Dataloader returns the batches and the labels</span>
        <span class="k">for</span> <span class="n">real</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
            <span class="n">cur_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>
            <span class="c1"># Flatten the batch of real images from the dataset</span>
            <span class="n">real</span> <span class="o">=</span> <span class="n">real</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">one_hot_labels</span> <span class="o">=</span> <span class="n">get_one_hot_labels</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">n_classes</span><span class="p">)</span>
            <span class="n">image_one_hot_labels</span> <span class="o">=</span> <span class="n">one_hot_labels</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
            <span class="n">image_one_hot_labels</span> <span class="o">=</span> <span class="n">image_one_hot_labels</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">mnist_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">mnist_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

            <span class="c1">### Update discriminator ###</span>
            <span class="c1"># Zero out the discriminator gradients</span>
            <span class="n">disc_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="c1"># Get noise corresponding to the current batch_size </span>
            <span class="n">fake_noise</span> <span class="o">=</span> <span class="n">make_some_noise</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Now you can get the images from the generator</span>
            <span class="c1"># Steps: 1) Combine the noise vectors and the one-hot labels for the generator</span>
            <span class="c1">#        2) Generate the conditioned fake images</span>

            <span class="c1">#### START CODE HERE ####</span>
            <span class="n">noise_and_labels</span> <span class="o">=</span> <span class="n">combine_vectors</span><span class="p">(</span><span class="n">fake_noise</span><span class="p">,</span> <span class="n">one_hot_labels</span><span class="p">)</span>
            <span class="n">fake</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">noise_and_labels</span><span class="p">)</span>
            <span class="c1">#### END CODE HERE ####</span>

            <span class="c1"># Make sure that enough images were generated</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">fake</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>
            <span class="c1"># Check that correct tensors were combined</span>
            <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">noise_and_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">fake_noise</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">one_hot_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="c1"># It comes from the correct generator</span>
            <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">fake</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">real</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

            <span class="c1"># Now you can get the predictions from the discriminator</span>
            <span class="c1"># Steps: 1) Create the input for the discriminator</span>
            <span class="c1">#           a) Combine the fake images with image_one_hot_labels, </span>
            <span class="c1">#              remember to detach the generator (.detach()) so you do not backpropagate through it</span>
            <span class="c1">#           b) Combine the real images with image_one_hot_labels</span>
            <span class="c1">#        2) Get the discriminator's prediction on the fakes as disc_fake_pred</span>
            <span class="c1">#        3) Get the discriminator's prediction on the reals as disc_real_pred</span>

            <span class="c1">#### START CODE HERE ####</span>
            <span class="n">fake_image_and_labels</span> <span class="o">=</span> <span class="n">combine_vectors</span><span class="p">(</span><span class="n">fake</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">image_one_hot_labels</span><span class="p">)</span>
            <span class="n">real_image_and_labels</span> <span class="o">=</span> <span class="n">combine_vectors</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">image_one_hot_labels</span><span class="p">)</span>
            <span class="n">disc_fake_pred</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">fake_image_and_labels</span><span class="p">)</span>
            <span class="n">disc_real_pred</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">real_image_and_labels</span><span class="p">)</span>
            <span class="c1">#### END CODE HERE ####</span>

            <span class="c1"># Make sure shapes are correct </span>
            <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">fake_image_and_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">real</span><span class="p">),</span> <span class="n">fake</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">image_one_hot_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">28</span> <span class="p">,</span><span class="mi">28</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">real_image_and_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">real</span><span class="p">),</span> <span class="n">real</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">image_one_hot_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">28</span> <span class="p">,</span><span class="mi">28</span><span class="p">)</span>
            <span class="c1"># Make sure that enough predictions were made</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">disc_real_pred</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>
            <span class="c1"># Make sure that the inputs are different</span>
            <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">fake_image_and_labels</span> <span class="o">!=</span> <span class="n">real_image_and_labels</span><span class="p">)</span>
            <span class="c1"># Shapes must match</span>
            <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">fake_image_and_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">real_image_and_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">disc_fake_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">disc_real_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


            <span class="n">disc_fake_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">disc_fake_pred</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">disc_fake_pred</span><span class="p">))</span>
            <span class="n">disc_real_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">disc_real_pred</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">disc_real_pred</span><span class="p">))</span>
            <span class="n">disc_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">disc_fake_loss</span> <span class="o">+</span> <span class="n">disc_real_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">disc_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">disc_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> 

            <span class="c1"># Keep track of the average discriminator loss</span>
            <span class="n">discriminator_losses</span> <span class="o">+=</span> <span class="p">[</span><span class="n">disc_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>

            <span class="c1">### Update generator ###</span>
            <span class="c1"># Zero out the generator gradients</span>
            <span class="n">gen_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">fake_image_and_labels</span> <span class="o">=</span> <span class="n">combine_vectors</span><span class="p">(</span><span class="n">fake</span><span class="p">,</span> <span class="n">image_one_hot_labels</span><span class="p">)</span>
            <span class="c1"># This will error if you didn't concatenate your labels to your image correctly</span>
            <span class="n">disc_fake_pred</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">fake_image_and_labels</span><span class="p">)</span>
            <span class="n">gen_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">disc_fake_pred</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">disc_fake_pred</span><span class="p">))</span>
            <span class="n">gen_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">gen_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># Keep track of the generator losses</span>
            <span class="n">generator_losses</span> <span class="o">+=</span> <span class="p">[</span><span class="n">gen_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
            <span class="c1">#</span>

            <span class="k">if</span> <span class="n">cur_step</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">cur_step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">gen_mean</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">generator_losses</span><span class="p">[</span><span class="o">-</span><span class="n">display_step</span><span class="p">:])</span> <span class="o">/</span> <span class="n">display_step</span>
                <span class="n">disc_mean</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">discriminator_losses</span><span class="p">[</span><span class="o">-</span><span class="n">display_step</span><span class="p">:])</span> <span class="o">/</span> <span class="n">display_step</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Step </span><span class="si">{</span><span class="n">cur_step</span><span class="si">}</span><span class="s2">: Generator loss: </span><span class="si">{</span><span class="n">gen_mean</span><span class="si">}</span><span class="s2">, discriminator loss: </span><span class="si">{</span><span class="n">disc_mean</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="c1"># show_tensor_images(fake)</span>
                <span class="c1"># show_tensor_images(real)</span>
                <span class="n">step_bins</span> <span class="o">=</span> <span class="mi">20</span>
                <span class="n">x_axis</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">i</span> <span class="o">*</span> <span class="n">step_bins</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">generator_losses</span><span class="p">)</span> <span class="o">//</span> <span class="n">step_bins</span><span class="p">)]</span> <span class="o">*</span> <span class="n">step_bins</span><span class="p">)</span>
                <span class="c1"># num_examples = (len(generator_losses) // step_bins) * step_bins</span>
                <span class="c1"># plt.plot(</span>
                <span class="c1">#     range(num_examples // step_bins), </span>
                <span class="c1">#     torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),</span>
                <span class="c1">#     label="Generator Loss"</span>
                <span class="c1"># )</span>
                <span class="c1"># plt.plot(</span>
                <span class="c1">#     range(num_examples // step_bins), </span>
                <span class="c1">#     torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),</span>
                <span class="c1">#     label="Discriminator Loss"</span>
                <span class="c1"># )</span>
                <span class="c1"># plt.legend()</span>
                <span class="c1"># plt.show()</span>
            <span class="k">elif</span> <span class="n">cur_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">"Congratulations! If you've gotten here, it's working. Please let this train until you're happy with how the generated numbers look, and then go on to the exploration!"</span><span class="p">)</span>
            <span class="n">cur_step</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
<pre class="example" id="org37087db">
Started: 2021-04-30 17:21:38.697176
Congratulations! If you've gotten here, it's working. Please let this train until you're happy with how the generated numbers look, and then go on to the exploration!
Step 500: Generator loss: 2.2972163581848144, discriminator loss: 0.24098993314430117
Step 1000: Generator loss: 4.111798384666443, discriminator loss: 0.03910111421905458
Step 1500: Generator loss: 5.055200936317444, discriminator loss: 0.017988519712351263
Step 2000: Generator loss: 4.356978572845459, discriminator loss: 0.07956613468006253
Step 2500: Generator loss: 3.1875410358905794, discriminator loss: 0.1825093053430319
Step 3000: Generator loss: 2.7038124163150785, discriminator loss: 0.26903335136175155
Step 3500: Generator loss: 2.3201852326393126, discriminator loss: 0.30360834433138373
Step 4000: Generator loss: 2.3750923416614533, discriminator loss: 0.3380578280091286
Step 4500: Generator loss: 1.9010865423679353, discriminator loss: 0.3774027600288391
Step 5000: Generator loss: 1.9102082657814026, discriminator loss: 0.39759708976745606
Step 5500: Generator loss: 1.6987447377443314, discriminator loss: 0.43035421246290206
Step 6000: Generator loss: 1.6317225174903869, discriminator loss: 0.44889184486865996
Step 6500: Generator loss: 1.4883701887130738, discriminator loss: 0.47211092388629916
Step 7000: Generator loss: 1.4601867563724518, discriminator loss: 0.49546391534805295
Step 7500: Generator loss: 1.3467793072462082, discriminator loss: 0.520910717189312
Step 8000: Generator loss: 1.3130292971134185, discriminator loss: 0.5447795498371124
Step 8500: Generator loss: 1.1705783107280732, discriminator loss: 0.5716251953244209
Step 9000: Generator loss: 1.119933351278305, discriminator loss: 0.594505407333374
Step 9500: Generator loss: 1.0671374444961548, discriminator loss: 0.6109852703809738
Step 10000: Generator loss: 1.042488064646721, discriminator loss: 0.6221774860620498
Step 10500: Generator loss: 1.015932119846344, discriminator loss: 0.6356924445033073
Step 11000: Generator loss: 0.9900961836576462, discriminator loss: 0.6363092860579491
Step 11500: Generator loss: 0.9709519152641296, discriminator loss: 0.642409072637558
Step 12000: Generator loss: 0.9450125323534012, discriminator loss: 0.6527952731847763
Step 12500: Generator loss: 0.9660063650608063, discriminator loss: 0.6581431583166123
Step 13000: Generator loss: 0.8976931695938111, discriminator loss: 0.6624037518501281
Step 13500: Generator loss: 0.8969441390037537, discriminator loss: 0.6631241027116775
Step 14000: Generator loss: 0.902042475938797, discriminator loss: 0.6669842832088471
Step 14500: Generator loss: 0.8777725909948348, discriminator loss: 0.6742114140987396
Step 15000: Generator loss: 0.8425910116434098, discriminator loss: 0.6705276243686676
Step 15500: Generator loss: 0.8403865963220596, discriminator loss: 0.6768578908443451
Step 16000: Generator loss: 0.8556022493839264, discriminator loss: 0.6762306448221207
Step 16500: Generator loss: 0.8764977214336396, discriminator loss: 0.678820540189743
Step 17000: Generator loss: 0.8166215040683746, discriminator loss: 0.6793025200366973
Step 17500: Generator loss: 0.8172620774507523, discriminator loss: 0.6820640956163406
Step 18000: Generator loss: 0.8534817943572998, discriminator loss: 0.679261458158493
Step 18500: Generator loss: 0.814961371421814, discriminator loss: 0.6819399018287658
Step 19000: Generator loss: 0.8046633821725845, discriminator loss: 0.6841713408231735
Step 19500: Generator loss: 0.8040647978782653, discriminator loss: 0.6816601184606552
Step 20000: Generator loss: 0.8188033536672592, discriminator loss: 0.6830086879730225
Step 20500: Generator loss: 0.8088009203672409, discriminator loss: 0.6811848978996277
Step 21000: Generator loss: 0.7853847659826279, discriminator loss: 0.6836997301578521
Step 21500: Generator loss: 0.7798927721977233, discriminator loss: 0.684486163020134
Step 22000: Generator loss: 0.7833593552112579, discriminator loss: 0.685326477766037
Step 22500: Generator loss: 0.8140243920087814, discriminator loss: 0.6838948290348053
Step 23000: Generator loss: 0.7766883851289749, discriminator loss: 0.6896610424518586
Step 23500: Generator loss: 0.7677333387136459, discriminator loss: 0.6847020034790039
Step 24000: Generator loss: 0.7968860776424408, discriminator loss: 0.6859219465255737
Step 24500: Generator loss: 0.7655997285842896, discriminator loss: 0.6866924543380737
Step 25000: Generator loss: 0.7897603868246078, discriminator loss: 0.6862760508060455
Step 25500: Generator loss: 0.7602986326217651, discriminator loss: 0.6839702378511429
Step 26000: Generator loss: 0.7566630525588989, discriminator loss: 0.6884172073602677
Step 26500: Generator loss: 0.7693239089250564, discriminator loss: 0.6848342741727829
Step 27000: Generator loss: 0.7744117819070816, discriminator loss: 0.6884717727899552
Step 27500: Generator loss: 0.7754857275485992, discriminator loss: 0.6871565765142441
Step 28000: Generator loss: 0.7671164673566818, discriminator loss: 0.691150808095932
Step 28500: Generator loss: 0.7767693866491318, discriminator loss: 0.6899988718032837
Step 29000: Generator loss: 0.7584288560152054, discriminator loss: 0.6866833527088165
Step 29500: Generator loss: 0.7469037870168685, discriminator loss: 0.6892017160654068
Step 30000: Generator loss: 0.7409272351264954, discriminator loss: 0.6925988558530808
Step 30500: Generator loss: 0.7461127021312713, discriminator loss: 0.6910134963989257
Step 31000: Generator loss: 0.7623333480358124, discriminator loss: 0.6848250635862351
Step 31500: Generator loss: 0.7320846046209335, discriminator loss: 0.6922971439361573
Step 32000: Generator loss: 0.7360488106012344, discriminator loss: 0.6958958665132523
Step 32500: Generator loss: 0.7436227219104767, discriminator loss: 0.6927914987802506
Step 33000: Generator loss: 0.7528411923646927, discriminator loss: 0.6868532946109772
Step 33500: Generator loss: 0.7555540499687194, discriminator loss: 0.6819704930782318
Step 34000: Generator loss: 0.7339509303569793, discriminator loss: 0.6947230596542359
Step 34500: Generator loss: 0.7203902735710144, discriminator loss: 0.694019063949585
Step 35000: Generator loss: 0.7161798032522202, discriminator loss: 0.694249948143959
Step 35500: Generator loss: 0.7100930047035218, discriminator loss: 0.6956643009185791
Step 36000: Generator loss: 0.7224245357513428, discriminator loss: 0.692036272764206
Step 36500: Generator loss: 0.7294702612161637, discriminator loss: 0.6839023213386536
Step 37000: Generator loss: 0.7326101566553116, discriminator loss: 0.6864855628013611
Step 37500: Generator loss: 0.7289662526845933, discriminator loss: 0.6891102294921875
Step 38000: Generator loss: 0.7277824294567108, discriminator loss: 0.6930312074422836
Step 38500: Generator loss: 0.7523093600273132, discriminator loss: 0.6822635132074356
Step 39000: Generator loss: 0.7260702294111252, discriminator loss: 0.6836128298044205
Step 39500: Generator loss: 0.7210463825464248, discriminator loss: 0.6865772886276245
Step 40000: Generator loss: 0.7197876414060592, discriminator loss: 0.6861994673013687
Step 40500: Generator loss: 0.7156198496818542, discriminator loss: 0.6897815141677857
Step 41000: Generator loss: 0.7411812788248062, discriminator loss: 0.6876297281980515
Step 41500: Generator loss: 0.7482703533172608, discriminator loss: 0.6831764079332352
Step 42000: Generator loss: 0.7353900390863418, discriminator loss: 0.6809069069623948
Step 42500: Generator loss: 0.726880151629448, discriminator loss: 0.6845077587366104
Step 43000: Generator loss: 0.7335763674974441, discriminator loss: 0.6855163406133652
Step 43500: Generator loss: 0.7247586588859558, discriminator loss: 0.684886796593666
Step 44000: Generator loss: 0.7244187197685241, discriminator loss: 0.6869175283908844
Step 44500: Generator loss: 0.7478935513496399, discriminator loss: 0.6783332238197327
Step 45000: Generator loss: 0.7392684471607208, discriminator loss: 0.687694214463234
Step 45500: Generator loss: 0.7384519840478897, discriminator loss: 0.6806207147836685
Step 46000: Generator loss: 0.7173152709007263, discriminator loss: 0.6894198944568634
Step 46500: Generator loss: 0.7135227386951446, discriminator loss: 0.6902039344310761
Step 47000: Generator loss: 0.7121314022541047, discriminator loss: 0.691226885676384
Step 47500: Generator loss: 0.7153779380321502, discriminator loss: 0.6898772416114807
Step 48000: Generator loss: 0.7112214748859406, discriminator loss: 0.6919035356044769
Step 48500: Generator loss: 0.729472970366478, discriminator loss: 0.6832324341535568
Step 49000: Generator loss: 0.7259864670038223, discriminator loss: 0.6850444099903107
Step 49500: Generator loss: 0.7463545156717301, discriminator loss: 0.6876692290306091
Step 50000: Generator loss: 0.72439306807518, discriminator loss: 0.6840117316246033
Step 50500: Generator loss: 0.7304026707410812, discriminator loss: 0.6828315691947937
Step 51000: Generator loss: 0.735065841794014, discriminator loss: 0.6877049984931946
Step 51500: Generator loss: 0.738693750500679, discriminator loss: 0.6786749280691147
Step 52000: Generator loss: 0.7165734323263169, discriminator loss: 0.688656357049942
Step 52500: Generator loss: 0.7124545810222626, discriminator loss: 0.6885210503339767
Step 53000: Generator loss: 0.7169003388881683, discriminator loss: 0.6898472727537155
Step 53500: Generator loss: 0.7116240389347076, discriminator loss: 0.6890990349054337
Step 54000: Generator loss: 0.7254890002012253, discriminator loss: 0.686066904425621
Step 54500: Generator loss: 0.7279696422815323, discriminator loss: 0.6824959990978241
Step 55000: Generator loss: 0.7243433123826981, discriminator loss: 0.686788556933403
Step 55500: Generator loss: 0.72320248234272, discriminator loss: 0.6819899456501007
Step 56000: Generator loss: 0.7283236463069915, discriminator loss: 0.6813042680025101
Step 56500: Generator loss: 0.7257692145109177, discriminator loss: 0.6882435537576675
Step 57000: Generator loss: 0.7204343225955964, discriminator loss: 0.6905163298845292
Step 57500: Generator loss: 0.7234136379957199, discriminator loss: 0.6828762836456299
Step 58000: Generator loss: 0.7213340125083924, discriminator loss: 0.6852367097139358
Step 58500: Generator loss: 0.7139561972618103, discriminator loss: 0.6901394550800324
Step 59000: Generator loss: 0.7128681792020798, discriminator loss: 0.6899428930282593
Step 59500: Generator loss: 0.7178032584190369, discriminator loss: 0.6901476013660431
Step 60000: Generator loss: 0.7218955677747726, discriminator loss: 0.6866856569051742
Step 60500: Generator loss: 0.7173091459274292, discriminator loss: 0.6909447896480561
Step 61000: Generator loss: 0.7196292532682419, discriminator loss: 0.6888659211397171
Step 61500: Generator loss: 0.7136147793531418, discriminator loss: 0.6911007264852523
Step 62000: Generator loss: 0.7167167031764984, discriminator loss: 0.6874131036996841
Step 62500: Generator loss: 0.7095696296691895, discriminator loss: 0.6924118340015412
Step 63000: Generator loss: 0.7100733149051667, discriminator loss: 0.6894952065944672
Step 63500: Generator loss: 0.7075963083505631, discriminator loss: 0.6918715183734894
Step 64000: Generator loss: 0.7087407541275025, discriminator loss: 0.6912821785211564
Step 64500: Generator loss: 0.7044790136814117, discriminator loss: 0.6919414196014404
Step 65000: Generator loss: 0.7120586842298507, discriminator loss: 0.6889722956418991
Step 65500: Generator loss: 0.7059948451519013, discriminator loss: 0.6913756219148636
Step 66000: Generator loss: 0.7103360829353332, discriminator loss: 0.6888430647850037
Step 66500: Generator loss: 0.7106574136018753, discriminator loss: 0.6923392252922058
Step 67000: Generator loss: 0.7205636972188949, discriminator loss: 0.6888139424324036
Step 67500: Generator loss: 0.7325763144493103, discriminator loss: 0.6851953419446946
Step 68000: Generator loss: 0.7144211075305938, discriminator loss: 0.6894719363451004
Step 68500: Generator loss: 0.7039347168207168, discriminator loss: 0.692310958981514
Step 69000: Generator loss: 0.707789731502533, discriminator loss: 0.690034374833107
Step 69500: Generator loss: 0.7080022550821304, discriminator loss: 0.6897176603078842
Step 70000: Generator loss: 0.706935028553009, discriminator loss: 0.6917025876045227
Step 70500: Generator loss: 0.7035844438076019, discriminator loss: 0.6928271135091781
Step 71000: Generator loss: 0.706664494395256, discriminator loss: 0.6913493415117263
Step 71500: Generator loss: 0.7080443944931031, discriminator loss: 0.6943384435176849
Step 72000: Generator loss: 0.7080535914897919, discriminator loss: 0.6904549078941346
Step 72500: Generator loss: 0.7195642621517181, discriminator loss: 0.6883307158946991
Step 73000: Generator loss: 0.7137477462291717, discriminator loss: 0.6895240060091019
Step 73500: Generator loss: 0.7089026942253113, discriminator loss: 0.6893982688188552
Step 74000: Generator loss: 0.71370064163208, discriminator loss: 0.6885940716266632
Step 74500: Generator loss: 0.7126090573072433, discriminator loss: 0.6913927717208862
Step 75000: Generator loss: 0.7061277792453766, discriminator loss: 0.6915859417915344
Step 75500: Generator loss: 0.7079737706184387, discriminator loss: 0.6918540188074112
Step 76000: Generator loss: 0.7094860315322876, discriminator loss: 0.6909938471317292
Step 76500: Generator loss: 0.7089288998842239, discriminator loss: 0.6928894543647766
Step 77000: Generator loss: 0.7099210443496704, discriminator loss: 0.6881472972631455
Step 77500: Generator loss: 0.7087316303253174, discriminator loss: 0.6922812685966492
Step 78000: Generator loss: 0.7124276860952378, discriminator loss: 0.686549712896347
Step 78500: Generator loss: 0.7118150774240494, discriminator loss: 0.6914097841978073
Step 79000: Generator loss: 0.7061567052602767, discriminator loss: 0.6910830926895142
Step 79500: Generator loss: 0.7130619381666183, discriminator loss: 0.6901648813486099
Step 80000: Generator loss: 0.7189263315200806, discriminator loss: 0.6891602661609649
Step 80500: Generator loss: 0.7099695562124252, discriminator loss: 0.6893361113071441
Step 81000: Generator loss: 0.7043007851839066, discriminator loss: 0.6928421225547791
Step 81500: Generator loss: 0.7055111042261124, discriminator loss: 0.6913482803106308
Step 82000: Generator loss: 0.7107034167051315, discriminator loss: 0.6899493371248245
Step 82500: Generator loss: 0.7072652250528335, discriminator loss: 0.691617219209671
Step 83000: Generator loss: 0.7116999027729034, discriminator loss: 0.6887015362977982
Step 83500: Generator loss: 0.7103397004604339, discriminator loss: 0.6889865008592606
Step 84000: Generator loss: 0.702219740986824, discriminator loss: 0.6927198125123978
Step 84500: Generator loss: 0.7042218887805939, discriminator loss: 0.6910840107202529
Step 85000: Generator loss: 0.7036903632879257, discriminator loss: 0.6948130846023559
Step 85500: Generator loss: 0.7157929112911224, discriminator loss: 0.6877820398807526
Step 86000: Generator loss: 0.703074496269226, discriminator loss: 0.6928336225748062
Step 86500: Generator loss: 0.7018165578842163, discriminator loss: 0.6942198793888092
Step 87000: Generator loss: 0.7056693414449692, discriminator loss: 0.6903062870502472
Step 87500: Generator loss: 0.7070764343738556, discriminator loss: 0.690039452791214
Step 88000: Generator loss: 0.7018579070568085, discriminator loss: 0.6929991252422333
Step 88500: Generator loss: 0.7042791714668274, discriminator loss: 0.6906855113506317
Step 89000: Generator loss: 0.7052908551692962, discriminator loss: 0.6917922974824905
Step 89500: Generator loss: 0.7057228873968124, discriminator loss: 0.6917544984817505
Step 90000: Generator loss: 0.7041428442001343, discriminator loss: 0.6921311345100403
Step 90500: Generator loss: 0.7040341221094132, discriminator loss: 0.6916886166334152
Step 91000: Generator loss: 0.7016080802679062, discriminator loss: 0.6918226274251937
Step 91500: Generator loss: 0.7047490992546082, discriminator loss: 0.6919238156080246
Step 92000: Generator loss: 0.7015802135467529, discriminator loss: 0.6937261604070664
Step 92500: Generator loss: 0.7035572265386582, discriminator loss: 0.6899326649904252
Step 93000: Generator loss: 0.7005916707515717, discriminator loss: 0.6933788905143737
Step 93500: Generator loss: 0.7005794968605041, discriminator loss: 0.6932051202058792
Ended: 2021-04-30 18:15:27.636306
Elapsed: 0:53:48.939130
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc6c19e6">
<h3 id="orgc6c19e6">Exploration</h3>
<div class="outline-text-3" id="text-orgc6c19e6">
<p>Before you explore, you should put the generator in eval mode, both in general and so that batch norm doesn't cause you issues and is using its eval statistics.</p>
<div class="highlight">
<pre><span></span><span class="n">gen</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org3552073">
<h4 id="org3552073">Changing the Class Vector</h4>
<div class="outline-text-4" id="text-org3552073">
<p>You can generate some numbers with your new model! You can add interpolation as well to make it more interesting.</p>
<p>So starting from a image, you will produce intermediate images that look more and more like the ending image until you get to the final image. Your're basically morphing one image into another. You can choose what these two images will be using your conditional GAN.</p>
<p>### Change me! ###</p>
<div class="highlight">
<pre><span></span><span class="n">n_interpolation</span> <span class="o">=</span> <span class="mi">9</span> <span class="c1"># Choose the interpolation: how many intermediate images you want + 2 (for the start and end image)</span>
<span class="n">interpolation_noise</span> <span class="o">=</span> <span class="n">make_some_noise</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">n_interpolation</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">interpolate_class</span><span class="p">(</span><span class="n">first_number</span><span class="p">,</span> <span class="n">second_number</span><span class="p">):</span>
    <span class="n">first_label</span> <span class="o">=</span> <span class="n">get_one_hot_labels</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">first_number</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">n_classes</span><span class="p">)</span>
    <span class="n">second_label</span> <span class="o">=</span> <span class="n">get_one_hot_labels</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">second_number</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">n_classes</span><span class="p">)</span>

    <span class="c1"># Calculate the interpolation vector between the two labels</span>
    <span class="n">percent_second_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_interpolation</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">interpolation_labels</span> <span class="o">=</span> <span class="n">first_label</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">percent_second_label</span><span class="p">)</span> <span class="o">+</span> <span class="n">second_label</span> <span class="o">*</span> <span class="n">percent_second_label</span>

    <span class="c1"># Combine the noise and the labels</span>
    <span class="n">noise_and_labels</span> <span class="o">=</span> <span class="n">combine_vectors</span><span class="p">(</span><span class="n">interpolation_noise</span><span class="p">,</span> <span class="n">interpolation_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="n">fake</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">noise_and_labels</span><span class="p">)</span>
    <span class="n">show_tensor_images</span><span class="p">(</span><span class="n">fake</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="n">n_interpolation</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_interpolation</span><span class="p">)),</span> <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1">### Change me! ###</span>
<span class="n">start_plot_number</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># Choose the start digit</span>
<span class="c1">### Change me! ###</span>
<span class="n">end_plot_number</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># Choose the end digit</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">interpolate_class</span><span class="p">(</span><span class="n">start_plot_number</span><span class="p">,</span> <span class="n">end_plot_number</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

<span class="c1">### Uncomment the following lines of code if you would like to visualize a set of pairwise class </span>
<span class="c1">### interpolations for a collection of different numbers, all in a single grid of interpolations.</span>
<span class="c1">### You'll also see another visualization like this in the next code block!</span>
<span class="c1"># plot_numbers = [2, 3, 4, 5, 7]</span>
<span class="c1"># n_numbers = len(plot_numbers)</span>
<span class="c1"># plt.figure(figsize=(8, 8))</span>
<span class="c1"># for i, first_plot_number in enumerate(plot_numbers):</span>
<span class="c1">#     for j, second_plot_number in enumerate(plot_numbers):</span>
<span class="c1">#         plt.subplot(n_numbers, n_numbers, i * n_numbers + j + 1)</span>
<span class="c1">#         interpolate_class(first_plot_number, second_plot_number)</span>
<span class="c1">#         plt.axis('off')</span>
<span class="c1"># plt.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0.1, wspace=0)</span>
<span class="c1"># plt.show()</span>
<span class="c1"># plt.close()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga96a37f">
<h4 id="orga96a37f">Changing the Noise Vector</h4>
<div class="outline-text-4" id="text-orga96a37f">
<p>Now, what happens if you hold the class constant, but instead you change the noise vector? You can also interpolate the noise vector and generate an image at each step.</p>
<div class="highlight">
<pre><span></span><span class="n">n_interpolation</span> <span class="o">=</span> <span class="mi">9</span> <span class="c1"># How many intermediate images you want + 2 (for the start and end image)</span>
</pre></div>
<p>This time you're interpolating between the noise instead of the labels</p>
<div class="highlight">
<pre><span></span><span class="n">interpolation_label</span> <span class="o">=</span> <span class="n">get_one_hot_labels</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">5</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">n_classes</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">n_interpolation</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">interpolate_noise</span><span class="p">(</span><span class="n">first_noise</span><span class="p">,</span> <span class="n">second_noise</span><span class="p">):</span>
    <span class="c1"># This time you're interpolating between the noise instead of the labels</span>
    <span class="n">percent_first_noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_interpolation</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">interpolation_noise</span> <span class="o">=</span> <span class="n">first_noise</span> <span class="o">*</span> <span class="n">percent_first_noise</span> <span class="o">+</span> <span class="n">second_noise</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">percent_first_noise</span><span class="p">)</span>

    <span class="c1"># Combine the noise and the labels again</span>
    <span class="n">noise_and_labels</span> <span class="o">=</span> <span class="n">combine_vectors</span><span class="p">(</span><span class="n">interpolation_noise</span><span class="p">,</span> <span class="n">interpolation_label</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="n">fake</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">noise_and_labels</span><span class="p">)</span>
    <span class="n">show_tensor_images</span><span class="p">(</span><span class="n">fake</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="n">n_interpolation</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_interpolation</span><span class="p">)),</span> <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p>Generate noise vectors to interpolate between.</p>
<div class="highlight">
<pre><span></span><span class="c1">### Change me! ###</span>
<span class="n">n_noise</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># Choose the number of noise examples in the grid</span>
<span class="n">plot_noises</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_noise</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_noise</span><span class="p">)]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">first_plot_noise</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">plot_noises</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">second_plot_noise</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">plot_noises</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">n_noise</span><span class="p">,</span> <span class="n">n_noise</span><span class="p">,</span> <span class="n">i</span> <span class="o">*</span> <span class="n">n_noise</span> <span class="o">+</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">interpolate_noise</span><span class="p">(</span><span class="n">first_plot_noise</span><span class="p">,</span> <span class="n">second_plot_noise</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org3782dbc">
<h2 id="org3782dbc">End</h2>
</div>
</div>
</article>
</div>
<ul class="pager postindexpager clearfix">
<li class="previous"><a href="." rel="prev">Newer posts</a></li>
<li class="next"><a href="index-21.html" rel="next">Older posts</a></li>
</ul>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script><!--End of body content-->
<footer id="footer">Scribbles by <a href="mailto:cloisteredmonkey.jmark@slmail.me">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>
<div id="license" xmlns:cc="http://creativecommons.org/ns#">This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" rel="license noopener noreferrer" style="display:inline-block;" target="_blank">CC BY 4.0 <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></div>
</footer>
</div>
</div>
<script src="assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
